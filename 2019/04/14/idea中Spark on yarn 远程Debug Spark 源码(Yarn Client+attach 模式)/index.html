<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="spark," />





  <link rel="alternate" href="/atom.xml" title="blog" type="application/atom+xml" />






<meta name="description" content="背景idea 中连接yarn集群debug spark代码,有利于定位线上问题。 环境默认你hadoop环境已经搞定情况下的说明！！！scala版本： 2.11.8jdk版本：JDK1.8hadoop版本： 2.7.3spark版本： 2.4.1zookeeper： 3.4.6高能预警： 一定要保持yarn集群机器scala版本和项目pom文件中scala版本一致。         linux版本">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)">
<meta property="og:url" content="https://tgluon.github.io/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="背景idea 中连接yarn集群debug spark代码,有利于定位线上问题。 环境默认你hadoop环境已经搞定情况下的说明！！！scala版本： 2.11.8jdk版本：JDK1.8hadoop版本： 2.7.3spark版本： 2.4.1zookeeper： 3.4.6高能预警： 一定要保持yarn集群机器scala版本和项目pom文件中scala版本一致。         linux版本">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-04-14T15:11:18.418Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)">
<meta name="twitter:description" content="背景idea 中连接yarn集群debug spark代码,有利于定位线上问题。 环境默认你hadoop环境已经搞定情况下的说明！！！scala版本： 2.11.8jdk版本：JDK1.8hadoop版本： 2.7.3spark版本： 2.4.1zookeeper： 3.4.6高能预警： 一定要保持yarn集群机器scala版本和项目pom文件中scala版本一致。         linux版本">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tgluon.github.io/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/"/>





  <title>idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式) | blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/tgluon"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_orange_ff7600.png" alt="Fork me on GitHub"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">追梦青年</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-14T23:11:18+08:00">
                2019-04-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  24,964
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  154
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>idea 中连接yarn集群debug spark代码,有利于定位线上问题。</p>
<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>默认你hadoop环境已经搞定情况下的说明！！！<br><strong>scala版本：</strong> 2.11.8<br><strong>jdk版本</strong>：JDK1.8<br><strong>hadoop版本：</strong> 2.7.3<br><strong>spark版本：</strong> 2.4.1<br><strong>zookeeper：</strong> 3.4.6<br><strong>高能预警：</strong> 一定要保持yarn集群机器scala版本和项目pom文件中scala版本一致。     </p>
<table>
<thead>
<tr>
<th>linux版本</th>
<th>IP</th>
<th>hostname</th>
<th>进程 </th>
</tr>
</thead>
<tbody>
<tr>
<td>centos7</td>
<td>192.168.8.81</td>
<td>hadoop01</td>
<td>NameNode、DFSZKFailoverController</td>
</tr>
<tr>
<td>centos7</td>
<td>192.168.8.82</td>
<td>hadoop02</td>
<td>NameNode、DFSZKFailoverController、ResourceManager、JournalNode、NodeManager、DataNode、QuorumPeerMain</td>
</tr>
<tr>
<td>centos7</td>
<td>192.168.8.83</td>
<td>hadoop03</td>
<td>JournalNode、NodeManager、DataNode、QuorumPeerMain</td>
</tr>
<tr>
<td>centos7</td>
<td>192.168.8.84</td>
<td>hadoop04</td>
<td>JournalNode、NodeManager、DataNode、QuorumPeerMain</td>
</tr>
</tbody>
</table>
<p><strong>idea所在机器：</strong>   </p>
<table>
<thead>
<tr>
<th>linux版本</th>
<th>IP</th>
<th>hostname</th>
</tr>
</thead>
<tbody>
<tr>
<td>ubuntu18.04</td>
<td>192.168.8.85</td>
<td>hadoop05</td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="maven项目中resources目录中配置文件"><a href="#maven项目中resources目录中配置文件" class="headerlink" title="maven项目中resources目录中配置文件"></a>maven项目中resources目录中配置文件</h1><p><strong>高能预警：</strong> 配置文件需要和hadoop集群一致</p>
<p><strong>具体配置文件如下：</strong><br>core-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hdfs的nameservice为ns1 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop临时目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定zookeeper地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:2181,hadoop03:2181,hadoop04:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>hdfs-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn1的RPC通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn1的http通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn2的RPC通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn2的http通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop02:8485;hadoop03:8485;hadoop04:8485/ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/journaldata<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启NameNode失败自动切换 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置失败自动切换实现方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">sshfence</span><br><span class="line">shell(/bin/true)</span><br><span class="line"><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置sshfence隔离机制超时时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.connect-timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--修改block块的大小,默认为128M--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.block.seze<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>128<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>yarn-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0"?&gt;</span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--开启RM高可用 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.embedded<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定RM的cluster id --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yrc<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定RM的名字 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 分别指定RM的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定zk集群地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:2181,hadoop03:2181,hadoop04:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.client.failover-proxy-provider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 两个可选值：org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore 以及 默认值org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.web-proxy.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>192.168.8.82:8089<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 打开日志聚合功能，这样才能从web界面查看日志 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 聚合日志最长保留时间 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>86400<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 中间结果存放位置。注意，这个参数通常会配置多个目录，已分摊磁盘IO负载。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/data/localdir1,/home/hadoop/hadoop/data/localdir2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 日志存放位置。注意，这个参数通常会配置多个目录，已分摊磁盘IO负载。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/data/hdfs/logdir1,/home/hadoop/hadoop/data/hdfs/logdir2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>spark-defaults.conf配置文件：</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Licensed to the Apache Software Foundation (ASF) under one or more</span><br><span class="line"># contributor license agreements.  See the NOTICE file distributed with</span><br><span class="line"># this work for additional information regarding copyright ownership.</span><br><span class="line"># The ASF licenses this file to You under the Apache License, Version 2.0</span><br><span class="line"># (the "License"); you may not use this file except in compliance with</span><br><span class="line"># the License.  You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an "AS IS" BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># Default system properties included when running spark-submit.</span><br><span class="line"># This is useful for setting default environmental settings.</span><br><span class="line">spark.driver.extraClassPath         /home/hadoop/spark/jars/*:/home/hadoop/hadoop/share/hadoop/hdfs/*:/home/hadoop/hadoop/share/hadoop/common/*:/home/hadoop/hadoop/share/hadoop/common/lib/*:/home/hadoop/hadoop/share/hadoop/yarn/*:/home/hadoop/hadoop/share/hadoop/yarn/lib/*</span><br><span class="line"></span><br><span class="line">spark.executor.extraClassPath     /home/hadoop/spark/jars/*:/home/hadoop/hadoop/share/hadoop/hdfs/*:/home/hadoop/hadoop/share/hadoop/common/*:/home/hadoop/hadoop/share/hadoop/common/lib/*:/home/hadoop/hadoop/share/hadoop/yarn/*:/home/hadoop/hadoop/share/hadoop/yarn/lib/*</span><br><span class="line">spark.driver.extraJavaOptions     -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005</span><br><span class="line">spark.executor.extraJavaOptions   -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005</span><br><span class="line">spark.driver.memory                512m</span><br><span class="line">spark.executor.memory              512m</span><br><span class="line"># Example:</span><br><span class="line"># spark.master                     spark://master:7077</span><br><span class="line"># spark.eventLog.enabled           true</span><br><span class="line"># spark.eventLog.dir               hdfs://namenode:8021/directory</span><br><span class="line"># spark.serializer                 org.apache.spark.serializer.KryoSerializer</span><br><span class="line"># spark.driver.memory              5g</span><br><span class="line"># spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"</span><br></pre></td></tr></table></figure></p>
<h1 id="maven-pom配置文件"><a href="#maven-pom配置文件" class="headerlink" title="maven pom配置文件"></a>maven pom配置文件</h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.xh.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>sparklearning<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.version</span>&gt;</span>2.11.8<span class="tag">&lt;/<span class="name">scala.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.binary.version</span>&gt;</span>2.11<span class="tag">&lt;/<span class="name">scala.binary.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spark.version</span>&gt;</span>2.4.1<span class="tag">&lt;/<span class="name">spark.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.7.3<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mysql.version</span>&gt;</span>5.1.35<span class="tag">&lt;/<span class="name">mysql.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hive.version</span>&gt;</span>2.3.3<span class="tag">&lt;/<span class="name">hive.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">guava.version</span>&gt;</span>26.0-jre<span class="tag">&lt;/<span class="name">guava.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">fastjson.version</span>&gt;</span>1.2.40<span class="tag">&lt;/<span class="name">fastjson.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">zookeeper.version</span>&gt;</span>3.4.6<span class="tag">&lt;/<span class="name">zookeeper.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--scala--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;zookeeper.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--spark--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-yarn_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-mllib_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-hive_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-10_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;fastjson.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--hive--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--hadoop--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--mysql--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;mysql.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--guava--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;guava.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- This plugin compiles Scala files --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.alchim31.maven<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>scala-compile-first<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>process-resources<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>add-source<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>scala-test-compile<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>process-test-resources<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- This plugin compiles Java files --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--跳过test begin--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.20<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">skipTests</span>&gt;</span>true<span class="tag">&lt;/<span class="name">skipTests</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- This plugin adds all dependencies to JAR file during 'package' command.</span></span><br><span class="line"><span class="comment">            Pay EXTRA attention to the 'mainClass' tag.</span></span><br><span class="line"><span class="comment">            You have to set name of class with entry point to program ('main' method) --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">manifestFile</span>&gt;</span><span class="tag">&lt;/<span class="name">manifestFile</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-shade-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>shade<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">filters</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">artifact</span>&gt;</span>*:*<span class="tag">&lt;/<span class="name">artifact</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.SF<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.DSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.RSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">filters</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">transformers</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">transformer</span></span></span><br><span class="line"><span class="tag">                                        <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.defonds.RsaEncryptor<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">transformer</span></span></span><br><span class="line"><span class="tag">                                        <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.AppendingTransformer"</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">resource</span>&gt;</span>META-INF/spring.handlers<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">transformer</span></span></span><br><span class="line"><span class="tag">                                        <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.AppendingTransformer"</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">resource</span>&gt;</span>META-INF/spring.schemas<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">transformers</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="开发程序"><a href="#开发程序" class="headerlink" title="开发程序"></a>开发程序</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xh.spark.sql.function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WindowFunctionTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      .setAppName(<span class="string">"WindowFunctionTest"</span>)</span><br><span class="line">          .set(<span class="string">"spark.master"</span>, <span class="string">"yarn"</span>)</span><br><span class="line">          .set(<span class="string">"spark.submit.deployMode"</span>, <span class="string">"client"</span>) <span class="comment">// 部署模式为client</span></span><br><span class="line">          .set(<span class="string">"yarn.resourcemanager.hostname"</span>, <span class="string">"hadoop02"</span>) <span class="comment">// resourcemanager主机名</span></span><br><span class="line">          .set(<span class="string">"spark.executor.instances"</span>, <span class="string">"2"</span>) <span class="comment">// Executor实例的数量</span></span><br><span class="line">          .set(<span class="string">"spark.dynamicAllocation.enabled"</span>, <span class="string">"false"</span>)</span><br><span class="line">          .setJars(<span class="type">List</span>(<span class="string">"/home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT.jar"</span>,</span><br><span class="line">            <span class="string">"/home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT-jar-with-dependencies.jar"</span></span><br><span class="line">          ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .config(sparkConf)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">val</span> df = <span class="type">List</span>(</span><br><span class="line">      (<span class="string">"站点1"</span>, <span class="string">"2018-01-01"</span>, <span class="number">50</span>),</span><br><span class="line">      (<span class="string">"站点1"</span>, <span class="string">"2018-01-02"</span>, <span class="number">45</span>),</span><br><span class="line">      (<span class="string">"站点1"</span>, <span class="string">"2018-01-03"</span>, <span class="number">55</span>),</span><br><span class="line">      (<span class="string">"站点2"</span>, <span class="string">"2018-01-01"</span>, <span class="number">25</span>),</span><br><span class="line">      (<span class="string">"站点2"</span>, <span class="string">"2018-01-02"</span>, <span class="number">29</span>),</span><br><span class="line">      (<span class="string">"站点2"</span>, <span class="string">"2018-01-03"</span>, <span class="number">27</span>)</span><br><span class="line">    ).toDF(<span class="string">"site"</span>, <span class="string">"date"</span>, <span class="string">"user_cnt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 简单移动平均值</span></span><br><span class="line">    <span class="comment">// API方式</span></span><br><span class="line">    <span class="comment">// 窗口定义从 -1(前一行)到 1(后一行)	，每一个滑动的窗口总用有3行</span></span><br><span class="line">    <span class="keyword">val</span> movinAvgSpec = <span class="type">Window</span>.partitionBy(<span class="string">"site"</span>).orderBy(<span class="string">"date"</span>).rowsBetween(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">    df.withColumn(<span class="string">"MovingAvg"</span>, avg(df(<span class="string">"user_cnt"</span>)).over(movinAvgSpec)).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sql方式</span></span><br><span class="line">     df.createOrReplaceTempView(<span class="string">"site_info"</span>)</span><br><span class="line">        spark.sql(</span><br><span class="line">          <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">            |select site,</span></span><br><span class="line"><span class="string">            |       date,</span></span><br><span class="line"><span class="string">            |       user_cnt,</span></span><br><span class="line"><span class="string">            |       avg(user_cnt) over(partition by site order by date rows between 1 preceding and 1 following) as moving_avg</span></span><br><span class="line"><span class="string">            |from   site_info</span></span><br><span class="line"><span class="string">          "</span><span class="string">""</span>.stripMargin).show()</span><br><span class="line">    </span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上确认无误之后，直接在idea里面run该程序。   </p>
<h1 id="执行结果如下"><a href="#执行结果如下" class="headerlink" title="执行结果如下"></a>执行结果如下</h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br></pre></td><td class="code"><pre><span class="line">/usr/lib/jvm/java-1.8.0-openjdk/bin/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:45315,suspend=y,server=n -javaagent:/home/hadoop/idea/lib/rt/debugger-agent.jar -Dfile.encoding=UTF-8 -classpath /usr/lib/jvm/java-1.8.0-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/cldrdata.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/dnsns.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/jaccess.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/localedata.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/nashorn.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/sunec.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/sunjce_provider.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/sunpkcs11.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/zipfs.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/management-agent.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/rt.jar:/home/hadoop/worker/sparklearning/target/classes:/home/hadoop/repository/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar:/home/hadoop/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/repository/log4j/log4j/1.2.16/log4j-1.2.16.jar:/home/hadoop/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/hadoop/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/home/hadoop/repository/org/apache/spark/spark-yarn_2.11/2.4.1/spark-yarn_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-api/2.6.5/hadoop-yarn-api-2.6.5.jar:/home/hadoop/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-common/2.6.5/hadoop-yarn-common-2.6.5.jar:/home/hadoop/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/hadoop/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.6.5/hadoop-yarn-server-web-proxy-2.6.5.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-common/2.6.5/hadoop-yarn-server-common-2.6.5.jar:/home/hadoop/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-client/2.6.5/hadoop-yarn-client-2.6.5.jar:/home/hadoop/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/hadoop/repository/org/apache/spark/spark-core_2.11/2.4.1/spark-core_2.11-2.4.1.jar:/home/hadoop/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/hadoop/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/hadoop/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/hadoop/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/hadoop/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/hadoop/repository/com/twitter/chill_2.11/0.9.3/chill_2.11-0.9.3.jar:/home/hadoop/repository/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar:/home/hadoop/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/home/hadoop/repository/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar:/home/hadoop/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/hadoop/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/hadoop/repository/org/apache/spark/spark-launcher_2.11/2.4.1/spark-launcher_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-kvstore_2.11/2.4.1/spark-kvstore_2.11-2.4.1.jar:/home/hadoop/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/repository/com/fasterxml/jackson/core/jackson-core/2.6.7/jackson-core-2.6.7.jar:/home/hadoop/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.7/jackson-annotations-2.6.7.jar:/home/hadoop/repository/org/apache/spark/spark-network-common_2.11/2.4.1/spark-network-common_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-network-shuffle_2.11/2.4.1/spark-network-shuffle_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-unsafe_2.11/2.4.1/spark-unsafe_2.11-2.4.1.jar:/home/hadoop/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/hadoop/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/home/hadoop/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/hadoop/repository/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar:/home/hadoop/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/home/hadoop/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/hadoop/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/hadoop/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/hadoop/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/home/hadoop/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/hadoop/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/hadoop/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/home/hadoop/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/repository/org/json4s/json4s-jackson_2.11/3.5.3/json4s-jackson_2.11-3.5.3.jar:/home/hadoop/repository/org/json4s/json4s-core_2.11/3.5.3/json4s-core_2.11-3.5.3.jar:/home/hadoop/repository/org/json4s/json4s-ast_2.11/3.5.3/json4s-ast_2.11-3.5.3.jar:/home/hadoop/repository/org/json4s/json4s-scalap_2.11/3.5.3/json4s-scalap_2.11-3.5.3.jar:/home/hadoop/repository/org/scala-lang/modules/scala-xml_2.11/1.0.6/scala-xml_2.11-1.0.6.jar:/home/hadoop/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/hadoop/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/hadoop/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/hadoop/repository/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/home/hadoop/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/hadoop/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/hadoop/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/hadoop/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/hadoop/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/hadoop/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/hadoop/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/hadoop/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.jar:/home/hadoop/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/hadoop/repository/io/netty/netty-all/4.1.17.Final/netty-all-4.1.17.Final.jar:/home/hadoop/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/hadoop/repository/com/fasterxml/jackson/core/jackson-databind/2.6.7.1/jackson-databind-2.6.7.1.jar:/home/hadoop/repository/com/fasterxml/jackson/module/jackson-module-scala_2.11/2.6.7.1/jackson-module-scala_2.11-2.6.7.1.jar:/home/hadoop/repository/org/scala-lang/scala-reflect/2.11.8/scala-reflect-2.11.8.jar:/home/hadoop/repository/com/fasterxml/jackson/module/jackson-module-paranamer/2.7.9/jackson-module-paranamer-2.7.9.jar:/home/hadoop/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/hadoop/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/hadoop/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/hadoop/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/hadoop/repository/org/apache/spark/spark-tags_2.11/2.4.1/spark-tags_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/hadoop/repository/org/apache/spark/spark-sql_2.11/2.4.1/spark-sql_2.11-2.4.1.jar:/home/hadoop/repository/com/univocity/univocity-parsers/2.7.3/univocity-parsers-2.7.3.jar:/home/hadoop/repository/org/apache/spark/spark-sketch_2.11/2.4.1/spark-sketch_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-catalyst_2.11/2.4.1/spark-catalyst_2.11-2.4.1.jar:/home/hadoop/repository/org/codehaus/janino/janino/3.0.9/janino-3.0.9.jar:/home/hadoop/repository/org/codehaus/janino/commons-compiler/3.0.9/commons-compiler-3.0.9.jar:/home/hadoop/repository/org/antlr/antlr4-runtime/4.7/antlr4-runtime-4.7.jar:/home/hadoop/repository/org/apache/orc/orc-core/1.5.5/orc-core-1.5.5-nohive.jar:/home/hadoop/repository/org/apache/orc/orc-shims/1.5.5/orc-shims-1.5.5.jar:/home/hadoop/repository/io/airlift/aircompressor/0.10/aircompressor-0.10.jar:/home/hadoop/repository/org/apache/orc/orc-mapreduce/1.5.5/orc-mapreduce-1.5.5-nohive.jar:/home/hadoop/repository/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.jar:/home/hadoop/repository/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.jar:/home/hadoop/repository/org/apache/arrow/arrow-vector/0.10.0/arrow-vector-0.10.0.jar:/home/hadoop/repository/org/apache/arrow/arrow-format/0.10.0/arrow-format-0.10.0.jar:/home/hadoop/repository/org/apache/arrow/arrow-memory/0.10.0/arrow-memory-0.10.0.jar:/home/hadoop/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/hadoop/repository/com/vlkan/flatbuffers/1.2.0-3f79e055/flatbuffers-1.2.0-3f79e055.jar:/home/hadoop/repository/org/apache/spark/spark-mllib_2.11/2.4.1/spark-mllib_2.11-2.4.1.jar:/home/hadoop/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.1.0/scala-parser-combinators_2.11-1.1.0.jar:/home/hadoop/repository/org/apache/spark/spark-graphx_2.11/2.4.1/spark-graphx_2.11-2.4.1.jar:/home/hadoop/repository/com/github/fommil/netlib/core/1.1.2/core-1.1.2.jar:/home/hadoop/repository/net/sourceforge/f2j/arpack_combined_all/0.1/arpack_combined_all-0.1.jar:/home/hadoop/repository/org/apache/spark/spark-mllib-local_2.11/2.4.1/spark-mllib-local_2.11-2.4.1.jar:/home/hadoop/repository/org/scalanlp/breeze_2.11/0.13.2/breeze_2.11-0.13.2.jar:/home/hadoop/repository/org/scalanlp/breeze-macros_2.11/0.13.2/breeze-macros_2.11-0.13.2.jar:/home/hadoop/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/hadoop/repository/com/github/rwl/jtransforms/2.4.0/jtransforms-2.4.0.jar:/home/hadoop/repository/org/spire-math/spire_2.11/0.13.0/spire_2.11-0.13.0.jar:/home/hadoop/repository/org/spire-math/spire-macros_2.11/0.13.0/spire-macros_2.11-0.13.0.jar:/home/hadoop/repository/org/typelevel/machinist_2.11/0.6.1/machinist_2.11-0.6.1.jar:/home/hadoop/repository/com/chuusai/shapeless_2.11/2.3.2/shapeless_2.11-2.3.2.jar:/home/hadoop/repository/org/typelevel/macro-compat_2.11/1.1.1/macro-compat_2.11-1.1.1.jar:/home/hadoop/repository/org/apache/spark/spark-hive_2.11/2.4.1/spark-hive_2.11-2.4.1.jar:/home/hadoop/repository/com/twitter/parquet-hadoop-bundle/1.6.0/parquet-hadoop-bundle-1.6.0.jar:/home/hadoop/repository/org/spark-project/hive/hive-exec/1.2.1.spark2/hive-exec-1.2.1.spark2.jar:/home/hadoop/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/hadoop/repository/log4j/apache-log4j-extras/1.2.17/apache-log4j-extras-1.2.17.jar:/home/hadoop/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/hadoop/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/home/hadoop/repository/org/spark-project/hive/hive-metastore/1.2.1.spark2/hive-metastore-1.2.1.spark2.jar:/home/hadoop/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/hadoop/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/repository/org/datanucleus/datanucleus-api-jdo/3.2.6/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/repository/org/datanucleus/datanucleus-rdbms/3.2.9/datanucleus-rdbms-3.2.9.jar:/home/hadoop/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/hadoop/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/hadoop/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/hadoop/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/hadoop/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/repository/org/apache/calcite/calcite-avatica/1.2.0-incubating/calcite-avatica-1.2.0-incubating.jar:/home/hadoop/repository/org/apache/calcite/calcite-core/1.2.0-incubating/calcite-core-1.2.0-incubating.jar:/home/hadoop/repository/org/apache/calcite/calcite-linq4j/1.2.0-incubating/calcite-linq4j-1.2.0-incubating.jar:/home/hadoop/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/hadoop/repository/org/apache/httpcomponents/httpclient/4.5.6/httpclient-4.5.6.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/repository/commons-codec/commons-codec/1.10/commons-codec-1.10.jar:/home/hadoop/repository/joda-time/joda-time/2.9.3/joda-time-2.9.3.jar:/home/hadoop/repository/org/jodd/jodd-core/3.5.2/jodd-core-3.5.2.jar:/home/hadoop/repository/org/datanucleus/datanucleus-core/3.2.10/datanucleus-core-3.2.10.jar:/home/hadoop/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/hadoop/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/hadoop/repository/org/apache/derby/derby/10.12.1.1/derby-10.12.1.1.jar:/home/hadoop/repository/org/apache/spark/spark-streaming_2.11/2.4.1/spark-streaming_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-streaming-kafka-0-10_2.11/2.4.1/spark-streaming-kafka-0-10_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/kafka/kafka-clients/2.0.0/kafka-clients-2.0.0.jar:/home/hadoop/repository/com/alibaba/fastjson/1.2.40/fastjson-1.2.40.jar:/home/hadoop/repository/org/apache/hive/hive-jdbc/2.3.3/hive-jdbc-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-storage-api/2.4.0/hive-storage-api-2.4.0.jar:/home/hadoop/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/hadoop/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/hadoop/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/hadoop/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/hadoop/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/hadoop/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/hadoop/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/hadoop/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/hadoop/repository/asm/asm/3.1/asm-3.1.jar:/home/hadoop/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/hadoop/repository/com/tdunning/json/1.8/json-1.8.jar:/home/hadoop/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/hadoop/repository/org/apache/hive/hive-service/2.3.3/hive-service-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-llap-server/2.3.3/hive-llap-server-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/hadoop/repository/org/apache/slider/slider-core/0.90.2-incubating/slider-core-0.90.2-incubating.jar:/home/hadoop/repository/com/beust/jcommander/1.30/jcommander-1.30.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.1/hadoop-yarn-registry-2.7.1.jar:/home/hadoop/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/hadoop/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/hadoop/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3-tests.jar:/home/hadoop/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.1/hbase-hadoop2-compat-1.1.1.jar:/home/hadoop/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/home/hadoop/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/repository/org/apache/hbase/hbase-server/1.1.1/hbase-server-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-procedure/1.1.1/hbase-procedure-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1-tests.jar:/home/hadoop/repository/org/apache/hbase/hbase-prefix-tree/1.1.1/hbase-prefix-tree-1.1.1.jar:/home/hadoop/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/home/hadoop/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-hadoop-compat/1.1.1/hbase-hadoop-compat-1.1.1.jar:/home/hadoop/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/hadoop/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/repository/javax/servlet/jsp-api/2.0/jsp-api-2.0.jar:/home/hadoop/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/hadoop/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/repository/javax/servlet/servlet-api/2.4/servlet-api-2.4.jar:/home/hadoop/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/hadoop/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/hadoop/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/hadoop/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/usr/lib/jvm/java-1.8.0-openjdk/lib/tools.jar:/home/hadoop/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/hadoop/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/hadoop/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/hadoop/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/hadoop/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/hadoop/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/hadoop/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/hadoop/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/hadoop/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/hadoop/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/hadoop/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/hadoop/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/hadoop/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/hadoop/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/hadoop/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6-tests.jar:/home/hadoop/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/hadoop/repository/org/apache/httpcomponents/httpcore/4.4/httpcore-4.4.jar:/home/hadoop/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/hadoop/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/hadoop/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/hadoop/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/hadoop/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/hadoop/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/hadoop/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/hadoop/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/hadoop/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/hadoop/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/hadoop/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/hadoop/repository/org/codehaus/groovy/groovy-all/2.4.4/groovy-all-2.4.4.jar:/home/hadoop/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/hadoop/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/hadoop/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/hadoop/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/hadoop/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-client/2.7.3/hadoop-client-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-common/2.7.3/hadoop-common-2.7.3.jar:/home/hadoop/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/hadoop/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-auth/2.7.3/hadoop-auth-2.7.3.jar:/home/hadoop/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-hdfs/2.7.3/hadoop-hdfs-2.7.3.jar:/home/hadoop/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/hadoop/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-annotations/2.7.3/hadoop-annotations-2.7.3.jar:/home/hadoop/repository/mysql/mysql-connector-java/5.1.35/mysql-connector-java-5.1.35.jar:/home/hadoop/repository/com/google/guava/guava/26.0-jre/guava-26.0-jre.jar:/home/hadoop/repository/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/home/hadoop/repository/com/google/errorprone/error_prone_annotations/2.1.3/error_prone_annotations-2.1.3.jar:/home/hadoop/repository/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/home/hadoop/repository/org/codehaus/mojo/animal-sniffer-annotations/1.14/animal-sniffer-annotations-1.14.jar:/home/hadoop/scala/lib/scala-parser-combinators_2.11-1.0.4.jar:/home/hadoop/scala/lib/scala-reflect.jar:/home/hadoop/scala/lib/scala-actors-migration_2.11-1.1.0.jar:/home/hadoop/scala/lib/scala-xml_2.11-1.0.4.jar:/home/hadoop/scala/lib/scala-library.jar:/home/hadoop/scala/lib/scala-swing_2.11-1.0.2.jar:/home/hadoop/scala/lib/scala-actors-2.11.0.jar:/home/hadoop/idea/lib/idea_rt.jar com.xh.spark.sql.function.WindowFunctionTest</span><br><span class="line">Connected to the target VM, address: '127.0.0.1:45315', transport: 'socket'</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/hadoop/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/hadoop/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line">19/04/12 16:47:02 INFO SparkContext: Running Spark version 2.4.1</span><br><span class="line">19/04/12 16:47:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">19/04/12 16:47:04 INFO SparkContext: Submitted application: WindowFunctionTest</span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing view acls to: hadoop</span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing modify acls to: hadoop</span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing view acls groups to: </span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing modify acls groups to: </span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()</span><br><span class="line">19/04/12 16:47:07 INFO Utils: Successfully started service 'sparkDriver' on port 43568.</span><br><span class="line">19/04/12 16:47:07 INFO SparkEnv: Registering MapOutputTracker</span><br><span class="line">19/04/12 16:47:07 INFO SparkEnv: Registering BlockManagerMaster</span><br><span class="line">19/04/12 16:47:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information</span><br><span class="line">19/04/12 16:47:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up</span><br><span class="line">19/04/12 16:47:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-07913749-f493-4bae-95aa-f9ea019dde51</span><br><span class="line">19/04/12 16:47:07 INFO MemoryStore: MemoryStore started with capacity 447.3 MB</span><br><span class="line">19/04/12 16:47:07 INFO SparkEnv: Registering OutputCommitCoordinator</span><br><span class="line">19/04/12 16:47:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.</span><br><span class="line">19/04/12 16:47:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://hadoop04:4040</span><br><span class="line">19/04/12 16:47:08 INFO SparkContext: Added JAR /home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT.jar at spark://hadoop04:43568/jars/sparklearning-1.0-SNAPSHOT.jar with timestamp 1555058828687</span><br><span class="line">19/04/12 16:47:08 INFO SparkContext: Added JAR /home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://hadoop04:43568/jars/sparklearning-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1555058828703</span><br><span class="line">19/04/12 16:47:13 INFO Client: Requesting a new application from cluster with 3 NodeManagers</span><br><span class="line">19/04/12 16:47:13 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)</span><br><span class="line">19/04/12 16:47:13 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead</span><br><span class="line">19/04/12 16:47:13 INFO Client: Setting up container launch context for our AM</span><br><span class="line">19/04/12 16:47:13 INFO Client: Setting up the launch environment for our AM container</span><br><span class="line">19/04/12 16:47:14 INFO Client: Preparing resources for our AM container</span><br><span class="line">19/04/12 16:47:14 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.</span><br><span class="line">19/04/12 16:47:23 INFO Client: Uploading resource file:/tmp/spark-f3533ae6-b45b-4a1f-8119-0c12775c5a33/__spark_libs__8176900855339303501.zip -&gt; hdfs://ns1/user/hadoop/.sparkStaging/application_1555049463744_0005/__spark_libs__8176900855339303501.zip</span><br><span class="line">19/04/12 16:47:50 INFO Client: Uploading resource file:/tmp/spark-f3533ae6-b45b-4a1f-8119-0c12775c5a33/__spark_conf__4747135480716905311.zip -&gt; hdfs://ns1/user/hadoop/.sparkStaging/application_1555049463744_0005/__spark_conf__.zip</span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing view acls to: hadoop</span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing modify acls to: hadoop</span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing view acls groups to: </span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing modify acls groups to: </span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()</span><br><span class="line">19/04/12 16:47:55 INFO Client: Submitting application application_1555049463744_0005 to ResourceManager</span><br><span class="line">19/04/12 16:47:55 INFO YarnClientImpl: Submitted application application_1555049463744_0005</span><br><span class="line">19/04/12 16:47:55 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1555049463744_0005 and attemptId None</span><br><span class="line">19/04/12 16:47:57 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:47:57 INFO Client: </span><br><span class="line">	 client token: N/A</span><br><span class="line">	 diagnostics: N/A</span><br><span class="line">	 ApplicationMaster host: N/A</span><br><span class="line">	 ApplicationMaster RPC port: -1</span><br><span class="line">	 queue: root.hadoop</span><br><span class="line">	 start time: 1555058875812</span><br><span class="line">	 final status: UNDEFINED</span><br><span class="line">	 tracking URL: http://192.168.8.82:8089/proxy/application_1555049463744_0005/</span><br><span class="line">	 user: hadoop</span><br><span class="line">19/04/12 16:47:58 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:47:59 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:00 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:01 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:02 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:03 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:04 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:05 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:06 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:07 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:08 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:09 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:10 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:11 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:12 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:13 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:14 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:15 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:16 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:17 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:18 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:19 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:20 INFO Client: Application report for application_1555049463744_0005 (state: RUNNING)</span><br><span class="line">19/04/12 16:48:20 INFO Client: </span><br><span class="line">	 client token: N/A</span><br><span class="line">	 diagnostics: N/A</span><br><span class="line">	 ApplicationMaster host: 192.168.8.82</span><br><span class="line">	 ApplicationMaster RPC port: -1</span><br><span class="line">	 queue: root.hadoop</span><br><span class="line">	 start time: 1555058875812</span><br><span class="line">	 final status: UNDEFINED</span><br><span class="line">	 tracking URL: http://192.168.8.82:8089/proxy/application_1555049463744_0005/</span><br><span class="line">	 user: hadoop</span><br><span class="line">19/04/12 16:48:20 INFO YarnClientSchedulerBackend: Application application_1555049463744_0005 has started running.</span><br><span class="line">19/04/12 16:48:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42715.</span><br><span class="line">19/04/12 16:48:21 INFO NettyBlockTransferService: Server created on hadoop04:42715</span><br><span class="line">19/04/12 16:48:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy</span><br><span class="line">19/04/12 16:48:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:21 INFO BlockManagerMasterEndpoint: Registering block manager hadoop04:42715 with 447.3 MB RAM, BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:23 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)</span><br><span class="line">19/04/12 16:48:24 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; 192.168.8.82, PROXY_URI_BASES -&gt; http://192.168.8.82:8089/proxy/application_1555049463744_0005, RM_HA_URLS -&gt; hadoop02:8088,hadoop03:8088), /proxy/application_1555049463744_0005</span><br><span class="line">19/04/12 16:48:24 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill, /metrics/json.</span><br><span class="line">19/04/12 16:48:24 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)</span><br><span class="line">19/04/12 16:48:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/hadoop/worker/sparklearning/spark-warehouse').</span><br><span class="line">19/04/12 16:48:32 INFO SharedState: Warehouse path is 'file:/home/hadoop/worker/sparklearning/spark-warehouse'.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.</span><br><span class="line">19/04/12 16:48:52 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint</span><br><span class="line">19/04/12 16:48:55 INFO CodeGenerator: Code generated in 2751.822246 ms</span><br><span class="line">19/04/12 16:52:26 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.8.83:53042) with ID 1</span><br><span class="line">19/04/12 16:52:30 INFO BlockManagerMasterEndpoint: Registering block manager hadoop03:45104 with 366.3 MB RAM, BlockManagerId(1, hadoop03, 45104, None)</span><br><span class="line">19/04/12 16:52:35 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.8.84:37146) with ID 2</span><br><span class="line">19/04/12 16:52:39 INFO BlockManagerMasterEndpoint: Registering block manager hadoop04:38267 with 366.3 MB RAM, BlockManagerId(2, hadoop04, 38267, None)</span><br><span class="line">19/04/12 16:53:38 INFO CodeGenerator: Code generated in 668.087005 ms</span><br><span class="line">19/04/12 16:53:45 INFO CodeGenerator: Code generated in 732.99189 ms</span><br><span class="line">19/04/12 16:53:47 INFO CodeGenerator: Code generated in 1265.744172 ms</span><br><span class="line">19/04/12 16:53:47 INFO CodeGenerator: Code generated in 271.771791 ms</span><br><span class="line">19/04/12 16:53:51 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Registering RDD 2 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Got job 0 (show at WindowFunctionTest.scala:45) with 1 output partitions</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Final stage: ResultStage 1 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:53:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.1 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:53:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.1 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:53:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hadoop04:42715 (size: 3.1 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:53:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:53:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(0, 1))</span><br><span class="line">19/04/12 16:53:55 INFO YarnScheduler: Adding task set 0.0 with 2 tasks</span><br><span class="line">19/04/12 16:53:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hadoop03, executor 1, partition 0, PROCESS_LOCAL, 8230 bytes)</span><br><span class="line">19/04/12 16:53:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hadoop04, executor 2, partition 1, PROCESS_LOCAL, 8230 bytes)</span><br><span class="line">19/04/12 16:55:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hadoop03:45104 (size: 3.1 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:55:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hadoop04:38267 (size: 3.1 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 137230 ms on hadoop03 (executor 1) (1/2)</span><br><span class="line">19/04/12 16:56:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 147247 ms on hadoop04 (executor 2) (2/2)</span><br><span class="line">19/04/12 16:56:24 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: ShuffleMapStage 0 (show at WindowFunctionTest.scala:45) finished in 151.743 s</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: looking for newly runnable stages</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: running: Set()</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: waiting: Set(ResultStage 1)</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: failed: Set()</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.4 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:56:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:56:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(0))</span><br><span class="line">19/04/12 16:56:25 INFO YarnScheduler: Adding task set 1.0 with 1 tasks</span><br><span class="line">19/04/12 16:56:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hadoop03, executor 1, partition 0, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.8.83:53042</span><br><span class="line">19/04/12 16:56:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 2345 ms on hadoop03 (executor 1) (1/1)</span><br><span class="line">19/04/12 16:56:27 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:27 INFO DAGScheduler: ResultStage 1 (show at WindowFunctionTest.scala:45) finished in 3.127 s</span><br><span class="line">19/04/12 16:56:27 INFO DAGScheduler: Job 0 finished: show at WindowFunctionTest.scala:45, took 156.360095 s</span><br><span class="line">19/04/12 16:56:28 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Got job 1 (show at WindowFunctionTest.scala:45) with 4 output partitions</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Final stage: ResultStage 3 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(1, 2, 3, 4))</span><br><span class="line">19/04/12 16:56:28 INFO YarnScheduler: Adding task set 3.0 with 4 tasks</span><br><span class="line">19/04/12 16:56:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, hadoop04, executor 2, partition 1, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:28 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, hadoop03, executor 1, partition 2, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5, hadoop03, executor 1, partition 3, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 447 ms on hadoop03 (executor 1) (1/4)</span><br><span class="line">19/04/12 16:56:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6, hadoop03, executor 1, partition 4, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 290 ms on hadoop03 (executor 1) (2/4)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 334 ms on hadoop03 (executor 1) (3/4)</span><br><span class="line">19/04/12 16:56:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.8.84:37146</span><br><span class="line">19/04/12 16:56:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 3241 ms on hadoop04 (executor 2) (4/4)</span><br><span class="line">19/04/12 16:56:31 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:31 INFO DAGScheduler: ResultStage 3 (show at WindowFunctionTest.scala:45) finished in 3.803 s</span><br><span class="line">19/04/12 16:56:31 INFO DAGScheduler: Job 1 finished: show at WindowFunctionTest.scala:45, took 3.848347 s</span><br><span class="line">19/04/12 16:56:32 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Got job 2 (show at WindowFunctionTest.scala:45) with 20 output partitions</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Final stage: ResultStage 5 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Submitting 20 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))</span><br><span class="line">19/04/12 16:56:32 INFO YarnScheduler: Adding task set 5.0 with 20 tasks</span><br><span class="line">19/04/12 16:56:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7, hadoop03, executor 1, partition 5, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:32 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8, hadoop04, executor 2, partition 6, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 9, hadoop04, executor 2, partition 7, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 726 ms on hadoop04 (executor 2) (1/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 10, hadoop03, executor 1, partition 8, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 811 ms on hadoop03 (executor 1) (2/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 11, hadoop03, executor 1, partition 9, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 10) in 393 ms on hadoop03 (executor 1) (3/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 12, hadoop04, executor 2, partition 10, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 9) in 523 ms on hadoop04 (executor 2) (4/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 13, hadoop03, executor 1, partition 11, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 11) in 317 ms on hadoop03 (executor 1) (5/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 14, hadoop03, executor 1, partition 12, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 15, hadoop03, executor 1, partition 13, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 13) in 851 ms on hadoop03 (executor 1) (6/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 14) in 541 ms on hadoop03 (executor 1) (7/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 16, hadoop04, executor 2, partition 14, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 12) in 1219 ms on hadoop04 (executor 2) (8/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 17, hadoop04, executor 2, partition 15, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 18, hadoop03, executor 1, partition 16, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 16) in 313 ms on hadoop04 (executor 2) (9/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 15) in 596 ms on hadoop03 (executor 1) (10/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 19, hadoop04, executor 2, partition 17, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 20, hadoop03, executor 1, partition 18, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 18) in 158 ms on hadoop03 (executor 1) (11/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 17) in 167 ms on hadoop04 (executor 2) (12/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 21, hadoop03, executor 1, partition 19, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 22, hadoop04, executor 2, partition 20, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 20) in 250 ms on hadoop03 (executor 1) (13/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 19) in 343 ms on hadoop04 (executor 2) (14/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 23, hadoop04, executor 2, partition 21, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 22) in 247 ms on hadoop04 (executor 2) (15/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 24, hadoop03, executor 1, partition 22, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 21) in 481 ms on hadoop03 (executor 1) (16/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 25, hadoop04, executor 2, partition 23, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 23) in 393 ms on hadoop04 (executor 2) (17/20)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 26, hadoop04, executor 2, partition 24, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 25) in 473 ms on hadoop04 (executor 2) (18/20)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 24) in 898 ms on hadoop03 (executor 1) (19/20)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 26) in 524 ms on hadoop04 (executor 2) (20/20)</span><br><span class="line">19/04/12 16:56:36 INFO YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:36 INFO DAGScheduler: ResultStage 5 (show at WindowFunctionTest.scala:45) finished in 4.493 s</span><br><span class="line">19/04/12 16:56:36 INFO DAGScheduler: Job 2 finished: show at WindowFunctionTest.scala:45, took 4.566402 s</span><br><span class="line">19/04/12 16:56:37 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Got job 3 (show at WindowFunctionTest.scala:45) with 100 output partitions</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Final stage: ResultStage 7 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Submitting 100 missing tasks from ResultStage 7 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))</span><br><span class="line">19/04/12 16:56:37 INFO YarnScheduler: Adding task set 7.0 with 100 tasks</span><br><span class="line">19/04/12 16:56:37 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 27, hadoop04, executor 2, partition 110, NODE_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:37 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 28, hadoop03, executor 1, partition 102, NODE_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 29, hadoop04, executor 2, partition 25, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:39 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 27) in 1607 ms on hadoop04 (executor 2) (1/100)</span><br><span class="line">19/04/12 16:56:39 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 30, hadoop04, executor 2, partition 26, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 31, hadoop04, executor 2, partition 27, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 29) in 1083 ms on hadoop04 (executor 2) (2/100)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 30) in 659 ms on hadoop04 (executor 2) (3/100)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 32, hadoop04, executor 2, partition 28, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 31) in 473 ms on hadoop04 (executor 2) (4/100)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 33, hadoop04, executor 2, partition 29, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 34, hadoop03, executor 1, partition 30, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 28) in 3578 ms on hadoop03 (executor 1) (5/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 32) in 505 ms on hadoop04 (executor 2) (6/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 35, hadoop04, executor 2, partition 31, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 33) in 438 ms on hadoop04 (executor 2) (7/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 36, hadoop03, executor 1, partition 32, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 37, hadoop04, executor 2, partition 33, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 35) in 353 ms on hadoop04 (executor 2) (8/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 34) in 583 ms on hadoop03 (executor 1) (9/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 38, hadoop03, executor 1, partition 34, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 36) in 301 ms on hadoop03 (executor 1) (10/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 39, hadoop03, executor 1, partition 35, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 40, hadoop04, executor 2, partition 36, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 38) in 453 ms on hadoop03 (executor 1) (11/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 41, hadoop04, executor 2, partition 37, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 37) in 1017 ms on hadoop04 (executor 2) (12/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 42, hadoop03, executor 1, partition 38, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 39) in 407 ms on hadoop03 (executor 1) (13/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 40) in 486 ms on hadoop04 (executor 2) (14/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 43, hadoop04, executor 2, partition 39, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 41) in 259 ms on hadoop04 (executor 2) (15/100)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 44, hadoop04, executor 2, partition 40, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 43) in 472 ms on hadoop04 (executor 2) (16/100)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 45, hadoop03, executor 1, partition 41, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 42) in 964 ms on hadoop03 (executor 1) (17/100)</span><br><span class="line">19/04/12 16:56:45 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 46, hadoop03, executor 1, partition 42, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 47, hadoop04, executor 2, partition 43, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 44) in 2989 ms on hadoop04 (executor 2) (18/100)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 45) in 3210 ms on hadoop03 (executor 1) (19/100)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 48, hadoop03, executor 1, partition 44, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 46) in 1507 ms on hadoop03 (executor 1) (20/100)</span><br><span class="line">19/04/12 16:56:47 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 49, hadoop04, executor 2, partition 45, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:47 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 47) in 1533 ms on hadoop04 (executor 2) (21/100)</span><br><span class="line">19/04/12 16:56:48 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 50, hadoop04, executor 2, partition 46, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:48 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 49) in 715 ms on hadoop04 (executor 2) (22/100)</span><br><span class="line">19/04/12 16:56:48 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 51, hadoop03, executor 1, partition 47, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 48) in 2132 ms on hadoop03 (executor 1) (23/100)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 52, hadoop04, executor 2, partition 48, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 50) in 1332 ms on hadoop04 (executor 2) (24/100)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 53, hadoop03, executor 1, partition 49, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 51) in 776 ms on hadoop03 (executor 1) (25/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 54, hadoop04, executor 2, partition 50, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 52) in 1066 ms on hadoop04 (executor 2) (26/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 55, hadoop03, executor 1, partition 51, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 53) in 698 ms on hadoop03 (executor 1) (27/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 56, hadoop04, executor 2, partition 52, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 54) in 679 ms on hadoop04 (executor 2) (28/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 57, hadoop03, executor 1, partition 53, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 55) in 1082 ms on hadoop03 (executor 1) (29/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 58, hadoop04, executor 2, partition 54, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 56) in 731 ms on hadoop04 (executor 2) (30/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 59, hadoop03, executor 1, partition 55, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 57) in 592 ms on hadoop03 (executor 1) (31/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 60, hadoop04, executor 2, partition 56, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 58) in 557 ms on hadoop04 (executor 2) (32/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 61, hadoop03, executor 1, partition 57, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 59) in 468 ms on hadoop03 (executor 1) (33/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 62, hadoop04, executor 2, partition 58, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 60) in 241 ms on hadoop04 (executor 2) (34/100)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 63, hadoop04, executor 2, partition 59, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 62) in 728 ms on hadoop04 (executor 2) (35/100)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 64, hadoop03, executor 1, partition 60, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 61) in 804 ms on hadoop03 (executor 1) (36/100)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 65, hadoop04, executor 2, partition 61, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 63) in 392 ms on hadoop04 (executor 2) (37/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 66, hadoop03, executor 1, partition 62, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 64) in 320 ms on hadoop03 (executor 1) (38/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 67, hadoop04, executor 2, partition 63, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 65) in 154 ms on hadoop04 (executor 2) (39/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 68, hadoop03, executor 1, partition 64, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 66) in 297 ms on hadoop03 (executor 1) (40/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 69, hadoop03, executor 1, partition 65, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 68) in 463 ms on hadoop03 (executor 1) (41/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 70, hadoop04, executor 2, partition 66, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 67) in 672 ms on hadoop04 (executor 2) (42/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 71, hadoop03, executor 1, partition 67, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 69) in 165 ms on hadoop03 (executor 1) (43/100)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 72, hadoop03, executor 1, partition 68, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 71) in 1656 ms on hadoop03 (executor 1) (44/100)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 73, hadoop03, executor 1, partition 69, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 72) in 534 ms on hadoop03 (executor 1) (45/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 74, hadoop03, executor 1, partition 70, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 73) in 376 ms on hadoop03 (executor 1) (46/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 75, hadoop04, executor 2, partition 71, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 70) in 2844 ms on hadoop04 (executor 2) (47/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 76, hadoop03, executor 1, partition 72, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 74) in 444 ms on hadoop03 (executor 1) (48/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 77, hadoop03, executor 1, partition 73, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 76) in 341 ms on hadoop03 (executor 1) (49/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 78, hadoop03, executor 1, partition 74, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 77) in 169 ms on hadoop03 (executor 1) (50/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 79, hadoop03, executor 1, partition 75, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 78) in 193 ms on hadoop03 (executor 1) (51/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 80, hadoop04, executor 2, partition 76, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 75) in 1174 ms on hadoop04 (executor 2) (52/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 81, hadoop03, executor 1, partition 77, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 82, hadoop04, executor 2, partition 78, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 79) in 337 ms on hadoop03 (executor 1) (53/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 80) in 310 ms on hadoop04 (executor 2) (54/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 83, hadoop03, executor 1, partition 79, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 81) in 761 ms on hadoop03 (executor 1) (55/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 84, hadoop04, executor 2, partition 80, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 82) in 696 ms on hadoop04 (executor 2) (56/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 85, hadoop03, executor 1, partition 81, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 83) in 691 ms on hadoop03 (executor 1) (57/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 86, hadoop03, executor 1, partition 82, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 85) in 118 ms on hadoop03 (executor 1) (58/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 87, hadoop04, executor 2, partition 83, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 84) in 447 ms on hadoop04 (executor 2) (59/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 88, hadoop03, executor 1, partition 84, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 86) in 240 ms on hadoop03 (executor 1) (60/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 89, hadoop04, executor 2, partition 85, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 87) in 325 ms on hadoop04 (executor 2) (61/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 90, hadoop03, executor 1, partition 86, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 88) in 255 ms on hadoop03 (executor 1) (62/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 91, hadoop04, executor 2, partition 87, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 89) in 147 ms on hadoop04 (executor 2) (63/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 92, hadoop03, executor 1, partition 88, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 90) in 130 ms on hadoop03 (executor 1) (64/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 93, hadoop03, executor 1, partition 89, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 92) in 110 ms on hadoop03 (executor 1) (65/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 94, hadoop04, executor 2, partition 90, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 91) in 264 ms on hadoop04 (executor 2) (66/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 95, hadoop03, executor 1, partition 91, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 93) in 165 ms on hadoop03 (executor 1) (67/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 96, hadoop04, executor 2, partition 92, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 94) in 267 ms on hadoop04 (executor 2) (68/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 97, hadoop03, executor 1, partition 93, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 95) in 222 ms on hadoop03 (executor 1) (69/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 98, hadoop04, executor 2, partition 94, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 96) in 191 ms on hadoop04 (executor 2) (70/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 99, hadoop03, executor 1, partition 95, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 97) in 173 ms on hadoop03 (executor 1) (71/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 100, hadoop04, executor 2, partition 96, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 98) in 165 ms on hadoop04 (executor 2) (72/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 101, hadoop03, executor 1, partition 97, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 99) in 181 ms on hadoop03 (executor 1) (73/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 102, hadoop04, executor 2, partition 98, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 100) in 176 ms on hadoop04 (executor 2) (74/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 103, hadoop04, executor 2, partition 99, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 102) in 103 ms on hadoop04 (executor 2) (75/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 104, hadoop03, executor 1, partition 100, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 101) in 202 ms on hadoop03 (executor 1) (76/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 105, hadoop04, executor 2, partition 101, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 103) in 159 ms on hadoop04 (executor 2) (77/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 106, hadoop04, executor 2, partition 103, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 105) in 378 ms on hadoop04 (executor 2) (78/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 107, hadoop03, executor 1, partition 104, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 104) in 551 ms on hadoop03 (executor 1) (79/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 108, hadoop04, executor 2, partition 105, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 106) in 437 ms on hadoop04 (executor 2) (80/100)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 109, hadoop03, executor 1, partition 106, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 107) in 621 ms on hadoop03 (executor 1) (81/100)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 110, hadoop04, executor 2, partition 107, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 108) in 1254 ms on hadoop04 (executor 2) (82/100)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 111, hadoop03, executor 1, partition 108, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 109) in 1316 ms on hadoop03 (executor 1) (83/100)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 112, hadoop04, executor 2, partition 109, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 110) in 793 ms on hadoop04 (executor 2) (84/100)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 113, hadoop03, executor 1, partition 111, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 111) in 780 ms on hadoop03 (executor 1) (85/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 114, hadoop04, executor 2, partition 112, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 112) in 567 ms on hadoop04 (executor 2) (86/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 115, hadoop03, executor 1, partition 113, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 113) in 689 ms on hadoop03 (executor 1) (87/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 116, hadoop04, executor 2, partition 114, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 114) in 513 ms on hadoop04 (executor 2) (88/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 117, hadoop03, executor 1, partition 115, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 115) in 432 ms on hadoop03 (executor 1) (89/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 118, hadoop04, executor 2, partition 116, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 116) in 271 ms on hadoop04 (executor 2) (90/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 119, hadoop03, executor 1, partition 117, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 120, hadoop04, executor 2, partition 118, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 118) in 129 ms on hadoop04 (executor 2) (91/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 117) in 173 ms on hadoop03 (executor 1) (92/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 121, hadoop04, executor 2, partition 119, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 120) in 139 ms on hadoop04 (executor 2) (93/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 122, hadoop03, executor 1, partition 120, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 119) in 232 ms on hadoop03 (executor 1) (94/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 123, hadoop04, executor 2, partition 121, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 121) in 110 ms on hadoop04 (executor 2) (95/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 124, hadoop03, executor 1, partition 122, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 122) in 115 ms on hadoop03 (executor 1) (96/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 125, hadoop04, executor 2, partition 123, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 123) in 136 ms on hadoop04 (executor 2) (97/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 126, hadoop03, executor 1, partition 124, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 124) in 124 ms on hadoop03 (executor 1) (98/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 125) in 140 ms on hadoop04 (executor 2) (99/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 126) in 145 ms on hadoop03 (executor 1) (100/100)</span><br><span class="line">19/04/12 16:57:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:57:04 INFO DAGScheduler: ResultStage 7 (show at WindowFunctionTest.scala:45) finished in 26.819 s</span><br><span class="line">19/04/12 16:57:04 INFO DAGScheduler: Job 3 finished: show at WindowFunctionTest.scala:45, took 27.209729 s</span><br><span class="line">19/04/12 16:57:05 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Got job 4 (show at WindowFunctionTest.scala:45) with 75 output partitions</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Final stage: ResultStage 9 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:57:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:57:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:57:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:57:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Submitting 75 missing tasks from ResultStage 9 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139))</span><br><span class="line">19/04/12 16:57:05 INFO YarnScheduler: Adding task set 9.0 with 75 tasks</span><br><span class="line">19/04/12 16:57:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 127, hadoop04, executor 2, partition 125, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:05 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 128, hadoop03, executor 1, partition 126, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 129, hadoop04, executor 2, partition 127, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 127) in 398 ms on hadoop04 (executor 2) (1/75)</span><br><span class="line">19/04/12 16:57:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 130, hadoop04, executor 2, partition 128, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 129) in 259 ms on hadoop04 (executor 2) (2/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 131, hadoop03, executor 1, partition 129, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 128) in 796 ms on hadoop03 (executor 1) (3/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 132, hadoop04, executor 2, partition 130, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 130) in 277 ms on hadoop04 (executor 2) (4/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 133, hadoop03, executor 1, partition 131, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 131) in 188 ms on hadoop03 (executor 1) (5/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 134, hadoop03, executor 1, partition 132, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 133) in 173 ms on hadoop03 (executor 1) (6/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 135, hadoop04, executor 2, partition 133, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 132) in 289 ms on hadoop04 (executor 2) (7/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 136, hadoop03, executor 1, partition 134, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 134) in 206 ms on hadoop03 (executor 1) (8/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 137, hadoop04, executor 2, partition 135, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 135) in 187 ms on hadoop04 (executor 2) (9/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 138, hadoop03, executor 1, partition 136, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 139, hadoop04, executor 2, partition 137, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 136) in 218 ms on hadoop03 (executor 1) (10/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 140, hadoop03, executor 1, partition 138, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 138) in 102 ms on hadoop03 (executor 1) (11/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 137) in 232 ms on hadoop04 (executor 2) (12/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 141, hadoop03, executor 1, partition 139, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 140) in 96 ms on hadoop03 (executor 1) (13/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 142, hadoop04, executor 2, partition 140, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 139) in 200 ms on hadoop04 (executor 2) (14/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 143, hadoop03, executor 1, partition 141, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 141) in 156 ms on hadoop03 (executor 1) (15/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 144, hadoop03, executor 1, partition 142, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 143) in 234 ms on hadoop03 (executor 1) (16/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 145, hadoop04, executor 2, partition 143, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 142) in 453 ms on hadoop04 (executor 2) (17/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 146, hadoop03, executor 1, partition 144, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 144) in 273 ms on hadoop03 (executor 1) (18/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 147, hadoop04, executor 2, partition 145, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 145) in 220 ms on hadoop04 (executor 2) (19/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 148, hadoop03, executor 1, partition 146, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 146) in 178 ms on hadoop03 (executor 1) (20/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 149, hadoop04, executor 2, partition 147, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 147) in 313 ms on hadoop04 (executor 2) (21/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 150, hadoop03, executor 1, partition 148, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 148) in 279 ms on hadoop03 (executor 1) (22/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 151, hadoop04, executor 2, partition 149, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 149) in 371 ms on hadoop04 (executor 2) (23/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 152, hadoop03, executor 1, partition 150, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 150) in 291 ms on hadoop03 (executor 1) (24/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 153, hadoop04, executor 2, partition 151, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 151) in 321 ms on hadoop04 (executor 2) (25/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 154, hadoop03, executor 1, partition 152, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 152) in 385 ms on hadoop03 (executor 1) (26/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 155, hadoop03, executor 1, partition 153, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 156, hadoop04, executor 2, partition 154, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 153) in 386 ms on hadoop04 (executor 2) (27/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 154) in 332 ms on hadoop03 (executor 1) (28/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 157, hadoop03, executor 1, partition 155, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 155) in 199 ms on hadoop03 (executor 1) (29/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 158, hadoop04, executor 2, partition 156, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 156) in 303 ms on hadoop04 (executor 2) (30/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 159, hadoop04, executor 2, partition 157, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 158) in 94 ms on hadoop04 (executor 2) (31/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 160, hadoop03, executor 1, partition 158, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 157) in 276 ms on hadoop03 (executor 1) (32/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 161, hadoop04, executor 2, partition 159, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 159) in 171 ms on hadoop04 (executor 2) (33/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 162, hadoop03, executor 1, partition 160, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 160) in 182 ms on hadoop03 (executor 1) (34/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 163, hadoop03, executor 1, partition 161, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 164, hadoop04, executor 2, partition 162, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 165, hadoop04, executor 2, partition 163, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 164) in 52 ms on hadoop04 (executor 2) (35/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 161) in 191 ms on hadoop04 (executor 2) (36/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 162) in 206 ms on hadoop03 (executor 1) (37/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 166, hadoop03, executor 1, partition 164, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 167, hadoop04, executor 2, partition 165, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 165) in 108 ms on hadoop04 (executor 2) (38/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 168, hadoop04, executor 2, partition 166, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 163) in 218 ms on hadoop03 (executor 1) (39/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 167) in 88 ms on hadoop04 (executor 2) (40/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 169, hadoop03, executor 1, partition 167, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 166) in 112 ms on hadoop03 (executor 1) (41/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 170, hadoop03, executor 1, partition 168, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 169) in 75 ms on hadoop03 (executor 1) (42/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 171, hadoop04, executor 2, partition 169, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 168) in 162 ms on hadoop04 (executor 2) (43/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 172, hadoop03, executor 1, partition 170, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 173, hadoop04, executor 2, partition 171, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 170) in 96 ms on hadoop03 (executor 1) (44/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 174, hadoop03, executor 1, partition 172, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 171) in 75 ms on hadoop04 (executor 2) (45/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 172) in 49 ms on hadoop03 (executor 1) (46/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 175, hadoop03, executor 1, partition 173, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 174) in 85 ms on hadoop03 (executor 1) (47/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 176, hadoop04, executor 2, partition 174, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 177, hadoop03, executor 1, partition 175, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 178, hadoop03, executor 1, partition 176, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 177) in 38 ms on hadoop03 (executor 1) (48/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 173) in 141 ms on hadoop04 (executor 2) (49/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 179, hadoop03, executor 1, partition 177, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 175) in 123 ms on hadoop03 (executor 1) (50/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 178) in 57 ms on hadoop03 (executor 1) (51/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 180, hadoop04, executor 2, partition 178, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 176) in 114 ms on hadoop04 (executor 2) (52/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 181, hadoop03, executor 1, partition 179, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 182, hadoop03, executor 1, partition 180, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 183, hadoop04, executor 2, partition 181, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 179) in 159 ms on hadoop03 (executor 1) (53/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 184, hadoop03, executor 1, partition 182, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 181) in 110 ms on hadoop03 (executor 1) (54/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 185, hadoop04, executor 2, partition 183, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 180) in 165 ms on hadoop04 (executor 2) (55/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 182) in 262 ms on hadoop03 (executor 1) (56/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 186, hadoop03, executor 1, partition 184, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 187, hadoop04, executor 2, partition 185, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 183) in 331 ms on hadoop04 (executor 2) (57/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 184) in 301 ms on hadoop03 (executor 1) (58/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 185) in 289 ms on hadoop04 (executor 2) (59/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 188, hadoop03, executor 1, partition 186, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 186) in 151 ms on hadoop03 (executor 1) (60/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 189, hadoop04, executor 2, partition 187, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 187) in 197 ms on hadoop04 (executor 2) (61/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 190, hadoop03, executor 1, partition 188, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 188) in 114 ms on hadoop03 (executor 1) (62/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 191, hadoop04, executor 2, partition 189, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 189) in 148 ms on hadoop04 (executor 2) (63/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 192, hadoop03, executor 1, partition 190, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 190) in 113 ms on hadoop03 (executor 1) (64/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 193, hadoop03, executor 1, partition 191, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 194, hadoop04, executor 2, partition 192, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 191) in 129 ms on hadoop04 (executor 2) (65/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 192) in 105 ms on hadoop03 (executor 1) (66/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 195, hadoop03, executor 1, partition 193, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 193) in 126 ms on hadoop03 (executor 1) (67/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 196, hadoop04, executor 2, partition 194, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 194) in 131 ms on hadoop04 (executor 2) (68/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 197, hadoop04, executor 2, partition 195, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 196) in 217 ms on hadoop04 (executor 2) (69/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 198, hadoop03, executor 1, partition 196, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 195) in 301 ms on hadoop03 (executor 1) (70/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 199, hadoop04, executor 2, partition 197, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 197) in 270 ms on hadoop04 (executor 2) (71/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 200, hadoop03, executor 1, partition 198, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 198) in 256 ms on hadoop03 (executor 1) (72/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 201, hadoop04, executor 2, partition 199, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 199) in 282 ms on hadoop04 (executor 2) (73/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 200) in 214 ms on hadoop03 (executor 1) (74/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 201) in 104 ms on hadoop04 (executor 2) (75/75)</span><br><span class="line">19/04/12 16:57:11 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:57:11 INFO DAGScheduler: ResultStage 9 (show at WindowFunctionTest.scala:45) finished in 6.626 s</span><br><span class="line">19/04/12 16:57:11 INFO DAGScheduler: Job 4 finished: show at WindowFunctionTest.scala:45, took 6.700226 s</span><br><span class="line">19/04/12 16:57:14 INFO SparkUI: Stopped Spark web UI at http://hadoop04:4040</span><br><span class="line">19/04/12 16:57:14 INFO YarnClientSchedulerBackend: Interrupting monitor thread</span><br><span class="line">19/04/12 16:57:15 INFO YarnClientSchedulerBackend: Shutting down all executors</span><br><span class="line">19/04/12 16:57:15 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down</span><br><span class="line">19/04/12 16:57:15 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices</span><br><span class="line">(serviceOption=None,</span><br><span class="line"> services=List(),</span><br><span class="line"> started=false)</span><br><span class="line">19/04/12 16:57:15 INFO YarnClientSchedulerBackend: Stopped</span><br><span class="line">19/04/12 16:57:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span><br><span class="line">19/04/12 16:57:17 INFO MemoryStore: MemoryStore cleared</span><br><span class="line">19/04/12 16:57:17 INFO BlockManager: BlockManager stopped</span><br><span class="line">19/04/12 16:57:17 INFO BlockManagerMaster: BlockManagerMaster stopped</span><br><span class="line">19/04/12 16:57:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span><br><span class="line">19/04/12 16:57:18 INFO SparkContext: Successfully stopped SparkContext</span><br><span class="line">19/04/12 16:57:19 INFO ShutdownHookManager: Shutdown hook called</span><br><span class="line">19/04/12 16:57:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-f3533ae6-b45b-4a1f-8119-0c12775c5a33</span><br><span class="line">+-----+----------+--------+---------+</span><br><span class="line">| site|      date|user_cnt|MovingAvg|</span><br><span class="line">+-----+----------+--------+---------+</span><br><span class="line">|站点1|2018-01-01|      50|     47.5|</span><br><span class="line">|站点1|2018-01-02|      45|     50.0|</span><br><span class="line">|站点1|2018-01-03|      55|     50.0|</span><br><span class="line">|站点2|2018-01-01|      25|     27.0|</span><br><span class="line">|站点2|2018-01-02|      29|     27.0|</span><br><span class="line">|站点2|2018-01-03|      27|     28.0|</span><br><span class="line">+-----+----------+--------+---------+</span><br><span class="line"></span><br><span class="line">Disconnected from the target VM, address: '127.0.0.1:45315', transport: 'socket'</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>至此,IDEA已经能连接上yarn集群。</p>
<h1 id="开启远程yarn-client-debug调试"><a href="#开启远程yarn-client-debug调试" class="headerlink" title="开启远程yarn client debug调试"></a>开启远程yarn client debug调试</h1><h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p>将我们的应用程序打包(在hadoop05机器)，发送到hadoop01机器，并在hadoop01上启动我们的应用程序,具体如下：  </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/hadoop/worker/sparklearning/target/   </span><br><span class="line"></span><br><span class="line">scp -r sparklearning-1.0-SNAPSHOT.jar  hadoop@hadoop01:/home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT.jar   </span><br><span class="line"></span><br><span class="line">scp -r sparklearning-1.0-SNAPSHOT.jar  hadoop@hadoop01:/home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT-jar-with-dependencies.jar</span><br></pre></td></tr></table></figure>
<p><strong>在hadoop01启动</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --class com.xh.spark.sql.function.WindowFunctionTest \</span><br><span class="line">    --master yarn \</span><br><span class="line">    --deploy-mode client \</span><br><span class="line">    --driver-memory 512m \</span><br><span class="line">    --executor-memory 512m \</span><br><span class="line">    --executor-cores 6 \</span><br><span class="line">	--driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005" \</span><br><span class="line">    /home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure></p>
<h2 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h2><p>在idea中Edit Configurations ——&gt; 点击+号 ——&gt;Remote —— Configuration ——&gt; Debugger Mode (用Attach to remote JVM)——&gt;host(hadoop01)<br>——&gt; Port(默认5005，也可以选择使用未使用的端口，比如5656) ——&gt; Command line arguments for remote JVN (-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005)</p>
<p>然后点击小虫子图标就可以run程序了！！！！</p>
<h1 id="问题解决分享"><a href="#问题解决分享" class="headerlink" title="问题解决分享"></a>问题解决分享</h1><h2 id="Could-not-parse-Master-URL"><a href="#Could-not-parse-Master-URL" class="headerlink" title="Could not parse Master URL"></a>Could not parse Master URL</h2><p><strong>解决：</strong> 在pom.xml中添加如下依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-yarn_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Name-node-is-in-safe-mode"><a href="#Name-node-is-in-safe-mode" class="headerlink" title="Name node is in safe mode"></a>Name node is in safe mode</h2><p><strong>解决：</strong>  在hadoop所在linux环境输入如下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode leave</span><br></pre></td></tr></table></figure></p>
<h2 id="Exception-in-thread-“main”-org-apache-hadoop-security-AccessControlException"><a href="#Exception-in-thread-“main”-org-apache-hadoop-security-AccessControlException" class="headerlink" title="Exception in thread “main” org.apache.hadoop.security.AccessControlException:"></a>Exception in thread “main” org.apache.hadoop.security.AccessControlException:</h2><blockquote>
<p>Exception in thread “main” org.apache.hadoop.security.AccessControlException: Permission denied: user=deeplearning, access=WRITE, inode=”/user/deeplearning/.sparkStaging/application_1554947367832_0002”:hadoop:supergroup:drwxr-xr-x</p>
</blockquote>
<p><strong>解决：</strong>  在hdfs-site.xml添加如下配置<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Diagnostics-Container-pid-3293-containerID-container-e12-1555047553207-0002-02-000001-is-running-beyond-virtual-memory-limits-Current-usage-116-1-MB-of-1-GB-physical-memory-used-2-3-GB-of-2-1-GB-virtual-memory-used-Killing-container"><a href="#Diagnostics-Container-pid-3293-containerID-container-e12-1555047553207-0002-02-000001-is-running-beyond-virtual-memory-limits-Current-usage-116-1-MB-of-1-GB-physical-memory-used-2-3-GB-of-2-1-GB-virtual-memory-used-Killing-container" class="headerlink" title="Diagnostics: Container [pid=3293,containerID=container_e12_1555047553207_0002_02_000001] is running beyond virtual memory limits. Current usage: 116.1 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container."></a>Diagnostics: Container [pid=3293,containerID=container_e12_1555047553207_0002_02_000001] is running beyond virtual memory limits. Current usage: 116.1 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container.</h2><p><strong>解决：</strong> 在yarn-site.xml文件中添加如下配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;5&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="问题解决参考文章"><a href="#问题解决参考文章" class="headerlink" title="问题解决参考文章"></a>问题解决参考文章</h2><p><a href="https://stackoverflow.com/questions/41054700/could-not-parse-master-url" target="_blank" rel="noopener">https://stackoverflow.com/questions/41054700/could-not-parse-master-url</a></p>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a></p>
<p><a href="http://www.cnblogs.com/lisi2016/p/6863923.html" target="_blank" rel="noopener">http://www.cnblogs.com/lisi2016/p/6863923.html</a>  </p>
<h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢!"></a>致谢!</h1><p>如有遇到问题，将问题发送至本人邮箱(<a href="mailto:t_spider@aliyun.com" target="_blank" rel="noopener">t_spider@aliyun.com</a>)。欢迎大家一起讨论问题！</p>

      
    </div>
    
    
    
     <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

  <!-- JS库 sweetalert 可修改路径 -->
  <script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script>
  <script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script>
  <link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css">
  <p><span>本文标题:</span><a href="/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/">idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 tang 的个人博客">tang</a></p>
  <p><span>发布时间:</span>2019年04月14日 - 23:04</p>
  <p><span>最后更新:</span>2019年04月14日 - 23:04</p>
  <p><span>原始链接:</span><a href="/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/" title="idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)">https://tgluon.github.io/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/</a>
    <span class="copy-path"  title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://tgluon.github.io/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/"  aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    clipboard.on('success', $(function(){
      $(".fa-clipboard").click(function(){
        swal({   
          title: "",   
          text: '复制成功',   
          html: false,
          timer: 500,   
          showConfirmButton: false
        });
      });
    }));  
</script>


      
     </div>
     <div>
     
     <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>


     
    </div>

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag"><i class="fa fa-tag"></i> spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/10/spark sql实战案例/" rel="next" title="sparksql实战案例">
                <i class="fa fa-chevron-left"></i> sparksql实战案例
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/15/spark sql窗口函数实战/" rel="prev" title="spark sql窗口函数实战">
                spark sql窗口函数实战 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_fav">收藏夹</a>
<a class="jiathis_button_copy">复制网址</a>
<a class="jiathis_button_email">邮件</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_qzone">QQ空间</a>
<a class="jiathis_button_tqq">腾讯微博</a>
<a class="jiathis_button_douban">豆瓣</a>
<a class="jiathis_button_share">一键分享</a>

<a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
var jiathis_config={
  data_track_clickback:true,
  summary:"",
  shortUrl:false,
  hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  




        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="tang" />
            
              <p class="site-author-name" itemprop="name">tang</p>
              <p class="site-description motion-element" itemprop="description">火星度假村追梦程序员。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/tgluon" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i></a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#背景"><span class="nav-number">1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#环境"><span class="nav-number">2.</span> <span class="nav-text">环境</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#maven项目中resources目录中配置文件"><span class="nav-number">3.</span> <span class="nav-text">maven项目中resources目录中配置文件</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#maven-pom配置文件"><span class="nav-number">4.</span> <span class="nav-text">maven pom配置文件</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#开发程序"><span class="nav-number">5.</span> <span class="nav-text">开发程序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#执行结果如下"><span class="nav-number">6.</span> <span class="nav-text">执行结果如下</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#开启远程yarn-client-debug调试"><span class="nav-number">7.</span> <span class="nav-text">开启远程yarn client debug调试</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#第一步"><span class="nav-number">7.1.</span> <span class="nav-text">第一步</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第二步"><span class="nav-number">7.2.</span> <span class="nav-text">第二步</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#问题解决分享"><span class="nav-number">8.</span> <span class="nav-text">问题解决分享</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Could-not-parse-Master-URL"><span class="nav-number">8.1.</span> <span class="nav-text">Could not parse Master URL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Name-node-is-in-safe-mode"><span class="nav-number">8.2.</span> <span class="nav-text">Name node is in safe mode</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Exception-in-thread-“main”-org-apache-hadoop-security-AccessControlException"><span class="nav-number">8.3.</span> <span class="nav-text">Exception in thread “main” org.apache.hadoop.security.AccessControlException:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Diagnostics-Container-pid-3293-containerID-container-e12-1555047553207-0002-02-000001-is-running-beyond-virtual-memory-limits-Current-usage-116-1-MB-of-1-GB-physical-memory-used-2-3-GB-of-2-1-GB-virtual-memory-used-Killing-container"><span class="nav-number">8.4.</span> <span class="nav-text">Diagnostics: Container [pid=3293,containerID=container_e12_1555047553207_0002_02_000001] is running beyond virtual memory limits. Current usage: 116.1 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#问题解决参考文章"><span class="nav-number">8.5.</span> <span class="nav-text">问题解决参考文章</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#致谢"><span class="nav-number">9.</span> <span class="nav-text">致谢!</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tang</span>

  
</div>


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
<span id="busuanzi_container_site_pv">
    本站总访问量:<span id="busuanzi_value_site_pv"></span>次
</span>
</div>
  
<!--<div class="powered-by">{
  }由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动{}</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">{
  }主题 &mdash; {
  }<a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">{
    }NexT.Pisces{
  }</a> v5.1.4{
}</div>
-->



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共54.0k字</span>
</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>


  
  <script type="text/javascript"
color="0,0,255" opacity='0.7' zIndex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  
  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://tgluon.github.io/2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/';
          this.page.identifier = '2019/04/14/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/';
          this.page.title = 'idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
<script type="text/javascript" src="/js/src/love.js"></script>
</html>
