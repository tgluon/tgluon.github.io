<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="blog" type="application/atom+xml" />






<meta name="description" content="火星度假村追梦程序员。">
<meta property="og:type" content="website">
<meta property="og:title" content="blog">
<meta property="og:url" content="https://tgluon.github.io/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="火星度假村追梦程序员。">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="blog">
<meta name="twitter:description" content="火星度假村追梦程序员。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tgluon.github.io/"/>





  <title>blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
    <a href="https://github.com/tgluon"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_orange_ff7600.png" alt="Fork me on GitHub"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">追梦青年</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/05/22/scala正则表达式实战/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/22/scala正则表达式实战/" itemprop="url">scala正则表达式实战</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-22T14:39:16+08:00">
                2019-05-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/scala/" itemprop="url" rel="index">
                    <span itemprop="name">scala</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/05/22/scala正则表达式实战/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/05/22/scala正则表达式实战/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  94
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="案例一"><a href="#案例一" class="headerlink" title="案例一"></a>案例一</h1><p><strong>说明</strong>：源码来自spark ConfigReader类<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">object</span> <span class="title">ConfigReader</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> <span class="type">REF_RE</span> = <span class="string">"\\$\\&#123;(?:(\\w+?):)?(\\S+?)\\&#125;"</span>.r</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">      <span class="type">ConfigReader</span>.<span class="type">REF_RE</span>.replaceAllIn(input, &#123; m =&gt;</span><br><span class="line">        <span class="keyword">val</span> prefix = m.group(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">val</span> name = m.group(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">val</span> ref = <span class="keyword">if</span> (prefix == <span class="literal">null</span>) name <span class="keyword">else</span> <span class="string">s"<span class="subst">$prefix</span>:<span class="subst">$name</span>"</span></span><br><span class="line">        require(!usedRefs.contains(ref), <span class="string">s"Circular reference in <span class="subst">$input</span>: <span class="subst">$ref</span>"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> replacement = bindings.get(prefix)</span><br><span class="line">          .flatMap(getOrDefault(_, name))</span><br><span class="line">          .map &#123; v =&gt; substitute(v, usedRefs + ref) &#125;</span><br><span class="line">          .getOrElse(m.matched)</span><br><span class="line">        <span class="type">Regex</span>.quoteReplacement(replacement)</span><br><span class="line">      &#125;)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/05/07/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/07/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/" itemprop="url">idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-07T23:55:25+08:00">
                2019-05-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/05/07/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/05/07/idea中Spark on yarn 远程Debug Spark 源码(Yarn Client+attach 模式)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  24,951
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  154
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>idea 中连接yarn集群debug spark代码,有利于定位线上问题。</p>
<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>默认你hadoop环境已经搞定情况下的说明！！！<br><strong>scala版本：</strong> 2.11.8<br><strong>jdk版本</strong>：JDK1.8<br><strong>hadoop版本：</strong> 2.7.3<br><strong>spark版本：</strong> 2.4.1<br><strong>zookeeper：</strong> 3.4.6<br><strong>高能预警：</strong> 一定要保持yarn集群机器scala版本和项目pom文件中scala版本一致。     </p>
<table>
<thead>
<tr>
<th>linux版本</th>
<th>IP</th>
<th>hostname</th>
<th>进程 </th>
</tr>
</thead>
<tbody>
<tr>
<td>centos7</td>
<td>192.168.8.81</td>
<td>hadoop01</td>
<td>NameNode、DFSZKFailoverController</td>
</tr>
<tr>
<td>centos7</td>
<td>192.168.8.82</td>
<td>hadoop02</td>
<td>NameNode、DFSZKFailoverController、ResourceManager、JournalNode、NodeManager、DataNode、QuorumPeerMain</td>
</tr>
<tr>
<td>centos7</td>
<td>192.168.8.83</td>
<td>hadoop03</td>
<td>JournalNode、NodeManager、DataNode、QuorumPeerMain</td>
</tr>
<tr>
<td>centos7</td>
<td>192.168.8.84</td>
<td>hadoop04</td>
<td>JournalNode、NodeManager、DataNode、QuorumPeerMain</td>
</tr>
</tbody>
</table>
<p><strong>idea所在机器：</strong>   </p>
<table>
<thead>
<tr>
<th>linux版本</th>
<th>IP</th>
<th>hostname</th>
</tr>
</thead>
<tbody>
<tr>
<td>ubuntu18.04</td>
<td>192.168.8.85</td>
<td>hadoop05</td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="maven项目中resources目录中配置文件"><a href="#maven项目中resources目录中配置文件" class="headerlink" title="maven项目中resources目录中配置文件"></a>maven项目中resources目录中配置文件</h1><p><strong>高能预警：</strong> 配置文件需要和hadoop集群一致</p>
<p><strong>具体配置文件如下：</strong><br>core-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hdfs的nameservice为ns1 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop临时目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定zookeeper地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:2181,hadoop03:2181,hadoop04:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>hdfs-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn1的RPC通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn1的http通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn2的RPC通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn2的http通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop02:8485;hadoop03:8485;hadoop04:8485/ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/journaldata<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启NameNode失败自动切换 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置失败自动切换实现方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">sshfence</span><br><span class="line">shell(/bin/true)</span><br><span class="line"><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置sshfence隔离机制超时时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.connect-timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--修改block块的大小,默认为128M--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.block.seze<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>128<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>yarn-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0"?&gt;</span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--开启RM高可用 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.embedded<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定RM的cluster id --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yrc<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定RM的名字 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 分别指定RM的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定zk集群地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:2181,hadoop03:2181,hadoop04:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop03:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.client.failover-proxy-provider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 两个可选值：org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore 以及 默认值org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop02:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.web-proxy.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>192.168.8.82:8089<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 打开日志聚合功能，这样才能从web界面查看日志 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 聚合日志最长保留时间 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>86400<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 中间结果存放位置。注意，这个参数通常会配置多个目录，已分摊磁盘IO负载。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/data/localdir1,/home/hadoop/hadoop/data/localdir2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 日志存放位置。注意，这个参数通常会配置多个目录，已分摊磁盘IO负载。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/data/hdfs/logdir1,/home/hadoop/hadoop/data/hdfs/logdir2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>spark-defaults.conf配置文件：</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Licensed to the Apache Software Foundation (ASF) under one or more</span><br><span class="line"># contributor license agreements.  See the NOTICE file distributed with</span><br><span class="line"># this work for additional information regarding copyright ownership.</span><br><span class="line"># The ASF licenses this file to You under the Apache License, Version 2.0</span><br><span class="line"># (the "License"); you may not use this file except in compliance with</span><br><span class="line"># the License.  You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an "AS IS" BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># Default system properties included when running spark-submit.</span><br><span class="line"># This is useful for setting default environmental settings.</span><br><span class="line">spark.driver.extraClassPath         /home/hadoop/spark/jars/*:/home/hadoop/hadoop/share/hadoop/hdfs/*:/home/hadoop/hadoop/share/hadoop/common/*:/home/hadoop/hadoop/share/hadoop/common/lib/*:/home/hadoop/hadoop/share/hadoop/yarn/*:/home/hadoop/hadoop/share/hadoop/yarn/lib/*</span><br><span class="line"></span><br><span class="line">spark.executor.extraClassPath     /home/hadoop/spark/jars/*:/home/hadoop/hadoop/share/hadoop/hdfs/*:/home/hadoop/hadoop/share/hadoop/common/*:/home/hadoop/hadoop/share/hadoop/common/lib/*:/home/hadoop/hadoop/share/hadoop/yarn/*:/home/hadoop/hadoop/share/hadoop/yarn/lib/*</span><br><span class="line">spark.driver.extraJavaOptions     -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005</span><br><span class="line">spark.executor.extraJavaOptions   -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005</span><br><span class="line">spark.driver.memory                512m</span><br><span class="line">spark.executor.memory              512m</span><br><span class="line"># Example:</span><br><span class="line"># spark.master                     spark://master:7077</span><br><span class="line"># spark.eventLog.enabled           true</span><br><span class="line"># spark.eventLog.dir               hdfs://namenode:8021/directory</span><br><span class="line"># spark.serializer                 org.apache.spark.serializer.KryoSerializer</span><br><span class="line"># spark.driver.memory              5g</span><br><span class="line"># spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"</span><br></pre></td></tr></table></figure></p>
<h1 id="maven-pom配置文件"><a href="#maven-pom配置文件" class="headerlink" title="maven pom配置文件"></a>maven pom配置文件</h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.xh.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>sparklearning<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.version</span>&gt;</span>2.11.8<span class="tag">&lt;/<span class="name">scala.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.binary.version</span>&gt;</span>2.11<span class="tag">&lt;/<span class="name">scala.binary.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spark.version</span>&gt;</span>2.4.1<span class="tag">&lt;/<span class="name">spark.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.7.3<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mysql.version</span>&gt;</span>5.1.35<span class="tag">&lt;/<span class="name">mysql.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hive.version</span>&gt;</span>2.3.3<span class="tag">&lt;/<span class="name">hive.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">guava.version</span>&gt;</span>26.0-jre<span class="tag">&lt;/<span class="name">guava.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">fastjson.version</span>&gt;</span>1.2.40<span class="tag">&lt;/<span class="name">fastjson.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">zookeeper.version</span>&gt;</span>3.4.6<span class="tag">&lt;/<span class="name">zookeeper.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--scala--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;zookeeper.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--spark--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-yarn_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-mllib_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-hive_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-10_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;fastjson.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--hive--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--hadoop--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--mysql--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;mysql.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--guava--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;guava.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- This plugin compiles Scala files --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.alchim31.maven<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>scala-compile-first<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>process-resources<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>add-source<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>scala-test-compile<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>process-test-resources<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- This plugin compiles Java files --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--跳过test begin--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.20<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">skipTests</span>&gt;</span>true<span class="tag">&lt;/<span class="name">skipTests</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- This plugin adds all dependencies to JAR file during 'package' command.</span></span><br><span class="line"><span class="comment">            Pay EXTRA attention to the 'mainClass' tag.</span></span><br><span class="line"><span class="comment">            You have to set name of class with entry point to program ('main' method) --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">manifestFile</span>&gt;</span><span class="tag">&lt;/<span class="name">manifestFile</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-shade-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>shade<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">filters</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">artifact</span>&gt;</span>*:*<span class="tag">&lt;/<span class="name">artifact</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.SF<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.DSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.RSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">filters</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">transformers</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">transformer</span></span></span><br><span class="line"><span class="tag">                                        <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.defonds.RsaEncryptor<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">transformer</span></span></span><br><span class="line"><span class="tag">                                        <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.AppendingTransformer"</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">resource</span>&gt;</span>META-INF/spring.handlers<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">transformer</span></span></span><br><span class="line"><span class="tag">                                        <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.AppendingTransformer"</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">resource</span>&gt;</span>META-INF/spring.schemas<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">transformers</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="开发程序"><a href="#开发程序" class="headerlink" title="开发程序"></a>开发程序</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xh.spark.sql.function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WindowFunctionTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      .setAppName(<span class="string">"WindowFunctionTest"</span>)</span><br><span class="line">          .set(<span class="string">"spark.master"</span>, <span class="string">"yarn"</span>)</span><br><span class="line">          .set(<span class="string">"spark.submit.deployMode"</span>, <span class="string">"client"</span>) <span class="comment">// 部署模式为client</span></span><br><span class="line">          .set(<span class="string">"yarn.resourcemanager.hostname"</span>, <span class="string">"hadoop02"</span>) <span class="comment">// resourcemanager主机名</span></span><br><span class="line">          .set(<span class="string">"spark.executor.instances"</span>, <span class="string">"2"</span>) <span class="comment">// Executor实例的数量</span></span><br><span class="line">          .set(<span class="string">"spark.dynamicAllocation.enabled"</span>, <span class="string">"false"</span>)</span><br><span class="line">          .setJars(<span class="type">List</span>(<span class="string">"/home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT.jar"</span>,</span><br><span class="line">            <span class="string">"/home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT-jar-with-dependencies.jar"</span></span><br><span class="line">          ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .config(sparkConf)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">val</span> df = <span class="type">List</span>(</span><br><span class="line">      (<span class="string">"站点1"</span>, <span class="string">"2018-01-01"</span>, <span class="number">50</span>),</span><br><span class="line">      (<span class="string">"站点1"</span>, <span class="string">"2018-01-02"</span>, <span class="number">45</span>),</span><br><span class="line">      (<span class="string">"站点1"</span>, <span class="string">"2018-01-03"</span>, <span class="number">55</span>),</span><br><span class="line">      (<span class="string">"站点2"</span>, <span class="string">"2018-01-01"</span>, <span class="number">25</span>),</span><br><span class="line">      (<span class="string">"站点2"</span>, <span class="string">"2018-01-02"</span>, <span class="number">29</span>),</span><br><span class="line">      (<span class="string">"站点2"</span>, <span class="string">"2018-01-03"</span>, <span class="number">27</span>)</span><br><span class="line">    ).toDF(<span class="string">"site"</span>, <span class="string">"date"</span>, <span class="string">"user_cnt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 简单移动平均值</span></span><br><span class="line">    <span class="comment">// API方式</span></span><br><span class="line">    <span class="comment">// 窗口定义从 -1(前一行)到 1(后一行)	，每一个滑动的窗口总用有3行</span></span><br><span class="line">    <span class="keyword">val</span> movinAvgSpec = <span class="type">Window</span>.partitionBy(<span class="string">"site"</span>).orderBy(<span class="string">"date"</span>).rowsBetween(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">    df.withColumn(<span class="string">"MovingAvg"</span>, avg(df(<span class="string">"user_cnt"</span>)).over(movinAvgSpec)).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sql方式</span></span><br><span class="line">     df.createOrReplaceTempView(<span class="string">"site_info"</span>)</span><br><span class="line">        spark.sql(</span><br><span class="line">          <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">            |select site,</span></span><br><span class="line"><span class="string">            |       date,</span></span><br><span class="line"><span class="string">            |       user_cnt,</span></span><br><span class="line"><span class="string">            |       avg(user_cnt) over(partition by site order by date rows between 1 preceding and 1 following) as moving_avg</span></span><br><span class="line"><span class="string">            |from   site_info</span></span><br><span class="line"><span class="string">          "</span><span class="string">""</span>.stripMargin).show()</span><br><span class="line">    </span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上确认无误之后，直接在idea里面run该程序。   </p>
<h1 id="执行结果如下"><a href="#执行结果如下" class="headerlink" title="执行结果如下"></a>执行结果如下</h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br></pre></td><td class="code"><pre><span class="line">/usr/lib/jvm/java-1.8.0-openjdk/bin/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:45315,suspend=y,server=n -javaagent:/home/hadoop/idea/lib/rt/debugger-agent.jar -Dfile.encoding=UTF-8 -classpath /usr/lib/jvm/java-1.8.0-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/cldrdata.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/dnsns.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/jaccess.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/localedata.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/nashorn.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/sunec.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/sunjce_provider.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/sunpkcs11.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext/zipfs.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/management-agent.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/rt.jar:/home/hadoop/worker/sparklearning/target/classes:/home/hadoop/repository/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar:/home/hadoop/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/repository/log4j/log4j/1.2.16/log4j-1.2.16.jar:/home/hadoop/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/hadoop/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/home/hadoop/repository/org/apache/spark/spark-yarn_2.11/2.4.1/spark-yarn_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-api/2.6.5/hadoop-yarn-api-2.6.5.jar:/home/hadoop/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-common/2.6.5/hadoop-yarn-common-2.6.5.jar:/home/hadoop/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/hadoop/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.6.5/hadoop-yarn-server-web-proxy-2.6.5.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-common/2.6.5/hadoop-yarn-server-common-2.6.5.jar:/home/hadoop/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-client/2.6.5/hadoop-yarn-client-2.6.5.jar:/home/hadoop/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/hadoop/repository/org/apache/spark/spark-core_2.11/2.4.1/spark-core_2.11-2.4.1.jar:/home/hadoop/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/hadoop/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/hadoop/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/hadoop/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/hadoop/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/hadoop/repository/com/twitter/chill_2.11/0.9.3/chill_2.11-0.9.3.jar:/home/hadoop/repository/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar:/home/hadoop/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/home/hadoop/repository/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar:/home/hadoop/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/hadoop/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/hadoop/repository/org/apache/spark/spark-launcher_2.11/2.4.1/spark-launcher_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-kvstore_2.11/2.4.1/spark-kvstore_2.11-2.4.1.jar:/home/hadoop/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/repository/com/fasterxml/jackson/core/jackson-core/2.6.7/jackson-core-2.6.7.jar:/home/hadoop/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.7/jackson-annotations-2.6.7.jar:/home/hadoop/repository/org/apache/spark/spark-network-common_2.11/2.4.1/spark-network-common_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-network-shuffle_2.11/2.4.1/spark-network-shuffle_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-unsafe_2.11/2.4.1/spark-unsafe_2.11-2.4.1.jar:/home/hadoop/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/hadoop/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/home/hadoop/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/hadoop/repository/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar:/home/hadoop/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/home/hadoop/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/hadoop/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/hadoop/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/hadoop/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/home/hadoop/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/hadoop/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/hadoop/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/home/hadoop/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/repository/org/json4s/json4s-jackson_2.11/3.5.3/json4s-jackson_2.11-3.5.3.jar:/home/hadoop/repository/org/json4s/json4s-core_2.11/3.5.3/json4s-core_2.11-3.5.3.jar:/home/hadoop/repository/org/json4s/json4s-ast_2.11/3.5.3/json4s-ast_2.11-3.5.3.jar:/home/hadoop/repository/org/json4s/json4s-scalap_2.11/3.5.3/json4s-scalap_2.11-3.5.3.jar:/home/hadoop/repository/org/scala-lang/modules/scala-xml_2.11/1.0.6/scala-xml_2.11-1.0.6.jar:/home/hadoop/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/hadoop/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/hadoop/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/hadoop/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/hadoop/repository/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/home/hadoop/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/hadoop/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/hadoop/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/hadoop/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/hadoop/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/hadoop/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/hadoop/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/hadoop/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.jar:/home/hadoop/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/hadoop/repository/io/netty/netty-all/4.1.17.Final/netty-all-4.1.17.Final.jar:/home/hadoop/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.jar:/home/hadoop/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/hadoop/repository/com/fasterxml/jackson/core/jackson-databind/2.6.7.1/jackson-databind-2.6.7.1.jar:/home/hadoop/repository/com/fasterxml/jackson/module/jackson-module-scala_2.11/2.6.7.1/jackson-module-scala_2.11-2.6.7.1.jar:/home/hadoop/repository/org/scala-lang/scala-reflect/2.11.8/scala-reflect-2.11.8.jar:/home/hadoop/repository/com/fasterxml/jackson/module/jackson-module-paranamer/2.7.9/jackson-module-paranamer-2.7.9.jar:/home/hadoop/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/hadoop/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/hadoop/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/hadoop/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/hadoop/repository/org/apache/spark/spark-tags_2.11/2.4.1/spark-tags_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/hadoop/repository/org/apache/spark/spark-sql_2.11/2.4.1/spark-sql_2.11-2.4.1.jar:/home/hadoop/repository/com/univocity/univocity-parsers/2.7.3/univocity-parsers-2.7.3.jar:/home/hadoop/repository/org/apache/spark/spark-sketch_2.11/2.4.1/spark-sketch_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-catalyst_2.11/2.4.1/spark-catalyst_2.11-2.4.1.jar:/home/hadoop/repository/org/codehaus/janino/janino/3.0.9/janino-3.0.9.jar:/home/hadoop/repository/org/codehaus/janino/commons-compiler/3.0.9/commons-compiler-3.0.9.jar:/home/hadoop/repository/org/antlr/antlr4-runtime/4.7/antlr4-runtime-4.7.jar:/home/hadoop/repository/org/apache/orc/orc-core/1.5.5/orc-core-1.5.5-nohive.jar:/home/hadoop/repository/org/apache/orc/orc-shims/1.5.5/orc-shims-1.5.5.jar:/home/hadoop/repository/io/airlift/aircompressor/0.10/aircompressor-0.10.jar:/home/hadoop/repository/org/apache/orc/orc-mapreduce/1.5.5/orc-mapreduce-1.5.5-nohive.jar:/home/hadoop/repository/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.jar:/home/hadoop/repository/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.jar:/home/hadoop/repository/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.jar:/home/hadoop/repository/org/apache/arrow/arrow-vector/0.10.0/arrow-vector-0.10.0.jar:/home/hadoop/repository/org/apache/arrow/arrow-format/0.10.0/arrow-format-0.10.0.jar:/home/hadoop/repository/org/apache/arrow/arrow-memory/0.10.0/arrow-memory-0.10.0.jar:/home/hadoop/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/hadoop/repository/com/vlkan/flatbuffers/1.2.0-3f79e055/flatbuffers-1.2.0-3f79e055.jar:/home/hadoop/repository/org/apache/spark/spark-mllib_2.11/2.4.1/spark-mllib_2.11-2.4.1.jar:/home/hadoop/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.1.0/scala-parser-combinators_2.11-1.1.0.jar:/home/hadoop/repository/org/apache/spark/spark-graphx_2.11/2.4.1/spark-graphx_2.11-2.4.1.jar:/home/hadoop/repository/com/github/fommil/netlib/core/1.1.2/core-1.1.2.jar:/home/hadoop/repository/net/sourceforge/f2j/arpack_combined_all/0.1/arpack_combined_all-0.1.jar:/home/hadoop/repository/org/apache/spark/spark-mllib-local_2.11/2.4.1/spark-mllib-local_2.11-2.4.1.jar:/home/hadoop/repository/org/scalanlp/breeze_2.11/0.13.2/breeze_2.11-0.13.2.jar:/home/hadoop/repository/org/scalanlp/breeze-macros_2.11/0.13.2/breeze-macros_2.11-0.13.2.jar:/home/hadoop/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/hadoop/repository/com/github/rwl/jtransforms/2.4.0/jtransforms-2.4.0.jar:/home/hadoop/repository/org/spire-math/spire_2.11/0.13.0/spire_2.11-0.13.0.jar:/home/hadoop/repository/org/spire-math/spire-macros_2.11/0.13.0/spire-macros_2.11-0.13.0.jar:/home/hadoop/repository/org/typelevel/machinist_2.11/0.6.1/machinist_2.11-0.6.1.jar:/home/hadoop/repository/com/chuusai/shapeless_2.11/2.3.2/shapeless_2.11-2.3.2.jar:/home/hadoop/repository/org/typelevel/macro-compat_2.11/1.1.1/macro-compat_2.11-1.1.1.jar:/home/hadoop/repository/org/apache/spark/spark-hive_2.11/2.4.1/spark-hive_2.11-2.4.1.jar:/home/hadoop/repository/com/twitter/parquet-hadoop-bundle/1.6.0/parquet-hadoop-bundle-1.6.0.jar:/home/hadoop/repository/org/spark-project/hive/hive-exec/1.2.1.spark2/hive-exec-1.2.1.spark2.jar:/home/hadoop/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/hadoop/repository/log4j/apache-log4j-extras/1.2.17/apache-log4j-extras-1.2.17.jar:/home/hadoop/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/hadoop/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/home/hadoop/repository/org/spark-project/hive/hive-metastore/1.2.1.spark2/hive-metastore-1.2.1.spark2.jar:/home/hadoop/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/hadoop/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/repository/org/datanucleus/datanucleus-api-jdo/3.2.6/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/repository/org/datanucleus/datanucleus-rdbms/3.2.9/datanucleus-rdbms-3.2.9.jar:/home/hadoop/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/hadoop/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/hadoop/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/hadoop/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/hadoop/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/repository/org/apache/calcite/calcite-avatica/1.2.0-incubating/calcite-avatica-1.2.0-incubating.jar:/home/hadoop/repository/org/apache/calcite/calcite-core/1.2.0-incubating/calcite-core-1.2.0-incubating.jar:/home/hadoop/repository/org/apache/calcite/calcite-linq4j/1.2.0-incubating/calcite-linq4j-1.2.0-incubating.jar:/home/hadoop/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/hadoop/repository/org/apache/httpcomponents/httpclient/4.5.6/httpclient-4.5.6.jar:/home/hadoop/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/repository/commons-codec/commons-codec/1.10/commons-codec-1.10.jar:/home/hadoop/repository/joda-time/joda-time/2.9.3/joda-time-2.9.3.jar:/home/hadoop/repository/org/jodd/jodd-core/3.5.2/jodd-core-3.5.2.jar:/home/hadoop/repository/org/datanucleus/datanucleus-core/3.2.10/datanucleus-core-3.2.10.jar:/home/hadoop/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/hadoop/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/hadoop/repository/org/apache/derby/derby/10.12.1.1/derby-10.12.1.1.jar:/home/hadoop/repository/org/apache/spark/spark-streaming_2.11/2.4.1/spark-streaming_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/spark/spark-streaming-kafka-0-10_2.11/2.4.1/spark-streaming-kafka-0-10_2.11-2.4.1.jar:/home/hadoop/repository/org/apache/kafka/kafka-clients/2.0.0/kafka-clients-2.0.0.jar:/home/hadoop/repository/com/alibaba/fastjson/1.2.40/fastjson-1.2.40.jar:/home/hadoop/repository/org/apache/hive/hive-jdbc/2.3.3/hive-jdbc-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-storage-api/2.4.0/hive-storage-api-2.4.0.jar:/home/hadoop/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/hadoop/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/hadoop/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/hadoop/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/hadoop/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/hadoop/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/hadoop/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/hadoop/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/hadoop/repository/asm/asm/3.1/asm-3.1.jar:/home/hadoop/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/hadoop/repository/com/tdunning/json/1.8/json-1.8.jar:/home/hadoop/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/hadoop/repository/org/apache/hive/hive-service/2.3.3/hive-service-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-llap-server/2.3.3/hive-llap-server-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/hadoop/repository/org/apache/slider/slider-core/0.90.2-incubating/slider-core-0.90.2-incubating.jar:/home/hadoop/repository/com/beust/jcommander/1.30/jcommander-1.30.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.1/hadoop-yarn-registry-2.7.1.jar:/home/hadoop/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/hadoop/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/hadoop/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3-tests.jar:/home/hadoop/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.1/hbase-hadoop2-compat-1.1.1.jar:/home/hadoop/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/home/hadoop/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/repository/org/apache/hbase/hbase-server/1.1.1/hbase-server-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-procedure/1.1.1/hbase-procedure-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1-tests.jar:/home/hadoop/repository/org/apache/hbase/hbase-prefix-tree/1.1.1/hbase-prefix-tree-1.1.1.jar:/home/hadoop/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/home/hadoop/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-hadoop-compat/1.1.1/hbase-hadoop-compat-1.1.1.jar:/home/hadoop/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/hadoop/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/repository/javax/servlet/jsp-api/2.0/jsp-api-2.0.jar:/home/hadoop/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/hadoop/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/repository/javax/servlet/servlet-api/2.4/servlet-api-2.4.jar:/home/hadoop/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/hadoop/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/hadoop/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/hadoop/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/hadoop/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/usr/lib/jvm/java-1.8.0-openjdk/lib/tools.jar:/home/hadoop/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/hadoop/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/hadoop/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/hadoop/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/hadoop/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/hadoop/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/hadoop/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/hadoop/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/hadoop/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/hadoop/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/hadoop/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/hadoop/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/hadoop/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/hadoop/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/hadoop/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/hadoop/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6-tests.jar:/home/hadoop/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/hadoop/repository/org/apache/httpcomponents/httpcore/4.4/httpcore-4.4.jar:/home/hadoop/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/hadoop/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/hadoop/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/hadoop/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/hadoop/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/hadoop/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/hadoop/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/hadoop/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/hadoop/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/hadoop/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/hadoop/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/hadoop/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/hadoop/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/hadoop/repository/org/codehaus/groovy/groovy-all/2.4.4/groovy-all-2.4.4.jar:/home/hadoop/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/hadoop/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/hadoop/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/hadoop/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/hadoop/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-client/2.7.3/hadoop-client-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-common/2.7.3/hadoop-common-2.7.3.jar:/home/hadoop/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/hadoop/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-auth/2.7.3/hadoop-auth-2.7.3.jar:/home/hadoop/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-hdfs/2.7.3/hadoop-hdfs-2.7.3.jar:/home/hadoop/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/hadoop/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/repository/org/apache/hadoop/hadoop-annotations/2.7.3/hadoop-annotations-2.7.3.jar:/home/hadoop/repository/mysql/mysql-connector-java/5.1.35/mysql-connector-java-5.1.35.jar:/home/hadoop/repository/com/google/guava/guava/26.0-jre/guava-26.0-jre.jar:/home/hadoop/repository/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/home/hadoop/repository/com/google/errorprone/error_prone_annotations/2.1.3/error_prone_annotations-2.1.3.jar:/home/hadoop/repository/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/home/hadoop/repository/org/codehaus/mojo/animal-sniffer-annotations/1.14/animal-sniffer-annotations-1.14.jar:/home/hadoop/scala/lib/scala-parser-combinators_2.11-1.0.4.jar:/home/hadoop/scala/lib/scala-reflect.jar:/home/hadoop/scala/lib/scala-actors-migration_2.11-1.1.0.jar:/home/hadoop/scala/lib/scala-xml_2.11-1.0.4.jar:/home/hadoop/scala/lib/scala-library.jar:/home/hadoop/scala/lib/scala-swing_2.11-1.0.2.jar:/home/hadoop/scala/lib/scala-actors-2.11.0.jar:/home/hadoop/idea/lib/idea_rt.jar com.xh.spark.sql.function.WindowFunctionTest</span><br><span class="line">Connected to the target VM, address: '127.0.0.1:45315', transport: 'socket'</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/hadoop/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/hadoop/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line">19/04/12 16:47:02 INFO SparkContext: Running Spark version 2.4.1</span><br><span class="line">19/04/12 16:47:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">19/04/12 16:47:04 INFO SparkContext: Submitted application: WindowFunctionTest</span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing view acls to: hadoop</span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing modify acls to: hadoop</span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing view acls groups to: </span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: Changing modify acls groups to: </span><br><span class="line">19/04/12 16:47:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()</span><br><span class="line">19/04/12 16:47:07 INFO Utils: Successfully started service 'sparkDriver' on port 43568.</span><br><span class="line">19/04/12 16:47:07 INFO SparkEnv: Registering MapOutputTracker</span><br><span class="line">19/04/12 16:47:07 INFO SparkEnv: Registering BlockManagerMaster</span><br><span class="line">19/04/12 16:47:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information</span><br><span class="line">19/04/12 16:47:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up</span><br><span class="line">19/04/12 16:47:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-07913749-f493-4bae-95aa-f9ea019dde51</span><br><span class="line">19/04/12 16:47:07 INFO MemoryStore: MemoryStore started with capacity 447.3 MB</span><br><span class="line">19/04/12 16:47:07 INFO SparkEnv: Registering OutputCommitCoordinator</span><br><span class="line">19/04/12 16:47:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.</span><br><span class="line">19/04/12 16:47:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://hadoop04:4040</span><br><span class="line">19/04/12 16:47:08 INFO SparkContext: Added JAR /home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT.jar at spark://hadoop04:43568/jars/sparklearning-1.0-SNAPSHOT.jar with timestamp 1555058828687</span><br><span class="line">19/04/12 16:47:08 INFO SparkContext: Added JAR /home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://hadoop04:43568/jars/sparklearning-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1555058828703</span><br><span class="line">19/04/12 16:47:13 INFO Client: Requesting a new application from cluster with 3 NodeManagers</span><br><span class="line">19/04/12 16:47:13 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)</span><br><span class="line">19/04/12 16:47:13 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead</span><br><span class="line">19/04/12 16:47:13 INFO Client: Setting up container launch context for our AM</span><br><span class="line">19/04/12 16:47:13 INFO Client: Setting up the launch environment for our AM container</span><br><span class="line">19/04/12 16:47:14 INFO Client: Preparing resources for our AM container</span><br><span class="line">19/04/12 16:47:14 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.</span><br><span class="line">19/04/12 16:47:23 INFO Client: Uploading resource file:/tmp/spark-f3533ae6-b45b-4a1f-8119-0c12775c5a33/__spark_libs__8176900855339303501.zip -&gt; hdfs://ns1/user/hadoop/.sparkStaging/application_1555049463744_0005/__spark_libs__8176900855339303501.zip</span><br><span class="line">19/04/12 16:47:50 INFO Client: Uploading resource file:/tmp/spark-f3533ae6-b45b-4a1f-8119-0c12775c5a33/__spark_conf__4747135480716905311.zip -&gt; hdfs://ns1/user/hadoop/.sparkStaging/application_1555049463744_0005/__spark_conf__.zip</span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing view acls to: hadoop</span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing modify acls to: hadoop</span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing view acls groups to: </span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: Changing modify acls groups to: </span><br><span class="line">19/04/12 16:47:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()</span><br><span class="line">19/04/12 16:47:55 INFO Client: Submitting application application_1555049463744_0005 to ResourceManager</span><br><span class="line">19/04/12 16:47:55 INFO YarnClientImpl: Submitted application application_1555049463744_0005</span><br><span class="line">19/04/12 16:47:55 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1555049463744_0005 and attemptId None</span><br><span class="line">19/04/12 16:47:57 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:47:57 INFO Client: </span><br><span class="line">	 client token: N/A</span><br><span class="line">	 diagnostics: N/A</span><br><span class="line">	 ApplicationMaster host: N/A</span><br><span class="line">	 ApplicationMaster RPC port: -1</span><br><span class="line">	 queue: root.hadoop</span><br><span class="line">	 start time: 1555058875812</span><br><span class="line">	 final status: UNDEFINED</span><br><span class="line">	 tracking URL: http://192.168.8.82:8089/proxy/application_1555049463744_0005/</span><br><span class="line">	 user: hadoop</span><br><span class="line">19/04/12 16:47:58 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:47:59 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:00 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:01 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:02 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:03 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:04 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:05 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:06 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:07 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:08 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:09 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:10 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:11 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:12 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:13 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:14 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:15 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:16 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:17 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:18 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:19 INFO Client: Application report for application_1555049463744_0005 (state: ACCEPTED)</span><br><span class="line">19/04/12 16:48:20 INFO Client: Application report for application_1555049463744_0005 (state: RUNNING)</span><br><span class="line">19/04/12 16:48:20 INFO Client: </span><br><span class="line">	 client token: N/A</span><br><span class="line">	 diagnostics: N/A</span><br><span class="line">	 ApplicationMaster host: 192.168.8.82</span><br><span class="line">	 ApplicationMaster RPC port: -1</span><br><span class="line">	 queue: root.hadoop</span><br><span class="line">	 start time: 1555058875812</span><br><span class="line">	 final status: UNDEFINED</span><br><span class="line">	 tracking URL: http://192.168.8.82:8089/proxy/application_1555049463744_0005/</span><br><span class="line">	 user: hadoop</span><br><span class="line">19/04/12 16:48:20 INFO YarnClientSchedulerBackend: Application application_1555049463744_0005 has started running.</span><br><span class="line">19/04/12 16:48:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42715.</span><br><span class="line">19/04/12 16:48:21 INFO NettyBlockTransferService: Server created on hadoop04:42715</span><br><span class="line">19/04/12 16:48:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy</span><br><span class="line">19/04/12 16:48:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:21 INFO BlockManagerMasterEndpoint: Registering block manager hadoop04:42715 with 447.3 MB RAM, BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, hadoop04, 42715, None)</span><br><span class="line">19/04/12 16:48:23 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)</span><br><span class="line">19/04/12 16:48:24 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; 192.168.8.82, PROXY_URI_BASES -&gt; http://192.168.8.82:8089/proxy/application_1555049463744_0005, RM_HA_URLS -&gt; hadoop02:8088,hadoop03:8088), /proxy/application_1555049463744_0005</span><br><span class="line">19/04/12 16:48:24 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill, /metrics/json.</span><br><span class="line">19/04/12 16:48:24 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)</span><br><span class="line">19/04/12 16:48:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/hadoop/worker/sparklearning/spark-warehouse').</span><br><span class="line">19/04/12 16:48:32 INFO SharedState: Warehouse path is 'file:/home/hadoop/worker/sparklearning/spark-warehouse'.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.</span><br><span class="line">19/04/12 16:48:32 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.</span><br><span class="line">19/04/12 16:48:52 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint</span><br><span class="line">19/04/12 16:48:55 INFO CodeGenerator: Code generated in 2751.822246 ms</span><br><span class="line">19/04/12 16:52:26 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.8.83:53042) with ID 1</span><br><span class="line">19/04/12 16:52:30 INFO BlockManagerMasterEndpoint: Registering block manager hadoop03:45104 with 366.3 MB RAM, BlockManagerId(1, hadoop03, 45104, None)</span><br><span class="line">19/04/12 16:52:35 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.8.84:37146) with ID 2</span><br><span class="line">19/04/12 16:52:39 INFO BlockManagerMasterEndpoint: Registering block manager hadoop04:38267 with 366.3 MB RAM, BlockManagerId(2, hadoop04, 38267, None)</span><br><span class="line">19/04/12 16:53:38 INFO CodeGenerator: Code generated in 668.087005 ms</span><br><span class="line">19/04/12 16:53:45 INFO CodeGenerator: Code generated in 732.99189 ms</span><br><span class="line">19/04/12 16:53:47 INFO CodeGenerator: Code generated in 1265.744172 ms</span><br><span class="line">19/04/12 16:53:47 INFO CodeGenerator: Code generated in 271.771791 ms</span><br><span class="line">19/04/12 16:53:51 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Registering RDD 2 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Got job 0 (show at WindowFunctionTest.scala:45) with 1 output partitions</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Final stage: ResultStage 1 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)</span><br><span class="line">19/04/12 16:53:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:53:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.1 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:53:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.1 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:53:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hadoop04:42715 (size: 3.1 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:53:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:53:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(0, 1))</span><br><span class="line">19/04/12 16:53:55 INFO YarnScheduler: Adding task set 0.0 with 2 tasks</span><br><span class="line">19/04/12 16:53:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hadoop03, executor 1, partition 0, PROCESS_LOCAL, 8230 bytes)</span><br><span class="line">19/04/12 16:53:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hadoop04, executor 2, partition 1, PROCESS_LOCAL, 8230 bytes)</span><br><span class="line">19/04/12 16:55:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hadoop03:45104 (size: 3.1 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:55:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hadoop04:38267 (size: 3.1 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 137230 ms on hadoop03 (executor 1) (1/2)</span><br><span class="line">19/04/12 16:56:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 147247 ms on hadoop04 (executor 2) (2/2)</span><br><span class="line">19/04/12 16:56:24 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: ShuffleMapStage 0 (show at WindowFunctionTest.scala:45) finished in 151.743 s</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: looking for newly runnable stages</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: running: Set()</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: waiting: Set(ResultStage 1)</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: failed: Set()</span><br><span class="line">19/04/12 16:56:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.4 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:56:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.3 MB)</span><br><span class="line">19/04/12 16:56:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(0))</span><br><span class="line">19/04/12 16:56:25 INFO YarnScheduler: Adding task set 1.0 with 1 tasks</span><br><span class="line">19/04/12 16:56:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hadoop03, executor 1, partition 0, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.8.83:53042</span><br><span class="line">19/04/12 16:56:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 2345 ms on hadoop03 (executor 1) (1/1)</span><br><span class="line">19/04/12 16:56:27 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:27 INFO DAGScheduler: ResultStage 1 (show at WindowFunctionTest.scala:45) finished in 3.127 s</span><br><span class="line">19/04/12 16:56:27 INFO DAGScheduler: Job 0 finished: show at WindowFunctionTest.scala:45, took 156.360095 s</span><br><span class="line">19/04/12 16:56:28 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Got job 1 (show at WindowFunctionTest.scala:45) with 4 output partitions</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Final stage: ResultStage 3 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(1, 2, 3, 4))</span><br><span class="line">19/04/12 16:56:28 INFO YarnScheduler: Adding task set 3.0 with 4 tasks</span><br><span class="line">19/04/12 16:56:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, hadoop04, executor 2, partition 1, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:28 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, hadoop03, executor 1, partition 2, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5, hadoop03, executor 1, partition 3, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 447 ms on hadoop03 (executor 1) (1/4)</span><br><span class="line">19/04/12 16:56:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6, hadoop03, executor 1, partition 4, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 290 ms on hadoop03 (executor 1) (2/4)</span><br><span class="line">19/04/12 16:56:29 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 334 ms on hadoop03 (executor 1) (3/4)</span><br><span class="line">19/04/12 16:56:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.8.84:37146</span><br><span class="line">19/04/12 16:56:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 3241 ms on hadoop04 (executor 2) (4/4)</span><br><span class="line">19/04/12 16:56:31 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:31 INFO DAGScheduler: ResultStage 3 (show at WindowFunctionTest.scala:45) finished in 3.803 s</span><br><span class="line">19/04/12 16:56:31 INFO DAGScheduler: Job 1 finished: show at WindowFunctionTest.scala:45, took 3.848347 s</span><br><span class="line">19/04/12 16:56:32 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Got job 2 (show at WindowFunctionTest.scala:45) with 20 output partitions</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Final stage: ResultStage 5 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:32 INFO DAGScheduler: Submitting 20 missing tasks from ResultStage 5 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))</span><br><span class="line">19/04/12 16:56:32 INFO YarnScheduler: Adding task set 5.0 with 20 tasks</span><br><span class="line">19/04/12 16:56:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7, hadoop03, executor 1, partition 5, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:32 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8, hadoop04, executor 2, partition 6, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 9, hadoop04, executor 2, partition 7, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 726 ms on hadoop04 (executor 2) (1/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 10, hadoop03, executor 1, partition 8, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 811 ms on hadoop03 (executor 1) (2/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 11, hadoop03, executor 1, partition 9, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 10) in 393 ms on hadoop03 (executor 1) (3/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 12, hadoop04, executor 2, partition 10, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 9) in 523 ms on hadoop04 (executor 2) (4/20)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 13, hadoop03, executor 1, partition 11, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:33 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 11) in 317 ms on hadoop03 (executor 1) (5/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 14, hadoop03, executor 1, partition 12, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 15, hadoop03, executor 1, partition 13, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 13) in 851 ms on hadoop03 (executor 1) (6/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 14) in 541 ms on hadoop03 (executor 1) (7/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 16, hadoop04, executor 2, partition 14, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 12) in 1219 ms on hadoop04 (executor 2) (8/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 17, hadoop04, executor 2, partition 15, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 18, hadoop03, executor 1, partition 16, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 16) in 313 ms on hadoop04 (executor 2) (9/20)</span><br><span class="line">19/04/12 16:56:34 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 15) in 596 ms on hadoop03 (executor 1) (10/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 19, hadoop04, executor 2, partition 17, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 20, hadoop03, executor 1, partition 18, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 18) in 158 ms on hadoop03 (executor 1) (11/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 17) in 167 ms on hadoop04 (executor 2) (12/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 21, hadoop03, executor 1, partition 19, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 22, hadoop04, executor 2, partition 20, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 20) in 250 ms on hadoop03 (executor 1) (13/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 19) in 343 ms on hadoop04 (executor 2) (14/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 23, hadoop04, executor 2, partition 21, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 22) in 247 ms on hadoop04 (executor 2) (15/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 24, hadoop03, executor 1, partition 22, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 21) in 481 ms on hadoop03 (executor 1) (16/20)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 25, hadoop04, executor 2, partition 23, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:35 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 23) in 393 ms on hadoop04 (executor 2) (17/20)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 26, hadoop04, executor 2, partition 24, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 25) in 473 ms on hadoop04 (executor 2) (18/20)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 24) in 898 ms on hadoop03 (executor 1) (19/20)</span><br><span class="line">19/04/12 16:56:36 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 26) in 524 ms on hadoop04 (executor 2) (20/20)</span><br><span class="line">19/04/12 16:56:36 INFO YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:56:36 INFO DAGScheduler: ResultStage 5 (show at WindowFunctionTest.scala:45) finished in 4.493 s</span><br><span class="line">19/04/12 16:56:36 INFO DAGScheduler: Job 2 finished: show at WindowFunctionTest.scala:45, took 4.566402 s</span><br><span class="line">19/04/12 16:56:37 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Got job 3 (show at WindowFunctionTest.scala:45) with 100 output partitions</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Final stage: ResultStage 7 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:56:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:56:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:56:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:56:37 INFO DAGScheduler: Submitting 100 missing tasks from ResultStage 7 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))</span><br><span class="line">19/04/12 16:56:37 INFO YarnScheduler: Adding task set 7.0 with 100 tasks</span><br><span class="line">19/04/12 16:56:37 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 27, hadoop04, executor 2, partition 110, NODE_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:37 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 28, hadoop03, executor 1, partition 102, NODE_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:56:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 29, hadoop04, executor 2, partition 25, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:39 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 27) in 1607 ms on hadoop04 (executor 2) (1/100)</span><br><span class="line">19/04/12 16:56:39 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 30, hadoop04, executor 2, partition 26, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 31, hadoop04, executor 2, partition 27, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 29) in 1083 ms on hadoop04 (executor 2) (2/100)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 30) in 659 ms on hadoop04 (executor 2) (3/100)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 32, hadoop04, executor 2, partition 28, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 31) in 473 ms on hadoop04 (executor 2) (4/100)</span><br><span class="line">19/04/12 16:56:40 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 33, hadoop04, executor 2, partition 29, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 34, hadoop03, executor 1, partition 30, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 28) in 3578 ms on hadoop03 (executor 1) (5/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 32) in 505 ms on hadoop04 (executor 2) (6/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 35, hadoop04, executor 2, partition 31, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 33) in 438 ms on hadoop04 (executor 2) (7/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 36, hadoop03, executor 1, partition 32, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 37, hadoop04, executor 2, partition 33, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 35) in 353 ms on hadoop04 (executor 2) (8/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 34) in 583 ms on hadoop03 (executor 1) (9/100)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 38, hadoop03, executor 1, partition 34, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:41 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 36) in 301 ms on hadoop03 (executor 1) (10/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 39, hadoop03, executor 1, partition 35, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 40, hadoop04, executor 2, partition 36, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 38) in 453 ms on hadoop03 (executor 1) (11/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 41, hadoop04, executor 2, partition 37, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 37) in 1017 ms on hadoop04 (executor 2) (12/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 42, hadoop03, executor 1, partition 38, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 39) in 407 ms on hadoop03 (executor 1) (13/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 40) in 486 ms on hadoop04 (executor 2) (14/100)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 43, hadoop04, executor 2, partition 39, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:42 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 41) in 259 ms on hadoop04 (executor 2) (15/100)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 44, hadoop04, executor 2, partition 40, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 43) in 472 ms on hadoop04 (executor 2) (16/100)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 45, hadoop03, executor 1, partition 41, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:43 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 42) in 964 ms on hadoop03 (executor 1) (17/100)</span><br><span class="line">19/04/12 16:56:45 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 46, hadoop03, executor 1, partition 42, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 47, hadoop04, executor 2, partition 43, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 44) in 2989 ms on hadoop04 (executor 2) (18/100)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 45) in 3210 ms on hadoop03 (executor 1) (19/100)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 48, hadoop03, executor 1, partition 44, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:46 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 46) in 1507 ms on hadoop03 (executor 1) (20/100)</span><br><span class="line">19/04/12 16:56:47 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 49, hadoop04, executor 2, partition 45, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:47 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 47) in 1533 ms on hadoop04 (executor 2) (21/100)</span><br><span class="line">19/04/12 16:56:48 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 50, hadoop04, executor 2, partition 46, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:48 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 49) in 715 ms on hadoop04 (executor 2) (22/100)</span><br><span class="line">19/04/12 16:56:48 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 51, hadoop03, executor 1, partition 47, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 48) in 2132 ms on hadoop03 (executor 1) (23/100)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 52, hadoop04, executor 2, partition 48, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 50) in 1332 ms on hadoop04 (executor 2) (24/100)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 53, hadoop03, executor 1, partition 49, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:49 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 51) in 776 ms on hadoop03 (executor 1) (25/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 54, hadoop04, executor 2, partition 50, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 52) in 1066 ms on hadoop04 (executor 2) (26/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 55, hadoop03, executor 1, partition 51, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 53) in 698 ms on hadoop03 (executor 1) (27/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 56, hadoop04, executor 2, partition 52, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 54) in 679 ms on hadoop04 (executor 2) (28/100)</span><br><span class="line">19/04/12 16:56:50 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 57, hadoop03, executor 1, partition 53, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 55) in 1082 ms on hadoop03 (executor 1) (29/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 58, hadoop04, executor 2, partition 54, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 56) in 731 ms on hadoop04 (executor 2) (30/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 59, hadoop03, executor 1, partition 55, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 57) in 592 ms on hadoop03 (executor 1) (31/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 60, hadoop04, executor 2, partition 56, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 58) in 557 ms on hadoop04 (executor 2) (32/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 61, hadoop03, executor 1, partition 57, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 59) in 468 ms on hadoop03 (executor 1) (33/100)</span><br><span class="line">19/04/12 16:56:51 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 62, hadoop04, executor 2, partition 58, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 60) in 241 ms on hadoop04 (executor 2) (34/100)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 63, hadoop04, executor 2, partition 59, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 62) in 728 ms on hadoop04 (executor 2) (35/100)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 64, hadoop03, executor 1, partition 60, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 61) in 804 ms on hadoop03 (executor 1) (36/100)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 65, hadoop04, executor 2, partition 61, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:52 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 63) in 392 ms on hadoop04 (executor 2) (37/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 66, hadoop03, executor 1, partition 62, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 64) in 320 ms on hadoop03 (executor 1) (38/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 67, hadoop04, executor 2, partition 63, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 65) in 154 ms on hadoop04 (executor 2) (39/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 68, hadoop03, executor 1, partition 64, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 66) in 297 ms on hadoop03 (executor 1) (40/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 69, hadoop03, executor 1, partition 65, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 68) in 463 ms on hadoop03 (executor 1) (41/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 70, hadoop04, executor 2, partition 66, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 67) in 672 ms on hadoop04 (executor 2) (42/100)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 71, hadoop03, executor 1, partition 67, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:53 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 69) in 165 ms on hadoop03 (executor 1) (43/100)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 72, hadoop03, executor 1, partition 68, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 71) in 1656 ms on hadoop03 (executor 1) (44/100)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 73, hadoop03, executor 1, partition 69, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:55 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 72) in 534 ms on hadoop03 (executor 1) (45/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 74, hadoop03, executor 1, partition 70, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 73) in 376 ms on hadoop03 (executor 1) (46/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 75, hadoop04, executor 2, partition 71, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 70) in 2844 ms on hadoop04 (executor 2) (47/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 76, hadoop03, executor 1, partition 72, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 74) in 444 ms on hadoop03 (executor 1) (48/100)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 77, hadoop03, executor 1, partition 73, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:56 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 76) in 341 ms on hadoop03 (executor 1) (49/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 78, hadoop03, executor 1, partition 74, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 77) in 169 ms on hadoop03 (executor 1) (50/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 79, hadoop03, executor 1, partition 75, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 78) in 193 ms on hadoop03 (executor 1) (51/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 80, hadoop04, executor 2, partition 76, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 75) in 1174 ms on hadoop04 (executor 2) (52/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 81, hadoop03, executor 1, partition 77, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 82, hadoop04, executor 2, partition 78, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 79) in 337 ms on hadoop03 (executor 1) (53/100)</span><br><span class="line">19/04/12 16:56:57 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 80) in 310 ms on hadoop04 (executor 2) (54/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 83, hadoop03, executor 1, partition 79, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 81) in 761 ms on hadoop03 (executor 1) (55/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 84, hadoop04, executor 2, partition 80, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 82) in 696 ms on hadoop04 (executor 2) (56/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 85, hadoop03, executor 1, partition 81, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 83) in 691 ms on hadoop03 (executor 1) (57/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 86, hadoop03, executor 1, partition 82, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 85) in 118 ms on hadoop03 (executor 1) (58/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 87, hadoop04, executor 2, partition 83, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 84) in 447 ms on hadoop04 (executor 2) (59/100)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 88, hadoop03, executor 1, partition 84, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:58 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 86) in 240 ms on hadoop03 (executor 1) (60/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 89, hadoop04, executor 2, partition 85, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 87) in 325 ms on hadoop04 (executor 2) (61/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 90, hadoop03, executor 1, partition 86, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 88) in 255 ms on hadoop03 (executor 1) (62/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 91, hadoop04, executor 2, partition 87, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 89) in 147 ms on hadoop04 (executor 2) (63/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 92, hadoop03, executor 1, partition 88, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 90) in 130 ms on hadoop03 (executor 1) (64/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 93, hadoop03, executor 1, partition 89, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 92) in 110 ms on hadoop03 (executor 1) (65/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 94, hadoop04, executor 2, partition 90, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 91) in 264 ms on hadoop04 (executor 2) (66/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 95, hadoop03, executor 1, partition 91, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 93) in 165 ms on hadoop03 (executor 1) (67/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 96, hadoop04, executor 2, partition 92, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 94) in 267 ms on hadoop04 (executor 2) (68/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 97, hadoop03, executor 1, partition 93, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 95) in 222 ms on hadoop03 (executor 1) (69/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 98, hadoop04, executor 2, partition 94, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 96) in 191 ms on hadoop04 (executor 2) (70/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 99, hadoop03, executor 1, partition 95, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 97) in 173 ms on hadoop03 (executor 1) (71/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 100, hadoop04, executor 2, partition 96, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 98) in 165 ms on hadoop04 (executor 2) (72/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 101, hadoop03, executor 1, partition 97, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 99) in 181 ms on hadoop03 (executor 1) (73/100)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 102, hadoop04, executor 2, partition 98, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:56:59 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 100) in 176 ms on hadoop04 (executor 2) (74/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 103, hadoop04, executor 2, partition 99, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 102) in 103 ms on hadoop04 (executor 2) (75/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 104, hadoop03, executor 1, partition 100, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 101) in 202 ms on hadoop03 (executor 1) (76/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 105, hadoop04, executor 2, partition 101, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 103) in 159 ms on hadoop04 (executor 2) (77/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 106, hadoop04, executor 2, partition 103, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 105) in 378 ms on hadoop04 (executor 2) (78/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 107, hadoop03, executor 1, partition 104, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 104) in 551 ms on hadoop03 (executor 1) (79/100)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 108, hadoop04, executor 2, partition 105, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:00 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 106) in 437 ms on hadoop04 (executor 2) (80/100)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 109, hadoop03, executor 1, partition 106, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 107) in 621 ms on hadoop03 (executor 1) (81/100)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 110, hadoop04, executor 2, partition 107, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:01 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 108) in 1254 ms on hadoop04 (executor 2) (82/100)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 111, hadoop03, executor 1, partition 108, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 109) in 1316 ms on hadoop03 (executor 1) (83/100)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 112, hadoop04, executor 2, partition 109, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 110) in 793 ms on hadoop04 (executor 2) (84/100)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 113, hadoop03, executor 1, partition 111, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:02 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 111) in 780 ms on hadoop03 (executor 1) (85/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 114, hadoop04, executor 2, partition 112, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 112) in 567 ms on hadoop04 (executor 2) (86/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 115, hadoop03, executor 1, partition 113, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 113) in 689 ms on hadoop03 (executor 1) (87/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 116, hadoop04, executor 2, partition 114, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 114) in 513 ms on hadoop04 (executor 2) (88/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 117, hadoop03, executor 1, partition 115, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 115) in 432 ms on hadoop03 (executor 1) (89/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 118, hadoop04, executor 2, partition 116, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 116) in 271 ms on hadoop04 (executor 2) (90/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 119, hadoop03, executor 1, partition 117, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 120, hadoop04, executor 2, partition 118, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 118) in 129 ms on hadoop04 (executor 2) (91/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 117) in 173 ms on hadoop03 (executor 1) (92/100)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 121, hadoop04, executor 2, partition 119, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:03 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 120) in 139 ms on hadoop04 (executor 2) (93/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 122, hadoop03, executor 1, partition 120, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 119) in 232 ms on hadoop03 (executor 1) (94/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 123, hadoop04, executor 2, partition 121, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 121) in 110 ms on hadoop04 (executor 2) (95/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 124, hadoop03, executor 1, partition 122, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 122) in 115 ms on hadoop03 (executor 1) (96/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 125, hadoop04, executor 2, partition 123, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 123) in 136 ms on hadoop04 (executor 2) (97/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 126, hadoop03, executor 1, partition 124, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 124) in 124 ms on hadoop03 (executor 1) (98/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 125) in 140 ms on hadoop04 (executor 2) (99/100)</span><br><span class="line">19/04/12 16:57:04 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 126) in 145 ms on hadoop03 (executor 1) (100/100)</span><br><span class="line">19/04/12 16:57:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:57:04 INFO DAGScheduler: ResultStage 7 (show at WindowFunctionTest.scala:45) finished in 26.819 s</span><br><span class="line">19/04/12 16:57:04 INFO DAGScheduler: Job 3 finished: show at WindowFunctionTest.scala:45, took 27.209729 s</span><br><span class="line">19/04/12 16:57:05 INFO SparkContext: Starting job: show at WindowFunctionTest.scala:45</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Got job 4 (show at WindowFunctionTest.scala:45) with 75 output partitions</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Final stage: ResultStage 9 (show at WindowFunctionTest.scala:45)</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45), which has no missing parents</span><br><span class="line">19/04/12 16:57:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.4 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:57:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.8 KB, free 447.2 MB)</span><br><span class="line">19/04/12 16:57:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hadoop04:42715 (size: 8.8 KB, free: 447.3 MB)</span><br><span class="line">19/04/12 16:57:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161</span><br><span class="line">19/04/12 16:57:05 INFO DAGScheduler: Submitting 75 missing tasks from ResultStage 9 (MapPartitionsRDD[8] at show at WindowFunctionTest.scala:45) (first 15 tasks are for partitions Vector(125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139))</span><br><span class="line">19/04/12 16:57:05 INFO YarnScheduler: Adding task set 9.0 with 75 tasks</span><br><span class="line">19/04/12 16:57:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 127, hadoop04, executor 2, partition 125, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:05 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 128, hadoop03, executor 1, partition 126, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hadoop04:38267 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 129, hadoop04, executor 2, partition 127, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 127) in 398 ms on hadoop04 (executor 2) (1/75)</span><br><span class="line">19/04/12 16:57:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hadoop03:45104 (size: 8.8 KB, free: 366.3 MB)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 130, hadoop04, executor 2, partition 128, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 129) in 259 ms on hadoop04 (executor 2) (2/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 131, hadoop03, executor 1, partition 129, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 128) in 796 ms on hadoop03 (executor 1) (3/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 132, hadoop04, executor 2, partition 130, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 130) in 277 ms on hadoop04 (executor 2) (4/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 133, hadoop03, executor 1, partition 131, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 131) in 188 ms on hadoop03 (executor 1) (5/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 134, hadoop03, executor 1, partition 132, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 133) in 173 ms on hadoop03 (executor 1) (6/75)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 135, hadoop04, executor 2, partition 133, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:06 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 132) in 289 ms on hadoop04 (executor 2) (7/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 136, hadoop03, executor 1, partition 134, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 134) in 206 ms on hadoop03 (executor 1) (8/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 137, hadoop04, executor 2, partition 135, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 135) in 187 ms on hadoop04 (executor 2) (9/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 138, hadoop03, executor 1, partition 136, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 139, hadoop04, executor 2, partition 137, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 136) in 218 ms on hadoop03 (executor 1) (10/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 140, hadoop03, executor 1, partition 138, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 138) in 102 ms on hadoop03 (executor 1) (11/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 137) in 232 ms on hadoop04 (executor 2) (12/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 141, hadoop03, executor 1, partition 139, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 140) in 96 ms on hadoop03 (executor 1) (13/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 142, hadoop04, executor 2, partition 140, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 139) in 200 ms on hadoop04 (executor 2) (14/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 143, hadoop03, executor 1, partition 141, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 141) in 156 ms on hadoop03 (executor 1) (15/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 144, hadoop03, executor 1, partition 142, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 143) in 234 ms on hadoop03 (executor 1) (16/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 145, hadoop04, executor 2, partition 143, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 142) in 453 ms on hadoop04 (executor 2) (17/75)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 146, hadoop03, executor 1, partition 144, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:07 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 144) in 273 ms on hadoop03 (executor 1) (18/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 147, hadoop04, executor 2, partition 145, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 145) in 220 ms on hadoop04 (executor 2) (19/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 148, hadoop03, executor 1, partition 146, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 146) in 178 ms on hadoop03 (executor 1) (20/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 149, hadoop04, executor 2, partition 147, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 147) in 313 ms on hadoop04 (executor 2) (21/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 150, hadoop03, executor 1, partition 148, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 148) in 279 ms on hadoop03 (executor 1) (22/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 151, hadoop04, executor 2, partition 149, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 149) in 371 ms on hadoop04 (executor 2) (23/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 152, hadoop03, executor 1, partition 150, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 150) in 291 ms on hadoop03 (executor 1) (24/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 153, hadoop04, executor 2, partition 151, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 151) in 321 ms on hadoop04 (executor 2) (25/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 154, hadoop03, executor 1, partition 152, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 152) in 385 ms on hadoop03 (executor 1) (26/75)</span><br><span class="line">19/04/12 16:57:08 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 155, hadoop03, executor 1, partition 153, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 156, hadoop04, executor 2, partition 154, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 153) in 386 ms on hadoop04 (executor 2) (27/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 154) in 332 ms on hadoop03 (executor 1) (28/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 157, hadoop03, executor 1, partition 155, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 155) in 199 ms on hadoop03 (executor 1) (29/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 158, hadoop04, executor 2, partition 156, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 156) in 303 ms on hadoop04 (executor 2) (30/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 159, hadoop04, executor 2, partition 157, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 158) in 94 ms on hadoop04 (executor 2) (31/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 160, hadoop03, executor 1, partition 158, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 157) in 276 ms on hadoop03 (executor 1) (32/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 161, hadoop04, executor 2, partition 159, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 159) in 171 ms on hadoop04 (executor 2) (33/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 162, hadoop03, executor 1, partition 160, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 160) in 182 ms on hadoop03 (executor 1) (34/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 163, hadoop03, executor 1, partition 161, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 164, hadoop04, executor 2, partition 162, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 165, hadoop04, executor 2, partition 163, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 164) in 52 ms on hadoop04 (executor 2) (35/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 161) in 191 ms on hadoop04 (executor 2) (36/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 162) in 206 ms on hadoop03 (executor 1) (37/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 166, hadoop03, executor 1, partition 164, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 167, hadoop04, executor 2, partition 165, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 165) in 108 ms on hadoop04 (executor 2) (38/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 168, hadoop04, executor 2, partition 166, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 163) in 218 ms on hadoop03 (executor 1) (39/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 167) in 88 ms on hadoop04 (executor 2) (40/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 169, hadoop03, executor 1, partition 167, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 166) in 112 ms on hadoop03 (executor 1) (41/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 170, hadoop03, executor 1, partition 168, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 169) in 75 ms on hadoop03 (executor 1) (42/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 171, hadoop04, executor 2, partition 169, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 168) in 162 ms on hadoop04 (executor 2) (43/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 172, hadoop03, executor 1, partition 170, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 173, hadoop04, executor 2, partition 171, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 170) in 96 ms on hadoop03 (executor 1) (44/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 174, hadoop03, executor 1, partition 172, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 171) in 75 ms on hadoop04 (executor 2) (45/75)</span><br><span class="line">19/04/12 16:57:09 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 172) in 49 ms on hadoop03 (executor 1) (46/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 175, hadoop03, executor 1, partition 173, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 174) in 85 ms on hadoop03 (executor 1) (47/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 176, hadoop04, executor 2, partition 174, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 177, hadoop03, executor 1, partition 175, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 178, hadoop03, executor 1, partition 176, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 177) in 38 ms on hadoop03 (executor 1) (48/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 173) in 141 ms on hadoop04 (executor 2) (49/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 179, hadoop03, executor 1, partition 177, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 175) in 123 ms on hadoop03 (executor 1) (50/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 178) in 57 ms on hadoop03 (executor 1) (51/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 180, hadoop04, executor 2, partition 178, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 176) in 114 ms on hadoop04 (executor 2) (52/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 181, hadoop03, executor 1, partition 179, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 182, hadoop03, executor 1, partition 180, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 183, hadoop04, executor 2, partition 181, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 179) in 159 ms on hadoop03 (executor 1) (53/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 184, hadoop03, executor 1, partition 182, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 181) in 110 ms on hadoop03 (executor 1) (54/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 185, hadoop04, executor 2, partition 183, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 180) in 165 ms on hadoop04 (executor 2) (55/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 182) in 262 ms on hadoop03 (executor 1) (56/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 186, hadoop03, executor 1, partition 184, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 187, hadoop04, executor 2, partition 185, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 183) in 331 ms on hadoop04 (executor 2) (57/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 184) in 301 ms on hadoop03 (executor 1) (58/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 185) in 289 ms on hadoop04 (executor 2) (59/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 188, hadoop03, executor 1, partition 186, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 186) in 151 ms on hadoop03 (executor 1) (60/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 189, hadoop04, executor 2, partition 187, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 187) in 197 ms on hadoop04 (executor 2) (61/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 190, hadoop03, executor 1, partition 188, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 188) in 114 ms on hadoop03 (executor 1) (62/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 191, hadoop04, executor 2, partition 189, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 189) in 148 ms on hadoop04 (executor 2) (63/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 192, hadoop03, executor 1, partition 190, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 190) in 113 ms on hadoop03 (executor 1) (64/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 193, hadoop03, executor 1, partition 191, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 194, hadoop04, executor 2, partition 192, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 191) in 129 ms on hadoop04 (executor 2) (65/75)</span><br><span class="line">19/04/12 16:57:10 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 192) in 105 ms on hadoop03 (executor 1) (66/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 195, hadoop03, executor 1, partition 193, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 193) in 126 ms on hadoop03 (executor 1) (67/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 196, hadoop04, executor 2, partition 194, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 194) in 131 ms on hadoop04 (executor 2) (68/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 197, hadoop04, executor 2, partition 195, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 196) in 217 ms on hadoop04 (executor 2) (69/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 198, hadoop03, executor 1, partition 196, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 195) in 301 ms on hadoop03 (executor 1) (70/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 199, hadoop04, executor 2, partition 197, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 197) in 270 ms on hadoop04 (executor 2) (71/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 200, hadoop03, executor 1, partition 198, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 198) in 256 ms on hadoop03 (executor 1) (72/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 201, hadoop04, executor 2, partition 199, PROCESS_LOCAL, 7778 bytes)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 199) in 282 ms on hadoop04 (executor 2) (73/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 200) in 214 ms on hadoop03 (executor 1) (74/75)</span><br><span class="line">19/04/12 16:57:11 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 201) in 104 ms on hadoop04 (executor 2) (75/75)</span><br><span class="line">19/04/12 16:57:11 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool </span><br><span class="line">19/04/12 16:57:11 INFO DAGScheduler: ResultStage 9 (show at WindowFunctionTest.scala:45) finished in 6.626 s</span><br><span class="line">19/04/12 16:57:11 INFO DAGScheduler: Job 4 finished: show at WindowFunctionTest.scala:45, took 6.700226 s</span><br><span class="line">19/04/12 16:57:14 INFO SparkUI: Stopped Spark web UI at http://hadoop04:4040</span><br><span class="line">19/04/12 16:57:14 INFO YarnClientSchedulerBackend: Interrupting monitor thread</span><br><span class="line">19/04/12 16:57:15 INFO YarnClientSchedulerBackend: Shutting down all executors</span><br><span class="line">19/04/12 16:57:15 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down</span><br><span class="line">19/04/12 16:57:15 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices</span><br><span class="line">(serviceOption=None,</span><br><span class="line"> services=List(),</span><br><span class="line"> started=false)</span><br><span class="line">19/04/12 16:57:15 INFO YarnClientSchedulerBackend: Stopped</span><br><span class="line">19/04/12 16:57:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span><br><span class="line">19/04/12 16:57:17 INFO MemoryStore: MemoryStore cleared</span><br><span class="line">19/04/12 16:57:17 INFO BlockManager: BlockManager stopped</span><br><span class="line">19/04/12 16:57:17 INFO BlockManagerMaster: BlockManagerMaster stopped</span><br><span class="line">19/04/12 16:57:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span><br><span class="line">19/04/12 16:57:18 INFO SparkContext: Successfully stopped SparkContext</span><br><span class="line">19/04/12 16:57:19 INFO ShutdownHookManager: Shutdown hook called</span><br><span class="line">19/04/12 16:57:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-f3533ae6-b45b-4a1f-8119-0c12775c5a33</span><br><span class="line">+-----+----------+--------+---------+</span><br><span class="line">| site|      date|user_cnt|MovingAvg|</span><br><span class="line">+-----+----------+--------+---------+</span><br><span class="line">|站点1|2018-01-01|      50|     47.5|</span><br><span class="line">|站点1|2018-01-02|      45|     50.0|</span><br><span class="line">|站点1|2018-01-03|      55|     50.0|</span><br><span class="line">|站点2|2018-01-01|      25|     27.0|</span><br><span class="line">|站点2|2018-01-02|      29|     27.0|</span><br><span class="line">|站点2|2018-01-03|      27|     28.0|</span><br><span class="line">+-----+----------+--------+---------+</span><br><span class="line"></span><br><span class="line">Disconnected from the target VM, address: '127.0.0.1:45315', transport: 'socket'</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>至此,IDEA已经能连接上yarn集群。</p>
<h1 id="开启远程yarn-client-debug调试"><a href="#开启远程yarn-client-debug调试" class="headerlink" title="开启远程yarn client debug调试"></a>开启远程yarn client debug调试</h1><h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p>将我们的应用程序打包(在hadoop05机器)，发送到hadoop01机器，并在hadoop01上启动我们的应用程序,具体如下：  </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/hadoop/worker/sparklearning/target/   </span><br><span class="line"></span><br><span class="line">scp -r sparklearning-1.0-SNAPSHOT.jar  hadoop@hadoop01:/home/hadoop/worker/sparklearning/target/</span><br><span class="line"></span><br><span class="line">scp -r sparklearning-1.0-SNAPSHOT.jar  hadoop@hadoop01:/home/hadoop/worker/sparklearning/target/</span><br></pre></td></tr></table></figure>
<p><strong>在hadoop01启动</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --class com.xh.spark.sql.function.WindowFunctionTest \</span><br><span class="line">    --master yarn \</span><br><span class="line">    --deploy-mode client \</span><br><span class="line">    --driver-memory 512m \</span><br><span class="line">    --executor-memory 512m \</span><br><span class="line">    --executor-cores 6 \</span><br><span class="line">	--driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005" \</span><br><span class="line">    /home/hadoop/worker/sparklearning/target/sparklearning-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure></p>
<h2 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h2><p>在idea中Edit Configurations ——&gt; 点击+号 ——&gt;Remote —— Configuration ——&gt; Debugger Mode (用Attach to remote JVM)——&gt;host(hadoop01)<br>——&gt; Port(默认5005，也可以选择使用未使用的端口，比如5656) ——&gt; Command line arguments for remote JVN (-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005)</p>
<p>然后点击小虫子图标就可以run程序了！！！！</p>
<h1 id="问题解决分享"><a href="#问题解决分享" class="headerlink" title="问题解决分享"></a>问题解决分享</h1><h2 id="Could-not-parse-Master-URL"><a href="#Could-not-parse-Master-URL" class="headerlink" title="Could not parse Master URL"></a>Could not parse Master URL</h2><p><strong>解决：</strong> 在pom.xml中添加如下依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-yarn_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Name-node-is-in-safe-mode"><a href="#Name-node-is-in-safe-mode" class="headerlink" title="Name node is in safe mode"></a>Name node is in safe mode</h2><p><strong>解决：</strong>  在hadoop所在linux环境输入如下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode leave</span><br></pre></td></tr></table></figure></p>
<h2 id="Exception-in-thread-“main”-org-apache-hadoop-security-AccessControlException"><a href="#Exception-in-thread-“main”-org-apache-hadoop-security-AccessControlException" class="headerlink" title="Exception in thread “main” org.apache.hadoop.security.AccessControlException:"></a>Exception in thread “main” org.apache.hadoop.security.AccessControlException:</h2><blockquote>
<p>Exception in thread “main” org.apache.hadoop.security.AccessControlException: Permission denied: user=deeplearning, access=WRITE, inode=”/user/deeplearning/.sparkStaging/application_1554947367832_0002”:hadoop:supergroup:drwxr-xr-x</p>
</blockquote>
<p><strong>解决：</strong>  在hdfs-site.xml添加如下配置<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Diagnostics-Container-pid-3293-containerID-container-e12-1555047553207-0002-02-000001-is-running-beyond-virtual-memory-limits-Current-usage-116-1-MB-of-1-GB-physical-memory-used-2-3-GB-of-2-1-GB-virtual-memory-used-Killing-container"><a href="#Diagnostics-Container-pid-3293-containerID-container-e12-1555047553207-0002-02-000001-is-running-beyond-virtual-memory-limits-Current-usage-116-1-MB-of-1-GB-physical-memory-used-2-3-GB-of-2-1-GB-virtual-memory-used-Killing-container" class="headerlink" title="Diagnostics: Container [pid=3293,containerID=container_e12_1555047553207_0002_02_000001] is running beyond virtual memory limits. Current usage: 116.1 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container."></a>Diagnostics: Container [pid=3293,containerID=container_e12_1555047553207_0002_02_000001] is running beyond virtual memory limits. Current usage: 116.1 MB of 1 GB physical memory used; 2.3 GB of 2.1 GB virtual memory used. Killing container.</h2><p><strong>解决：</strong> 在yarn-site.xml文件中添加如下配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;5&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="问题解决参考文章"><a href="#问题解决参考文章" class="headerlink" title="问题解决参考文章"></a>问题解决参考文章</h2><p><a href="https://stackoverflow.com/questions/41054700/could-not-parse-master-url" target="_blank" rel="noopener">https://stackoverflow.com/questions/41054700/could-not-parse-master-url</a></p>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a></p>
<p><a href="http://www.cnblogs.com/lisi2016/p/6863923.html" target="_blank" rel="noopener">http://www.cnblogs.com/lisi2016/p/6863923.html</a>  </p>
<h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢!"></a>致谢!</h1><p>如有遇到问题，将问题发送至本人邮箱(<a href="mailto:t_spider@aliyun.com" target="_blank" rel="noopener">t_spider@aliyun.com</a>)。欢迎大家一起讨论问题！</p>

          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/25/elasticsearch学习第四弹：聚合案例/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/25/elasticsearch学习第四弹：聚合案例/" itemprop="url">elasticsearch学习第四弹：聚合案例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-25T18:57:58+08:00">
                2019-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/25/elasticsearch学习第四弹：聚合案例/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/25/elasticsearch学习第四弹：聚合案例/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  331
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="计算每个tag下的商品数量"><a href="#计算每个tag下的商品数量" class="headerlink" title="计算每个tag下的商品数量"></a>计算每个tag下的商品数量</h1><p>将文本field的fielddata属性设置为true<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">PUT</span> /ecommerce/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"properties"</span>: &#123;</span><br><span class="line">    <span class="string">"tags"</span>: &#123;</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">      <span class="string">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span>: &#123;</span><br><span class="line">    <span class="string">"group_by_tags"</span>: &#123;</span><br><span class="line">      <span class="string">"terms"</span>: &#123; <span class="string">"field"</span>: <span class="string">"tags"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="对名称中包含yagao的商品，计算每个tag下的商品数量"><a href="#对名称中包含yagao的商品，计算每个tag下的商品数量" class="headerlink" title="对名称中包含yagao的商品，计算每个tag下的商品数量"></a>对名称中包含yagao的商品，计算每个tag下的商品数量</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"name"</span>: <span class="string">"yagao"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"aggs"</span>: &#123;</span><br><span class="line">    <span class="string">"all_tags"</span>: &#123;</span><br><span class="line">      <span class="string">"terms"</span>: &#123;</span><br><span class="line">        <span class="string">"field"</span>: <span class="string">"tags"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="先分组，再算每组的平均值，计算每个tag下的商品的平均价格"><a href="#先分组，再算每组的平均值，计算每个tag下的商品的平均价格" class="headerlink" title="先分组，再算每组的平均值，计算每个tag下的商品的平均价格"></a>先分组，再算每组的平均值，计算每个tag下的商品的平均价格</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"size"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">"aggs"</span> : &#123;</span><br><span class="line">        <span class="string">"group_by_tags"</span> : &#123;</span><br><span class="line">            <span class="string">"terms"</span> : &#123; <span class="string">"field"</span> : <span class="string">"tags"</span> &#125;,</span><br><span class="line">            <span class="string">"aggs"</span> : &#123;</span><br><span class="line">                <span class="string">"avg_price"</span> : &#123;</span><br><span class="line">                    <span class="string">"avg"</span> : &#123; <span class="string">"field"</span> : <span class="string">"price"</span> &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="计算每个tag下的商品的平均价格，并且按照平均价格降序排序"><a href="#计算每个tag下的商品的平均价格，并且按照平均价格降序排序" class="headerlink" title="计算每个tag下的商品的平均价格，并且按照平均价格降序排序"></a>计算每个tag下的商品的平均价格，并且按照平均价格降序排序</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"size"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">"aggs"</span> : &#123;</span><br><span class="line">        <span class="string">"all_tags"</span> : &#123;</span><br><span class="line">            <span class="string">"terms"</span> : &#123; <span class="string">"field"</span> : <span class="string">"tags"</span>, <span class="string">"order"</span>: &#123; <span class="string">"avg_price"</span>: <span class="string">"desc"</span> &#125; &#125;,</span><br><span class="line">            <span class="string">"aggs"</span> : &#123;</span><br><span class="line">                <span class="string">"avg_price"</span> : &#123;</span><br><span class="line">                    <span class="string">"avg"</span> : &#123; <span class="string">"field"</span> : <span class="string">"price"</span> &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="按照指定的价格范围区间进行分组，然后在每组内再按照tag进行分组，最后再计算每组的平均价格"><a href="#按照指定的价格范围区间进行分组，然后在每组内再按照tag进行分组，最后再计算每组的平均价格" class="headerlink" title="按照指定的价格范围区间进行分组，然后在每组内再按照tag进行分组，最后再计算每组的平均价格"></a>按照指定的价格范围区间进行分组，然后在每组内再按照tag进行分组，最后再计算每组的平均价格</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">"aggs"</span>: &#123;</span><br><span class="line">    <span class="string">"group_by_price"</span>: &#123;</span><br><span class="line">      <span class="string">"range"</span>: &#123;</span><br><span class="line">        <span class="string">"field"</span>: <span class="string">"price"</span>,</span><br><span class="line">        <span class="string">"ranges"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"from"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="string">"to"</span>: <span class="number">20</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"from"</span>: <span class="number">20</span>,</span><br><span class="line">            <span class="string">"to"</span>: <span class="number">40</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"from"</span>: <span class="number">40</span>,</span><br><span class="line">            <span class="string">"to"</span>: <span class="number">50</span></span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"aggs"</span>: &#123;</span><br><span class="line">        <span class="string">"group_by_tags"</span>: &#123;</span><br><span class="line">          <span class="string">"terms"</span>: &#123;</span><br><span class="line">            <span class="string">"field"</span>: <span class="string">"tags"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">"aggs"</span>: &#123;</span><br><span class="line">            <span class="string">"average_price"</span>: &#123;</span><br><span class="line">              <span class="string">"avg"</span>: &#123;</span><br><span class="line">                <span class="string">"field"</span>: <span class="string">"price"</span></span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/25/elasticsearch学习第二弹：CRUD操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/25/elasticsearch学习第二弹：CRUD操作/" itemprop="url">elasticsearch学习第二弹：CRUD操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-25T18:57:58+08:00">
                2019-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/25/elasticsearch学习第二弹：CRUD操作/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/25/elasticsearch学习第二弹：CRUD操作/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  261
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简单的索引操作"><a href="#简单的索引操作" class="headerlink" title="简单的索引操作"></a>简单的索引操作</h1><h2 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">PUT</span> /test_index?pretty</span><br></pre></td></tr></table></figure>
<h2 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a>查看索引</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> _cat/indices?v</span><br></pre></td></tr></table></figure>
<h2 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DELETE</span> /test_index?pretty</span><br></pre></td></tr></table></figure>
<h1 id="CRUD文档"><a href="#CRUD文档" class="headerlink" title="CRUD文档"></a>CRUD文档</h1><p>es会自动建立index和type，不需要提前创建，而且es默认会对document每个field都建立倒排索引，让其可以被搜索。</p>
<h2 id="新增文档"><a href="#新增文档" class="headerlink" title="新增文档"></a>新增文档</h2><p><strong>格式</strong>：<br><strong>注意</strong>：elasticsearch7.0已经没有type。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">PUT</span> /index/_doc/id</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"json数据"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">PUT</span> /ecommerce/_doc/<span class="number">1</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"name"</span> : <span class="string">"jiaqiangban gaolujie yagao"</span>,</span><br><span class="line">    <span class="string">"desc"</span> :  <span class="string">"gaoxiao meibai"</span>,</span><br><span class="line">    <span class="string">"price"</span> :  <span class="number">30</span>,</span><br><span class="line">    <span class="string">"producer"</span> :      <span class="string">"gaolujie producer"</span>,</span><br><span class="line">    <span class="string">"tags"</span>: [ <span class="string">"meibai"</span>, <span class="string">"fangzhu"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="查询文档"><a href="#查询文档" class="headerlink" title="查询文档"></a>查询文档</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_doc/<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><strong>sql方式</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">POST</span> /_xpack/sql?format=txt</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"query"</span>: <span class="string">"select name,price from ecommerce where price &gt; 20"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="修改文档"><a href="#修改文档" class="headerlink" title="修改文档"></a>修改文档</h2><p><strong>两种方式</strong>：一种替换、一种更新的方式。   </p>
<h3 id="替换方式"><a href="#替换方式" class="headerlink" title="替换方式"></a>替换方式</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">PUT</span> /ecommerce/_doc/<span class="number">1</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"name"</span> : <span class="string">"jiaqiangban gaolujie yagao"</span>,</span><br><span class="line">    <span class="string">"desc"</span> :  <span class="string">"gaoxiao meibai"</span>,</span><br><span class="line">    <span class="string">"price"</span> :  <span class="number">40</span>,</span><br><span class="line">    <span class="string">"producer"</span> :      <span class="string">"gaolujie producer"</span>,</span><br><span class="line">    <span class="string">"tags"</span>: [ <span class="string">"meibai"</span>, <span class="string">"fangzhu"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>缺点</strong>：替换方式有一个不好，必须带上所有的field，才能去进行信息的修改。</p>
<h3 id="更新方式"><a href="#更新方式" class="headerlink" title="更新方式"></a>更新方式</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">POST</span> /ecommerce/_update/<span class="number">1</span>/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"doc"</span>: &#123;</span><br><span class="line">    <span class="string">"name"</span>: <span class="string">"jiaqiangban gaolujie yagao"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DELETE</span> /ecommerce/_doc/<span class="number">1</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/25/elasticsearch学习第三弹：查询的几种方式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/25/elasticsearch学习第三弹：查询的几种方式/" itemprop="url">elasticsearch学习第三弹：查询的几种方式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-25T18:57:58+08:00">
                2019-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/25/elasticsearch学习第三弹：查询的几种方式/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/25/elasticsearch学习第三弹：查询的几种方式/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  771
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">PUT</span> /ecommerce/_doc/<span class="number">1</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"jiajieshi yagao"</span>,</span><br><span class="line">  <span class="string">"desc"</span>: <span class="string">"youxiao fangzhu"</span>,</span><br><span class="line">  <span class="string">"price"</span>: <span class="number">25</span>,</span><br><span class="line">  <span class="string">"producer"</span>: <span class="string">"jiajieshi producer"</span>,</span><br><span class="line">  <span class="string">"tags"</span>: [</span><br><span class="line">    <span class="string">"fangzhu"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">PUT</span> /ecommerce/_doc/<span class="number">2</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"jiajieshi yagao"</span>,</span><br><span class="line">  <span class="string">"desc"</span>: <span class="string">"youxiao fangzhu"</span>,</span><br><span class="line">  <span class="string">"price"</span>: <span class="number">25</span>,</span><br><span class="line">  <span class="string">"producer"</span>: <span class="string">"jiajieshi producer"</span>,</span><br><span class="line">  <span class="string">"tags"</span>: [</span><br><span class="line">    <span class="string">"fangzhu"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">PUT</span> /ecommerce/_doc/<span class="number">3</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"zhonghua yagao"</span>,</span><br><span class="line">  <span class="string">"desc"</span>: <span class="string">"caoben zhiwu"</span>,</span><br><span class="line">  <span class="string">"price"</span>: <span class="number">40</span>,</span><br><span class="line">  <span class="string">"producer"</span>: <span class="string">"zhonghua producer"</span>,</span><br><span class="line">  <span class="string">"tags"</span>: [</span><br><span class="line">    <span class="string">"qingxin"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="query-string-search"><a href="#query-string-search" class="headerlink" title="query string search"></a>query string search</h1><p>搜索全部:GET /ecommerce/_search/<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search/</span><br></pre></td></tr></table></figure></p>
<p><strong>结果</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"took"</span> : <span class="number">48</span>,</span><br><span class="line">  <span class="string">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="string">"_shards"</span> : &#123;</span><br><span class="line">    <span class="string">"total"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="string">"successful"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="string">"skipped"</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="string">"failed"</span> : <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"hits"</span> : &#123;</span><br><span class="line">    <span class="string">"total"</span> : &#123;</span><br><span class="line">      <span class="string">"value"</span> : <span class="number">2</span>,</span><br><span class="line">      <span class="string">"relation"</span> : <span class="string">"eq"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"max_score"</span> : <span class="number">1.0</span>,</span><br><span class="line">    <span class="string">"hits"</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"_index"</span> : <span class="string">"ecommerce"</span>,</span><br><span class="line">        <span class="string">"_type"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="string">"_id"</span> : <span class="string">"PBRZU2oB2AOCCrYzyACo"</span>,</span><br><span class="line">        <span class="string">"_score"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">"_source"</span> : &#123;</span><br><span class="line">          <span class="string">"name"</span> : <span class="string">"gaolujie yagao"</span>,</span><br><span class="line">          <span class="string">"desc"</span> : <span class="string">"gaoxiao meibai"</span>,</span><br><span class="line">          <span class="string">"price"</span> : <span class="number">30</span>,</span><br><span class="line">          <span class="string">"producer"</span> : <span class="string">"gaolujie producer"</span>,</span><br><span class="line">          <span class="string">"tags"</span> : [</span><br><span class="line">            <span class="string">"meibai"</span>,</span><br><span class="line">            <span class="string">"fangzhu"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"_index"</span> : <span class="string">"ecommerce"</span>,</span><br><span class="line">        <span class="string">"_type"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="string">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="string">"_score"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">"_source"</span> : &#123;</span><br><span class="line">          <span class="string">"name"</span> : <span class="string">"jiaqiangban gaolujie yagao"</span>,</span><br><span class="line">          <span class="string">"desc"</span> : <span class="string">"gaoxiao meibai"</span>,</span><br><span class="line">          <span class="string">"price"</span> : <span class="number">30</span>,</span><br><span class="line">          <span class="string">"producer"</span> : <span class="string">"gaolujie producer"</span>,</span><br><span class="line">          <span class="string">"tags"</span> : [</span><br><span class="line">            <span class="string">"meibai"</span>,</span><br><span class="line">            <span class="string">"fangzhu"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>took</strong>：耗费了几毫秒。<br><strong>timed_out</strong>：是否超时，这里是没有。<br>_shards：数据拆成了5个分片，所以对于搜索请求，会打到所有的primary shard（或者是它的某个replica shard也可以）。<br><strong>hits.total</strong>：查询结果的数量，3个document。<br><strong>hits.max_score</strong>：score的含义，就是document对于一个search的相关度的匹配分数，越相关，就越匹配，分数也高。<br><strong>hits.hits</strong>：包含了匹配搜索的document的详细数据 。</p>
<h1 id="query-DSL"><a href="#query-DSL" class="headerlink" title="query DSL"></a>query DSL</h1><p>DSL：Domain Specified Language，特定领域的语言<br>http request body：请求体，可以用json的格式来构建查询语法，比较方便，可以构建各种复杂的语法，比query string search肯定强大多了。</p>
<p>查询所有的商品<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123; <span class="string">"match_all"</span>: &#123;&#125; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>查询名称包含yagao的商品，同时按照价格降序排序<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">   <span class="string">"match"</span>: &#123;</span><br><span class="line">     <span class="string">"name"</span>: <span class="string">"yagao"</span></span><br><span class="line">   &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"sort"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"price"</span>: &#123;</span><br><span class="line">        <span class="string">"order"</span>: <span class="string">"desc"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>分页查询商品，总共2条商品，假设每页就显示1条商品，现在显示第2页，所以就查出来第2个商品.</p>
<p>指定要查询出来商品的名称和价格就可以<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match_all"</span>: &#123;&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"_source"</span>:[<span class="string">"name"</span>,<span class="string">"price"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="query-filter"><a href="#query-filter" class="headerlink" title="query filter"></a>query filter</h1><p>搜索商品名称包含yagao，而且售价大于25元的商品<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"query"</span> : &#123;</span><br><span class="line">        <span class="string">"bool"</span> : &#123;</span><br><span class="line">            <span class="string">"must"</span> : &#123;</span><br><span class="line">                <span class="string">"match"</span> : &#123;</span><br><span class="line">                    <span class="string">"name"</span> : <span class="string">"yagao"</span> </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">"filter"</span> : &#123;</span><br><span class="line">                <span class="string">"range"</span> : &#123;</span><br><span class="line">                    <span class="string">"price"</span> : &#123; <span class="string">"gt"</span> : <span class="number">30</span> &#125; </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="full-text-search（全文检索）"><a href="#full-text-search（全文检索）" class="headerlink" title="full-text search（全文检索）"></a>full-text search（全文检索）</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"query"</span> : &#123;</span><br><span class="line">        <span class="string">"match"</span> : &#123;</span><br><span class="line">            <span class="string">"producer"</span> : <span class="string">"yagao producer"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="phrase-search（短语搜索）"><a href="#phrase-search（短语搜索）" class="headerlink" title="phrase search（短语搜索）"></a>phrase search（短语搜索）</h1><p>跟全文检索相对应，相反，全文检索会将输入的搜索串拆解开来，去倒排索引里面去一一匹配，只要能匹配上任意一个拆解后的单词，就可以作为结果返回<br>phrase search，要求输入的搜索串，必须在指定的字段文本中，完全包含一模一样的，才可以算匹配，才能作为结果返回<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"query"</span> : &#123;</span><br><span class="line">        <span class="string">"match_phrase"</span> : &#123;</span><br><span class="line">            <span class="string">"producer"</span> : <span class="string">"yagao producer"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="highlight-search（高亮搜索结果）"><a href="#highlight-search（高亮搜索结果）" class="headerlink" title="highlight search（高亮搜索结果）"></a>highlight search（高亮搜索结果）</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"query"</span> : &#123;</span><br><span class="line">        <span class="string">"match"</span> : &#123;</span><br><span class="line">            <span class="string">"producer"</span> : <span class="string">"producer"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"highlight"</span>: &#123;</span><br><span class="line">        <span class="string">"fields"</span> : &#123;</span><br><span class="line">            <span class="string">"producer"</span> : &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/25/elasticsearch学习第一弹：集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/25/elasticsearch学习第一弹：集群搭建/" itemprop="url">elasticsearch学习第一弹：集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-25T18:57:58+08:00">
                2019-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/25/elasticsearch学习第一弹：集群搭建/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/25/elasticsearch学习第一弹：集群搭建/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,868
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  17
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h1><p><strong>版本</strong>： elasticsearch7.0</p>
<h2 id="下载资源包"><a href="#下载资源包" class="headerlink" title="下载资源包"></a>下载资源包</h2><p>到官方网站 <a href="https://www.elastic.co/downloads/" target="_blank" rel="noopener">https://www.elastic.co/downloads/</a> 分别下载需要安装的组件 </p>
<h2 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h2><table>
<thead>
<tr>
<th>主机名</th>
<th>ip</th>
<th>组件</th>
<th>节点类型 </th>
</tr>
</thead>
<tbody>
<tr>
<td>hadoop01</td>
<td>192.168.8.81</td>
<td>elasticsearch、kibana</td>
<td>主节点、非数据节点</td>
</tr>
<tr>
<td>hadoop02</td>
<td>192.168.8.82</td>
<td>elasticsearch</td>
<td>主节点、非数据节点</td>
</tr>
<tr>
<td>hadoop03</td>
<td>192.168.8.83</td>
<td>elasticsearch</td>
<td>非主节点、数据节点</td>
</tr>
</tbody>
</table>
<h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>elasticsearch.yml  </p>
<h3 id="hadoop01"><a href="#hadoop01" class="headerlink" title="hadoop01"></a>hadoop01</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"># ======================== <span class="type">Elasticsearch</span> <span class="type">Configuration</span> =========================</span><br><span class="line">#</span><br><span class="line"># <span class="type">NOTE</span>: <span class="type">Elasticsearch</span> comes <span class="keyword">with</span> reasonable defaults <span class="keyword">for</span> most settings.</span><br><span class="line">#       <span class="type">Before</span> you set out to tweak and tune the configuration, make sure you</span><br><span class="line">#       understand what are you trying to accomplish and the consequences.</span><br><span class="line">#</span><br><span class="line"># <span class="type">The</span> primary way of configuring a node is via <span class="keyword">this</span> file. <span class="type">This</span> template lists</span><br><span class="line"># the most important settings you may want to configure <span class="keyword">for</span> a production cluster.</span><br><span class="line">#</span><br><span class="line"># <span class="type">Please</span> consult the documentation <span class="keyword">for</span> further information on configuration options:</span><br><span class="line"># https:<span class="comment">//www.elastic.co/guide/en/elasticsearch/reference/index.html</span></span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Cluster</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Use</span> a descriptive name <span class="keyword">for</span> your cluster:</span><br><span class="line">#</span><br><span class="line">#cluster.name: my-application</span><br><span class="line">cluster.name: cluster</span><br><span class="line">#</span><br><span class="line"># ------------------------------------ <span class="type">Node</span> ------------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Use</span> a descriptive name <span class="keyword">for</span> the node:</span><br><span class="line">#</span><br><span class="line">#node.name: node<span class="number">-1</span></span><br><span class="line">node.name: node<span class="number">-1</span></span><br><span class="line">node.master: <span class="literal">true</span></span><br><span class="line">node.data: <span class="literal">false</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Add</span> custom attributes to the node:</span><br><span class="line">#</span><br><span class="line">#node.attr.rack: r1</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- <span class="type">Paths</span> ------------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Path</span> to directory where to store the data (separate multiple locations by comma):</span><br><span class="line">#</span><br><span class="line">#path.data: /path/to/data</span><br><span class="line">path.data: /home/hadoop/elasticsearch/data</span><br><span class="line">#</span><br><span class="line"># <span class="type">Path</span> to log files:</span><br><span class="line">#</span><br><span class="line">#path.logs: /path/to/logs</span><br><span class="line">path.logs: /home/hadoop/elasticsearch/logs</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- <span class="type">Memory</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Lock</span> the memory on startup:</span><br><span class="line">#</span><br><span class="line">#bootstrap.memory_lock: <span class="literal">true</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Make</span> sure that the heap size is set to about half the memory available</span><br><span class="line"># on the system and that the owner of the process is allowed to use <span class="keyword">this</span></span><br><span class="line"># limit.</span><br><span class="line">#</span><br><span class="line"># <span class="type">Elasticsearch</span> performs poorly when the system is swapping the memory.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Network</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Set</span> the bind address to a specific <span class="type">IP</span> (<span class="type">IPv4</span> or <span class="type">IPv6</span>):</span><br><span class="line">#</span><br><span class="line">#network.host: <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">network.host: <span class="number">192.168</span><span class="number">.8</span><span class="number">.81</span></span><br><span class="line">network.bind_host: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Set</span> a custom port <span class="keyword">for</span> <span class="type">HTTP</span>:</span><br><span class="line">#</span><br><span class="line">#http.port: <span class="number">9200</span></span><br><span class="line">http.port: <span class="number">9200</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the network module documentation.</span><br><span class="line">#</span><br><span class="line"># --------------------------------- <span class="type">Discovery</span> ----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Pass</span> an initial list of hosts to perform discovery when <span class="keyword">this</span> node is started:</span><br><span class="line"># <span class="type">The</span> <span class="keyword">default</span> list of hosts is [<span class="string">"127.0.0.1"</span>, <span class="string">"[::1]"</span>]</span><br><span class="line">#</span><br><span class="line">#discovery.seed_hosts: [<span class="string">"host1"</span>, <span class="string">"host2"</span>]</span><br><span class="line">#discovery.seed_hosts: [<span class="string">"192.168.8.81"</span>,<span class="string">"192.168.8.82"</span>,<span class="string">"192.168.8.83"</span>]</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"192.168.8.81"</span>, <span class="string">"192.168.8.82"</span>, <span class="string">"192.168.8.83"</span>]</span><br><span class="line">#</span><br><span class="line"># <span class="type">Bootstrap</span> the cluster using an initial set of master-eligible nodes:</span><br><span class="line">#</span><br><span class="line">#cluster.initial_master_nodes: [<span class="string">"node-1"</span>, <span class="string">"node-2"</span>]</span><br><span class="line">#可能成为主的节点</span><br><span class="line">cluster.initial_master_nodes: [<span class="string">"node-1"</span>, <span class="string">"node-2"</span>]</span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the discovery and cluster formation module documentation.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Gateway</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Block</span> initial recovery after a full cluster restart until <span class="type">N</span> nodes are started:</span><br><span class="line">#</span><br><span class="line">#gateway.recover_after_nodes: <span class="number">3</span></span><br><span class="line">#当集群内达到<span class="number">3</span>个时开始恢复数据（防止集群启动时部分节点自动恢复数据）</span><br><span class="line">gateway.recover_after_nodes: <span class="number">3</span>		</span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the gateway module documentation.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Various</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Require</span> explicit names when deleting indices:</span><br><span class="line">#</span><br><span class="line">#action.destructive_requires_name: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="hadoop04"><a href="#hadoop04" class="headerlink" title="hadoop04"></a>hadoop04</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"># ======================== <span class="type">Elasticsearch</span> <span class="type">Configuration</span> =========================</span><br><span class="line">#</span><br><span class="line"># <span class="type">NOTE</span>: <span class="type">Elasticsearch</span> comes <span class="keyword">with</span> reasonable defaults <span class="keyword">for</span> most settings.</span><br><span class="line">#       <span class="type">Before</span> you set out to tweak and tune the configuration, make sure you</span><br><span class="line">#       understand what are you trying to accomplish and the consequences.</span><br><span class="line">#</span><br><span class="line"># <span class="type">The</span> primary way of configuring a node is via <span class="keyword">this</span> file. <span class="type">This</span> template lists</span><br><span class="line"># the most important settings you may want to configure <span class="keyword">for</span> a production cluster.</span><br><span class="line">#</span><br><span class="line"># <span class="type">Please</span> consult the documentation <span class="keyword">for</span> further information on configuration options:</span><br><span class="line"># https:<span class="comment">//www.elastic.co/guide/en/elasticsearch/reference/index.html</span></span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Cluster</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Use</span> a descriptive name <span class="keyword">for</span> your cluster:</span><br><span class="line">#</span><br><span class="line">#cluster.name: my-application</span><br><span class="line">cluster.name: cluster</span><br><span class="line">#</span><br><span class="line"># ------------------------------------ <span class="type">Node</span> ------------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Use</span> a descriptive name <span class="keyword">for</span> the node:</span><br><span class="line">#</span><br><span class="line">#node.name: node<span class="number">-2</span></span><br><span class="line">node.name: node<span class="number">-1</span></span><br><span class="line">node.master: <span class="literal">true</span></span><br><span class="line">node.data: <span class="literal">false</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Add</span> custom attributes to the node:</span><br><span class="line">#</span><br><span class="line">#node.attr.rack: r1</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- <span class="type">Paths</span> ------------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Path</span> to directory where to store the data (separate multiple locations by comma):</span><br><span class="line">#</span><br><span class="line">#path.data: /path/to/data</span><br><span class="line">path.data: /home/hadoop/elasticsearch/data</span><br><span class="line">#</span><br><span class="line"># <span class="type">Path</span> to log files:</span><br><span class="line">#</span><br><span class="line">#path.logs: /path/to/logs</span><br><span class="line">path.logs: /home/hadoop/elasticsearch/logs</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- <span class="type">Memory</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Lock</span> the memory on startup:</span><br><span class="line">#</span><br><span class="line">#bootstrap.memory_lock: <span class="literal">true</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Make</span> sure that the heap size is set to about half the memory available</span><br><span class="line"># on the system and that the owner of the process is allowed to use <span class="keyword">this</span></span><br><span class="line"># limit.</span><br><span class="line">#</span><br><span class="line"># <span class="type">Elasticsearch</span> performs poorly when the system is swapping the memory.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Network</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Set</span> the bind address to a specific <span class="type">IP</span> (<span class="type">IPv4</span> or <span class="type">IPv6</span>):</span><br><span class="line">#</span><br><span class="line">#network.host: <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">network.host: <span class="number">192.168</span><span class="number">.8</span><span class="number">.82</span></span><br><span class="line">network.bind_host: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Set</span> a custom port <span class="keyword">for</span> <span class="type">HTTP</span>:</span><br><span class="line">#</span><br><span class="line">#http.port: <span class="number">9200</span></span><br><span class="line">http.port: <span class="number">9200</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the network module documentation.</span><br><span class="line">#</span><br><span class="line"># --------------------------------- <span class="type">Discovery</span> ----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Pass</span> an initial list of hosts to perform discovery when <span class="keyword">this</span> node is started:</span><br><span class="line"># <span class="type">The</span> <span class="keyword">default</span> list of hosts is [<span class="string">"127.0.0.1"</span>, <span class="string">"[::1]"</span>]</span><br><span class="line">#</span><br><span class="line">#discovery.seed_hosts: [<span class="string">"host1"</span>, <span class="string">"host2"</span>]</span><br><span class="line">#discovery.seed_hosts: [<span class="string">"192.168.8.81"</span>,<span class="string">"192.168.8.82"</span>,<span class="string">"192.168.8.83"</span>]</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"192.168.8.81"</span>, <span class="string">"192.168.8.82"</span>, <span class="string">"192.168.8.83"</span>]</span><br><span class="line">#</span><br><span class="line"># <span class="type">Bootstrap</span> the cluster using an initial set of master-eligible nodes:</span><br><span class="line">#</span><br><span class="line">#cluster.initial_master_nodes: [<span class="string">"node-1"</span>, <span class="string">"node-2"</span>]</span><br><span class="line">#可能成为主的节点</span><br><span class="line">cluster.initial_master_nodes: [<span class="string">"node-1"</span>, <span class="string">"node-2"</span>]</span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the discovery and cluster formation module documentation.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Gateway</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Block</span> initial recovery after a full cluster restart until <span class="type">N</span> nodes are started:</span><br><span class="line">#</span><br><span class="line">#gateway.recover_after_nodes: <span class="number">3</span></span><br><span class="line">#当集群内达到<span class="number">3</span>个时开始恢复数据（防止集群启动时部分节点自动恢复数据）</span><br><span class="line">gateway.recover_after_nodes: <span class="number">3</span>		</span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the gateway module documentation.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Various</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Require</span> explicit names when deleting indices:</span><br><span class="line">#</span><br><span class="line">#action.destructive_requires_name: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="hadoop03"><a href="#hadoop03" class="headerlink" title="hadoop03"></a>hadoop03</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"># ======================== <span class="type">Elasticsearch</span> <span class="type">Configuration</span> =========================</span><br><span class="line">#</span><br><span class="line"># <span class="type">NOTE</span>: <span class="type">Elasticsearch</span> comes <span class="keyword">with</span> reasonable defaults <span class="keyword">for</span> most settings.</span><br><span class="line">#       <span class="type">Before</span> you set out to tweak and tune the configuration, make sure you</span><br><span class="line">#       understand what are you trying to accomplish and the consequences.</span><br><span class="line">#</span><br><span class="line"># <span class="type">The</span> primary way of configuring a node is via <span class="keyword">this</span> file. <span class="type">This</span> template lists</span><br><span class="line"># the most important settings you may want to configure <span class="keyword">for</span> a production cluster.</span><br><span class="line">#</span><br><span class="line"># <span class="type">Please</span> consult the documentation <span class="keyword">for</span> further information on configuration options:</span><br><span class="line"># https:<span class="comment">//www.elastic.co/guide/en/elasticsearch/reference/index.html</span></span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Cluster</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Use</span> a descriptive name <span class="keyword">for</span> your cluster:</span><br><span class="line">#</span><br><span class="line">#cluster.name: my-application</span><br><span class="line">cluster.name: cluster</span><br><span class="line">#</span><br><span class="line"># ------------------------------------ <span class="type">Node</span> ------------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Use</span> a descriptive name <span class="keyword">for</span> the node:</span><br><span class="line">#</span><br><span class="line">#node.name: node<span class="number">-1</span></span><br><span class="line">node.name: node<span class="number">-3</span></span><br><span class="line">node.master: <span class="literal">false</span></span><br><span class="line">node.data: <span class="literal">true</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Add</span> custom attributes to the node:</span><br><span class="line">#</span><br><span class="line">#node.attr.rack: r1</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- <span class="type">Paths</span> ------------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Path</span> to directory where to store the data (separate multiple locations by comma):</span><br><span class="line">#</span><br><span class="line">#path.data: /path/to/data</span><br><span class="line">path.data: /home/hadoop/elasticsearch/data</span><br><span class="line">#</span><br><span class="line"># <span class="type">Path</span> to log files:</span><br><span class="line">#</span><br><span class="line">#path.logs: /path/to/logs</span><br><span class="line">path.logs: /home/hadoop/elasticsearch/logs</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- <span class="type">Memory</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Lock</span> the memory on startup:</span><br><span class="line">#</span><br><span class="line">#bootstrap.memory_lock: <span class="literal">true</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Make</span> sure that the heap size is set to about half the memory available</span><br><span class="line"># on the system and that the owner of the process is allowed to use <span class="keyword">this</span></span><br><span class="line"># limit.</span><br><span class="line">#</span><br><span class="line"># <span class="type">Elasticsearch</span> performs poorly when the system is swapping the memory.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Network</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Set</span> the bind address to a specific <span class="type">IP</span> (<span class="type">IPv4</span> or <span class="type">IPv6</span>):</span><br><span class="line">#</span><br><span class="line">#network.host: <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">network.host: <span class="number">192.168</span><span class="number">.8</span><span class="number">.83</span></span><br><span class="line">network.bind_host: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">Set</span> a custom port <span class="keyword">for</span> <span class="type">HTTP</span>:</span><br><span class="line">#</span><br><span class="line">#http.port: <span class="number">9200</span></span><br><span class="line">http.port: <span class="number">9200</span></span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the network module documentation.</span><br><span class="line">#</span><br><span class="line"># --------------------------------- <span class="type">Discovery</span> ----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Pass</span> an initial list of hosts to perform discovery when <span class="keyword">this</span> node is started:</span><br><span class="line"># <span class="type">The</span> <span class="keyword">default</span> list of hosts is [<span class="string">"127.0.0.1"</span>, <span class="string">"[::1]"</span>]</span><br><span class="line">#</span><br><span class="line">#discovery.seed_hosts: [<span class="string">"host1"</span>, <span class="string">"host2"</span>]</span><br><span class="line">#discovery.seed_hosts: [<span class="string">"192.168.8.81"</span>,<span class="string">"192.168.8.82"</span>,<span class="string">"192.168.8.83"</span>]</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"192.168.8.81"</span>, <span class="string">"192.168.8.82"</span>, <span class="string">"192.168.8.83"</span>]</span><br><span class="line">#</span><br><span class="line"># <span class="type">Bootstrap</span> the cluster using an initial set of master-eligible nodes:</span><br><span class="line">#</span><br><span class="line">#cluster.initial_master_nodes: [<span class="string">"node-1"</span>, <span class="string">"node-2"</span>]</span><br><span class="line">#可能成为主的节点</span><br><span class="line">cluster.initial_master_nodes: [<span class="string">"node-1"</span>, <span class="string">"node-2"</span>]</span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the discovery and cluster formation module documentation.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Gateway</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Block</span> initial recovery after a full cluster restart until <span class="type">N</span> nodes are started:</span><br><span class="line">#</span><br><span class="line">#gateway.recover_after_nodes: <span class="number">3</span></span><br><span class="line">#当集群内达到<span class="number">3</span>个时开始恢复数据（防止集群启动时部分节点自动恢复数据）</span><br><span class="line">gateway.recover_after_nodes: <span class="number">3</span>		</span><br><span class="line">#</span><br><span class="line"># <span class="type">For</span> more information, consult the gateway module documentation.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- <span class="type">Various</span> -----------------------------------</span><br><span class="line">#</span><br><span class="line"># <span class="type">Require</span> explicit names when deleting indices:</span><br><span class="line">#</span><br><span class="line">#action.destructive_requires_name: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h2 id="kibana配置"><a href="#kibana配置" class="headerlink" title="kibana配置"></a>kibana配置</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"># <span class="type">Kibana</span> is served by a back end server. <span class="type">This</span> setting specifies the port to use.</span><br><span class="line">#server.port: <span class="number">5601</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Specifies</span> the address to which the <span class="type">Kibana</span> server will bind. <span class="type">IP</span> addresses and host names are both valid values.</span><br><span class="line"># <span class="type">The</span> <span class="keyword">default</span> is <span class="symbol">'localhos</span>t', which usually means remote machines will not be able to connect.</span><br><span class="line"># <span class="type">To</span> allow connections from remote users, set <span class="keyword">this</span> parameter to a non-loopback address.</span><br><span class="line">server.host: <span class="string">"hadoop01"</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Enables</span> you to specify a path to mount <span class="type">Kibana</span> at <span class="keyword">if</span> you are running behind a proxy.</span><br><span class="line"># <span class="type">Use</span> the `server.rewriteBasePath` setting to tell <span class="type">Kibana</span> <span class="keyword">if</span> it should remove the basePath</span><br><span class="line"># from requests it receives, and to prevent a deprecation warning at startup.</span><br><span class="line"># <span class="type">This</span> setting cannot end in a slash.</span><br><span class="line">#server.basePath: <span class="string">""</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Specifies</span> whether <span class="type">Kibana</span> should rewrite requests that are prefixed <span class="keyword">with</span></span><br><span class="line"># `server.basePath` or require that they are rewritten by your reverse proxy.</span><br><span class="line"># <span class="type">This</span> setting was effectively always `<span class="literal">false</span>` before <span class="type">Kibana</span> <span class="number">6.3</span> and will</span><br><span class="line"># <span class="keyword">default</span> to `<span class="literal">true</span>` starting in <span class="type">Kibana</span> <span class="number">7.0</span>.</span><br><span class="line">#server.rewriteBasePath: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># <span class="type">The</span> maximum payload size in bytes <span class="keyword">for</span> incoming server requests.</span><br><span class="line">#server.maxPayloadBytes: <span class="number">1048576</span></span><br><span class="line"></span><br><span class="line"># <span class="type">The</span> <span class="type">Kibana</span> server<span class="symbol">'s</span> name.  <span class="type">This</span> is used <span class="keyword">for</span> display purposes.</span><br><span class="line">server.name: <span class="string">"kibana"</span></span><br><span class="line"></span><br><span class="line"># <span class="type">The</span> <span class="type">URLs</span> of the <span class="type">Elasticsearch</span> instances to use <span class="keyword">for</span> all your queries.</span><br><span class="line">elasticsearch.hosts: [<span class="string">"http://hadoop01:9200"</span>]</span><br><span class="line"></span><br><span class="line"># <span class="type">When</span> <span class="keyword">this</span> setting<span class="symbol">'s</span> value is <span class="literal">true</span> <span class="type">Kibana</span> uses the hostname specified in the server.host</span><br><span class="line"># setting. <span class="type">When</span> the value of <span class="keyword">this</span> setting is <span class="literal">false</span>, <span class="type">Kibana</span> uses the hostname of the host</span><br><span class="line"># that connects to <span class="keyword">this</span> <span class="type">Kibana</span> instance.</span><br><span class="line">#elasticsearch.preserveHost: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Kibana</span> uses an index in <span class="type">Elasticsearch</span> to store saved searches, visualizations and</span><br><span class="line"># dashboards. <span class="type">Kibana</span> creates a <span class="keyword">new</span> index <span class="keyword">if</span> the index doesn<span class="symbol">'t</span> already exist.</span><br><span class="line">#kibana.index: <span class="string">".kibana"</span></span><br><span class="line"></span><br><span class="line"># <span class="type">The</span> <span class="keyword">default</span> application to load.</span><br><span class="line">#kibana.defaultAppId: <span class="string">"home"</span></span><br><span class="line"></span><br><span class="line"># <span class="type">If</span> your <span class="type">Elasticsearch</span> is <span class="keyword">protected</span> <span class="keyword">with</span> basic authentication, these settings provide</span><br><span class="line"># the username and password that the <span class="type">Kibana</span> server uses to perform maintenance on the <span class="type">Kibana</span></span><br><span class="line"># index at startup. <span class="type">Your</span> <span class="type">Kibana</span> users still need to authenticate <span class="keyword">with</span> <span class="type">Elasticsearch</span>, which</span><br><span class="line"># is proxied through the <span class="type">Kibana</span> server.</span><br><span class="line">#elasticsearch.username: <span class="string">"user"</span></span><br><span class="line">#elasticsearch.password: <span class="string">"pass"</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Enables</span> <span class="type">SSL</span> and paths to the <span class="type">PEM</span>-format <span class="type">SSL</span> certificate and <span class="type">SSL</span> key files, respectively.</span><br><span class="line"># <span class="type">These</span> settings enable <span class="type">SSL</span> <span class="keyword">for</span> outgoing requests from the <span class="type">Kibana</span> server to the browser.</span><br><span class="line">#server.ssl.enabled: <span class="literal">false</span></span><br><span class="line">#server.ssl.certificate: /path/to/your/server.crt</span><br><span class="line">#server.ssl.key: /path/to/your/server.key</span><br><span class="line"></span><br><span class="line"># <span class="type">Optional</span> settings that provide the paths to the <span class="type">PEM</span>-format <span class="type">SSL</span> certificate and key files.</span><br><span class="line"># <span class="type">These</span> files validate that your <span class="type">Elasticsearch</span> backend uses the same key files.</span><br><span class="line">#elasticsearch.ssl.certificate: /path/to/your/client.crt</span><br><span class="line">#elasticsearch.ssl.key: /path/to/your/client.key</span><br><span class="line"></span><br><span class="line"># <span class="type">Optional</span> setting that enables you to specify a path to the <span class="type">PEM</span> file <span class="keyword">for</span> the certificate</span><br><span class="line"># authority <span class="keyword">for</span> your <span class="type">Elasticsearch</span> instance.</span><br><span class="line">#elasticsearch.ssl.certificateAuthorities: [ <span class="string">"/path/to/your/CA.pem"</span> ]</span><br><span class="line"></span><br><span class="line"># <span class="type">To</span> disregard the validity of <span class="type">SSL</span> certificates, change <span class="keyword">this</span> setting<span class="symbol">'s</span> value to <span class="symbol">'non</span>e'.</span><br><span class="line">#elasticsearch.ssl.verificationMode: full</span><br><span class="line"></span><br><span class="line"># <span class="type">Time</span> in milliseconds to wait <span class="keyword">for</span> <span class="type">Elasticsearch</span> to respond to pings. <span class="type">Defaults</span> to the value of</span><br><span class="line"># the elasticsearch.requestTimeout setting.</span><br><span class="line">#elasticsearch.pingTimeout: <span class="number">1500</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Time</span> in milliseconds to wait <span class="keyword">for</span> responses from the back end or <span class="type">Elasticsearch</span>. <span class="type">This</span> value</span><br><span class="line"># must be a positive integer.</span><br><span class="line">#elasticsearch.requestTimeout: <span class="number">30000</span></span><br><span class="line"></span><br><span class="line"># <span class="type">List</span> of <span class="type">Kibana</span> client-side headers to send to <span class="type">Elasticsearch</span>. <span class="type">To</span> send *no* client-side</span><br><span class="line"># headers, set <span class="keyword">this</span> value to [] (an empty list).</span><br><span class="line">#elasticsearch.requestHeadersWhitelist: [ authorization ]</span><br><span class="line"></span><br><span class="line"># <span class="type">Header</span> names and values that are sent to <span class="type">Elasticsearch</span>. <span class="type">Any</span> custom headers cannot be overwritten</span><br><span class="line"># by client-side headers, regardless of the elasticsearch.requestHeadersWhitelist configuration.</span><br><span class="line">#elasticsearch.customHeaders: &#123;&#125;</span><br><span class="line"></span><br><span class="line"># <span class="type">Time</span> in milliseconds <span class="keyword">for</span> <span class="type">Elasticsearch</span> to wait <span class="keyword">for</span> responses from shards. <span class="type">Set</span> to <span class="number">0</span> to disable.</span><br><span class="line">#elasticsearch.shardTimeout: <span class="number">30000</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Time</span> in milliseconds to wait <span class="keyword">for</span> <span class="type">Elasticsearch</span> at <span class="type">Kibana</span> startup before retrying.</span><br><span class="line">#elasticsearch.startupTimeout: <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Logs</span> queries sent to <span class="type">Elasticsearch</span>. <span class="type">Requires</span> logging.verbose set to <span class="literal">true</span>.</span><br><span class="line">#elasticsearch.logQueries: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Specifies</span> the path where <span class="type">Kibana</span> creates the process <span class="type">ID</span> file.</span><br><span class="line">#pid.file: /<span class="keyword">var</span>/run/kibana.pid</span><br><span class="line"></span><br><span class="line"># <span class="type">Enables</span> you specify a file where <span class="type">Kibana</span> stores log output.</span><br><span class="line">#logging.dest: stdout</span><br><span class="line"></span><br><span class="line"># <span class="type">Set</span> the value of <span class="keyword">this</span> setting to <span class="literal">true</span> to suppress all logging output.</span><br><span class="line">#logging.silent: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Set</span> the value of <span class="keyword">this</span> setting to <span class="literal">true</span> to suppress all logging output other than error messages.</span><br><span class="line">#logging.quiet: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Set</span> the value of <span class="keyword">this</span> setting to <span class="literal">true</span> to log all events, including system usage information</span><br><span class="line"># and all requests.</span><br><span class="line">#logging.verbose: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Set</span> the interval in milliseconds to sample system and process performance</span><br><span class="line"># metrics. <span class="type">Minimum</span> is <span class="number">100</span>ms. <span class="type">Defaults</span> to <span class="number">5000.</span></span><br><span class="line">#ops.interval: <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"># <span class="type">Specifies</span> locale to be used <span class="keyword">for</span> all localizable strings, dates and number formats.</span><br><span class="line">#i18n.locale: <span class="string">"en"</span></span><br></pre></td></tr></table></figure>
<h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><p><strong>分别进入每一台机器,运行下面命令，启动es集群</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch -d</span><br></pre></td></tr></table></figure></p>
<p><strong>启动kibana</strong>：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./kibana &amp;</span><br></pre></td></tr></table></figure></p>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>在浏览器输入如下地址：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:<span class="comment">//192.168.8.81:9200/_cluster/health?pretty=true</span></span><br></pre></td></tr></table></figure></p>
<p><strong>结果</strong>:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"cluster_name"</span> : <span class="string">"cluster"</span>,</span><br><span class="line">  <span class="string">"status"</span> : <span class="string">"green"</span>,</span><br><span class="line">  <span class="string">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="string">"number_of_nodes"</span> : <span class="number">3</span>,</span><br><span class="line">  <span class="string">"number_of_data_nodes"</span> : <span class="number">2</span>,</span><br><span class="line">  <span class="string">"active_primary_shards"</span> : <span class="number">4</span>,</span><br><span class="line">  <span class="string">"active_shards"</span> : <span class="number">8</span>,</span><br><span class="line">  <span class="string">"relocating_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"initializing_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"unassigned_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"delayed_unassigned_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"number_of_pending_tasks"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"number_of_in_flight_fetch"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"task_max_waiting_in_queue_millis"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"active_shards_percent_as_number"</span> : <span class="number">100.0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>green表示集群正确启动完成。   </p>
<p>在浏览器输入如下地址：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:<span class="comment">//192.168.8.81:5601</span></span><br></pre></td></tr></table></figure></p>
<p>在左边工具栏找到Dev Tools,在开发窗口输入一下命令,查看集群健康状态：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">GET</span> /_cat/health?v</span><br></pre></td></tr></table></figure></p>
<p><strong>结果</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">epoch      timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent</span><br><span class="line"><span class="number">1556175058</span> <span class="number">06</span>:<span class="number">50</span>:<span class="number">58</span>  cluster green           <span class="number">3</span>         <span class="number">2</span>      <span class="number">8</span>   <span class="number">4</span>    <span class="number">0</span>    <span class="number">0</span>        <span class="number">0</span>             <span class="number">0</span>                  -                <span class="number">100.0</span>%</span><br></pre></td></tr></table></figure></p>
<p><strong>集群的健康状况</strong><br><strong>green</strong>：每个索引的primary shard和replica shard都是active状态的。<br><strong>yellow</strong>：每个索引的primary shard都是active状态的，但是部分replica shard不是active状态，处于不可用的状态 。<br><strong>red</strong>：不是所有索引的primary shard都是active状态的，部分索引有数据丢失了。   </p>

          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/24/hive 自定义UDTF函数/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/24/hive 自定义UDTF函数/" itemprop="url">hive自定义UDTF函数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-24T14:20:26+08:00">
                2019-04-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hive/" itemprop="url" rel="index">
                    <span itemprop="name">hive</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/24/hive 自定义UDTF函数/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/24/hive 自定义UDTF函数/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  768
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="自定义UDTF函数"><a href="#自定义UDTF函数" class="headerlink" title="自定义UDTF函数"></a>自定义UDTF函数</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>用户自定义表生成函数（UDTF）接受零个或多个输入，然后产生多列或多行的输出。要实现UDTF，需要继承org.apache.hadoop.hive.ql.udf.generic.GenericUDTF，同时实现三个方法。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</a><br><a href="https://javinjunfeng.top/technicalstack/hive/77" target="_blank" rel="noopener">https://javinjunfeng.top/technicalstack/hive/77</a>    </p>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h3 id="原始数据和转换后的数据"><a href="#原始数据和转换后的数据" class="headerlink" title="原始数据和转换后的数据"></a>原始数据和转换后的数据</h3><p><strong>原始数据</strong>： </p>
<blockquote>
<p>sku,category_name,busi_time,shop_id,flag,sale_num,income<br> 21A5+32B2,烟灶,2018-06-29 00:00:00,21,0,6,16056.0   </p>
</blockquote>
<p> <strong>转换后的数据</strong>：</p>
<blockquote>
<p>rela_sku,rule_id,sku,category_name,busi_time,shop_id,sale_num,income<br> 21A5,0,21A5+32B2,烟机,2018-06-29 00:00:00,21,6,16056.0<br> 32B2,1,21A5+32B2,灶具,2018-06-29 00:00:00,21,6,16056.0</p>
</blockquote>
<h3 id="创建自定义函数"><a href="#创建自定义函数" class="headerlink" title="创建自定义函数"></a>创建自定义函数</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xh.spark.sql.hive.udtf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDFArgumentException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.metadata.HiveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JDQuotaReduction</span> <span class="keyword">extends</span> <span class="title">GenericUDTF</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> StructObjectInspector <span class="title">initialize</span><span class="params">(StructObjectInspector args)</span> <span class="keyword">throws</span> UDFArgumentException </span>&#123;</span><br><span class="line">        ArrayList&lt;String&gt; fieldNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        ArrayList&lt;ObjectInspector&gt; resType = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        fieldNames.add(<span class="string">"rela_sku"</span>);</span><br><span class="line">        resType.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line">        fieldNames.add(<span class="string">"rule_id"</span>);</span><br><span class="line">        resType.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line">        <span class="keyword">return</span> ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, resType);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Object[] record)</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line">        List&lt;Object&gt; allQuota = (ArrayList&lt;Object&gt;) record[<span class="number">0</span>];</span><br><span class="line">        List&lt;Object&gt; firstQuotaValueOrder = (ArrayList&lt;Object&gt;) allQuota.get(<span class="number">0</span>);</span><br><span class="line">        String[] sku = firstQuotaValueOrder.get(<span class="number">0</span>).toString().split(<span class="string">"\\+"</span>);</span><br><span class="line">        String cate = firstQuotaValueOrder.get(<span class="number">1</span>).toString();</span><br><span class="line">        String flag = firstQuotaValueOrder.get(<span class="number">2</span>).toString();</span><br><span class="line">        <span class="comment">// 烟灶套餐</span></span><br><span class="line">        <span class="keyword">if</span> (cate != <span class="keyword">null</span> &amp;&amp; <span class="string">"烟灶"</span>.equals(cate)) &#123;</span><br><span class="line">            Object[] result = <span class="keyword">new</span> Object[<span class="number">2</span>];</span><br><span class="line">            <span class="comment">//第一件单品</span></span><br><span class="line">            result[<span class="number">0</span>] = sku[<span class="number">0</span>];</span><br><span class="line">            result[<span class="number">1</span>] = <span class="string">"0"</span>;</span><br><span class="line">            forward(result);</span><br><span class="line">            <span class="comment">//第二件的单品</span></span><br><span class="line">            result[<span class="number">0</span>] = sku[<span class="number">1</span>];</span><br><span class="line">            result[<span class="number">1</span>] = <span class="string">"1"</span>;</span><br><span class="line">            forward(result);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 嵌入式套餐</span></span><br><span class="line">        <span class="keyword">if</span> (cate != <span class="keyword">null</span> &amp;&amp; <span class="string">"嵌入式"</span>.equals(cate)) &#123;</span><br><span class="line">            Object[] result = <span class="keyword">new</span> Object[<span class="number">2</span>];</span><br><span class="line">            <span class="comment">// 第一件单品</span></span><br><span class="line">            result[<span class="number">0</span>] = sku[<span class="number">0</span>];</span><br><span class="line">            result[<span class="number">1</span>] = <span class="string">"2"</span>;</span><br><span class="line">            forward(result);</span><br><span class="line">            <span class="comment">// 第二件及之后的单品</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; sku.length; i++) &#123;</span><br><span class="line">                result[<span class="number">0</span>] = sku[i];</span><br><span class="line">                result[<span class="number">1</span>] = <span class="string">"1"</span>;</span><br><span class="line">                forward(result);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 烟灶消套餐及大套系</span></span><br><span class="line">        <span class="keyword">if</span> (cate != <span class="keyword">null</span> &amp;&amp; (<span class="string">"烟灶消"</span>.equals(cate) || <span class="string">"大套系"</span>.equals(cate))) &#123;</span><br><span class="line">            Object[] result = <span class="keyword">new</span> Object[<span class="number">2</span>];</span><br><span class="line">            <span class="comment">// 第二件及之后的单品</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; sku.length; i++) &#123;</span><br><span class="line">                result[<span class="number">0</span>] = sku[i];</span><br><span class="line">                result[<span class="number">1</span>] = <span class="string">"1"</span>;</span><br><span class="line">                forward(result);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (flag != <span class="keyword">null</span> &amp;&amp; <span class="string">"1"</span>.equals(flag)) &#123;</span><br><span class="line">                <span class="comment">// 第一件+第二件的组合是烟灶套餐</span></span><br><span class="line">                result[<span class="number">0</span>] = sku[<span class="number">0</span>] + <span class="string">"+"</span> + sku[<span class="number">1</span>];</span><br><span class="line">                result[<span class="number">1</span>] = <span class="number">3</span>;</span><br><span class="line">                forward(result);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                result[<span class="number">0</span>] = sku[<span class="number">0</span>];</span><br><span class="line">                result[<span class="number">1</span>] = <span class="string">"2"</span>;</span><br><span class="line">                forward(result);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span>  transct_quota(</span><br><span class="line">sku <span class="keyword">string</span>,</span><br><span class="line">category_name <span class="keyword">string</span>,</span><br><span class="line">busi_time <span class="keyword">string</span>,</span><br><span class="line">shop_id <span class="keyword">string</span>,</span><br><span class="line">flag <span class="keyword">string</span>,</span><br><span class="line">sale_num <span class="built_in">int</span>,</span><br><span class="line">income <span class="keyword">double</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> </span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line"><span class="keyword">stored</span>  <span class="keyword">as</span> textfile</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> transct_quota <span class="keyword">values</span> (<span class="string">"21A5+32B2"</span>,<span class="string">"烟灶"</span>,<span class="string">"2018-06-29 00:00:00"</span>,<span class="string">"21"</span>,<span class="string">"0"</span>,<span class="number">6</span>,<span class="number">16056.0</span>);</span><br></pre></td></tr></table></figure>
<h3 id="在hive命令窗口添加函数jar包"><a href="#在hive命令窗口添加函数jar包" class="headerlink" title="在hive命令窗口添加函数jar包"></a>在hive命令窗口添加函数jar包</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar /home/hadoop/sparklearning<span class="number">-1.0</span>-<span class="type">SNAPSHOT</span>.jar;</span><br></pre></td></tr></table></figure>
<h3 id="在hive命令窗口创建临时函数"><a href="#在hive命令窗口创建临时函数" class="headerlink" title="在hive命令窗口创建临时函数"></a>在hive命令窗口创建临时函数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create temporary function combine_sku_reduction_rule as <span class="symbol">'com</span>.xh.spark.sql.hive.udtf.<span class="type">JDQuotaReduction</span>';</span><br></pre></td></tr></table></figure>
<h3 id="使用自定义函数"><a href="#使用自定义函数" class="headerlink" title="使用自定义函数"></a>使用自定义函数</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> c1,c2,jd_quota.* <span class="keyword">from</span> transct_quota LATERAL <span class="keyword">VIEW</span> combine_sku_reduction_rule(<span class="built_in">array</span>(named_struct(<span class="string">'sku'</span>, goods_sku_id, <span class="string">'cate'</span>, category_name,<span class="string">'flag'</span>,flag))) sku_tab  <span class="keyword">as</span> c1,c2;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/20/java中调用scala/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/20/java中调用scala/" itemprop="url">java中调用scala</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-20T19:03:09+08:00">
                2019-04-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index">
                    <span itemprop="name">java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/20/java中调用scala/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/20/java中调用scala/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  217
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p><strong>说明</strong>：主要参照spark源码 </p>
<h2 id="编写scala类及半生对象"><a href="#编写scala类及半生对象" class="headerlink" title="编写scala类及半生对象"></a>编写scala类及半生对象</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.spark.sql.types</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.annotation.<span class="type">Stable</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The data type representing `NULL` values. Please use the singleton `DataTypes.NullType`.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @since 1.3.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Stable</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NullType</span> <span class="title">private</span>(<span class="params"></span>) <span class="keyword">extends</span> <span class="title">DataType</span> </span>&#123;</span><br><span class="line">  <span class="comment">// The companion object and this class is separated so the companion object also subclasses</span></span><br><span class="line">  <span class="comment">// this type. Otherwise, the companion object would be of type "NullType$" in byte code.</span></span><br><span class="line">  <span class="comment">// Defined with a private constructor so the companion object is the only possible instantiation.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">defaultSize</span></span>: <span class="type">Int</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span>[spark] <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">asNullable</span></span>: <span class="type">NullType</span> = <span class="keyword">this</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @since 1.3.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Stable</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">object</span> <span class="title">NullType</span> <span class="keyword">extends</span> <span class="title">NullType</span></span></span><br></pre></td></tr></table></figure>
<h1 id="在java中调用scala"><a href="#在java中调用scala" class="headerlink" title="在java中调用scala"></a>在java中调用scala</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.spark.sql.types;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.annotation.Stable;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * To get/create specific data type, users should use singleton objects and factory methods</span></span><br><span class="line"><span class="comment"> * provided by this class.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 1.3.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Stable</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataTypes</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Gets the NullType object.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> DataType NullType = NullType$.MODULE$;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/19/sparksql DataSet算子实战/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/19/sparksql DataSet算子实战/" itemprop="url">sparksql DataSet算子实战</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-19T17:22:37+08:00">
                2019-04-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sparksql/" itemprop="url" rel="index">
                    <span itemprop="name">sparksql</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/19/sparksql DataSet算子实战/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/19/sparksql DataSet算子实战/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,414
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="基本环境"><a href="#基本环境" class="headerlink" title="基本环境"></a>基本环境</h1><p><strong>scala版本</strong>：scala2.12.8<br><strong>jdk版本</strong>：1.8<br><strong>spark版本</strong>：2.4.1</p>
<h1 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h1><p>sku_sale_amount.csv<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10001</span>,<span class="number">36</span>B0,烟机   ,<span class="number">2015</span>,<span class="number">100</span></span><br><span class="line"><span class="number">10001</span>,<span class="number">27</span>A3,烟机   ,<span class="number">2016</span>,<span class="number">100</span></span><br><span class="line"><span class="number">10001</span>,<span class="number">27</span>A3,烟机   ,<span class="number">2017</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">36</span>B0,烟机   ,<span class="number">2015</span>,<span class="number">100</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">36</span>B0,烟机   ,<span class="number">2016</span>,<span class="number">100</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">36</span>B0,烟机   ,<span class="number">2017</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">58</span>B5,灶具   ,<span class="number">2014</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">58</span>B5,灶具   ,<span class="number">2015</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">58</span>B5,灶具   ,<span class="number">2016</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">58</span>B5,灶具   ,<span class="number">2017</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10003</span>,<span class="number">64</span>B8,洗碗机  ,<span class="number">2014</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10003</span>,<span class="number">727</span>T,智能消毒柜,<span class="number">2014</span>,<span class="number">200</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">64</span>B8,净水器  ,<span class="number">2014</span>,<span class="number">150</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">64</span>B8,净水器  ,<span class="number">2015</span>,<span class="number">50</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">64</span>B8,净水器  ,<span class="number">2016</span>,<span class="number">50</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">45</span>A8,净水器  ,<span class="number">2017</span>,<span class="number">50</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">64</span>B8,嵌入式蒸箱,<span class="number">2014</span>,<span class="number">150</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">64</span>B8,嵌入式蒸箱,<span class="number">2015</span>,<span class="number">50</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">64</span>B8,嵌入式蒸箱,<span class="number">2016</span>,<span class="number">50</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">45</span>A8,嵌入式蒸箱,<span class="number">2017</span>,<span class="number">50</span></span><br></pre></td></tr></table></figure></p>
<p>sku_product.csv<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10001</span>,<span class="number">1000</span></span><br><span class="line"><span class="number">10001</span>,<span class="number">2000</span></span><br><span class="line"><span class="number">10001</span>,<span class="number">4000</span></span><br><span class="line"><span class="number">10001</span>,<span class="number">6000</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">8000</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">10000</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">9000</span></span><br><span class="line"><span class="number">10002</span>,<span class="number">6000</span></span><br><span class="line"><span class="number">10003</span>,<span class="number">5000</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">4000</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">3000</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">44000</span></span><br><span class="line"><span class="number">10004</span>,<span class="number">11000</span></span><br></pre></td></tr></table></figure></p>
<h1 id="准备基本环境"><a href="#准备基本环境" class="headerlink" title="准备基本环境"></a>准备基本环境</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DataSetSingleOperating</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">     <span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">"local[*]"</span>)</span><br><span class="line">      .appName(<span class="string">"DateFrameFromJsonScala"</span>)</span><br><span class="line">      .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> skuIncomeDF = spark.read.format(<span class="string">"csv"</span>)</span><br><span class="line">      .option(<span class="string">"sep"</span>, <span class="string">","</span>)</span><br><span class="line">      .option(<span class="string">"inferSchema"</span>, <span class="string">"true"</span>)</span><br><span class="line">      .option(<span class="string">"header"</span>, <span class="string">"false"</span>)</span><br><span class="line">      .load(<span class="string">"src/main/resources/data/sku_sale_amount.csv"</span>)</span><br><span class="line">      .toDF(<span class="string">"goods_id"</span>, <span class="string">"sku"</span>, <span class="string">"category"</span>, <span class="string">"year"</span>, <span class="string">"amount"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> skuProductDF = spark.read.format(<span class="string">"csv"</span>)</span><br><span class="line">      .option(<span class="string">"sep"</span>, <span class="string">","</span>)</span><br><span class="line">      .option(<span class="string">"inferSchema"</span>, <span class="string">"true"</span>)</span><br><span class="line">      .option(<span class="string">"header"</span>, <span class="string">"false"</span>)</span><br><span class="line">      .load(<span class="string">"src/main/resources/data/sku_product.csv"</span>)</span><br><span class="line">      .toDF(<span class="string">"goods_id1"</span>, <span class="string">"volume"</span>)</span><br><span class="line"></span><br><span class="line">    skuIncomeDF.createTempView(<span class="string">"sku_sale_amount"</span>)</span><br><span class="line">    skuIncomeDF.createTempView(<span class="string">"sku_product"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="select-操作"><a href="#select-操作" class="headerlink" title="select 操作"></a>select 操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.select($<span class="string">"goods_id"</span>, $<span class="string">"sku"</span>, $<span class="string">"category"</span>, $<span class="string">"year"</span>.as(<span class="string">"date"</span>), $<span class="string">"amount"</span>)</span><br><span class="line"> skuIncomeDF.select(<span class="symbol">'goods_id</span>, <span class="symbol">'sku</span>, <span class="symbol">'category</span>, <span class="symbol">'year</span>.as(<span class="string">"date"</span>), <span class="symbol">'amount</span>)</span><br><span class="line"> skuIncomeDF.select(col(<span class="string">"goods_id"</span>), col(<span class="string">"sku"</span>), col(<span class="string">"category"</span>), col(<span class="string">"year"</span>).as(<span class="string">"date"</span>), <span class="symbol">'amount</span>)</span><br><span class="line"> skuIncomeDF.select(expr(<span class="string">"goods_id"</span>), expr(<span class="string">"sku"</span>), expr(<span class="string">"category"</span>), expr(<span class="string">"year as date"</span>), expr(<span class="string">"amount+1"</span>))</span><br><span class="line"> spark.sql(</span><br><span class="line">   <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">     |select sku,category,year,amount from sku_sale_amount</span></span><br><span class="line"><span class="string">   "</span><span class="string">""</span>.stripMargin)</span><br></pre></td></tr></table></figure>
<h1 id="selectExpr操作"><a href="#selectExpr操作" class="headerlink" title="selectExpr操作"></a>selectExpr操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.selectExpr(<span class="string">"goods_id"</span>, <span class="string">"sku"</span>, <span class="string">"category"</span>, <span class="string">"year as date"</span>, <span class="string">"amount+1 as amount"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="filter-操作"><a href="#filter-操作" class="headerlink" title="filter 操作"></a>filter 操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.filter($<span class="string">"amount"</span> &gt; <span class="number">150</span>)</span><br><span class="line">skuIncomeDF.filter(col(<span class="string">"amount"</span>) &gt; <span class="number">150</span>)</span><br><span class="line">skuIncomeDF.filter(<span class="symbol">'amount</span> &gt; <span class="number">150</span>)</span><br><span class="line">skuIncomeDF.filter(<span class="string">"amount &gt; 150"</span>)</span><br><span class="line">skuIncomeDF.filter(row =&gt; row.getInt(<span class="number">3</span>) &gt; <span class="number">150</span>)</span><br></pre></td></tr></table></figure>
<h1 id="where操作"><a href="#where操作" class="headerlink" title="where操作"></a>where操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.where($<span class="string">"amount"</span> &gt; <span class="number">150</span>)</span><br><span class="line">skuIncomeDF.where(col(<span class="string">"amount"</span>) &gt; <span class="number">150</span>)</span><br><span class="line">skuIncomeDF.where(<span class="symbol">'amount</span> &gt; <span class="number">150</span>)</span><br><span class="line">skuIncomeDF.where(<span class="string">"amount &gt; 150"</span>)</span><br><span class="line">spark.sql(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select sku,category,year,amount from sku_sale_amount where amount &gt; 150</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br></pre></td></tr></table></figure>
<h1 id="union-操作"><a href="#union-操作" class="headerlink" title="union 操作"></a>union 操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.union(skuIncomeDF).groupBy(<span class="string">"sku"</span>).count()</span><br><span class="line">spark.sql(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select sku,count(1) from (</span></span><br><span class="line"><span class="string">    |select sku,category,year,amount  from sku_sale_amount</span></span><br><span class="line"><span class="string">    | union all</span></span><br><span class="line"><span class="string">    |select sku,category,year,amount  from sku_sale_amount</span></span><br><span class="line"><span class="string">    |)a group by sku</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">skuIncomeDF.union(skuIncomeDF).distinct().groupBy(<span class="string">"sku"</span>).count()</span><br><span class="line">spark.sql(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select sku,count(1) from (</span></span><br><span class="line"><span class="string">    |select sku,category,year,amount  from sku_sale_amount</span></span><br><span class="line"><span class="string">    | union</span></span><br><span class="line"><span class="string">    |select sku,category,year,amount  from sku_sale_amount</span></span><br><span class="line"><span class="string">    |)a group by sku</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br></pre></td></tr></table></figure>
<h1 id="group-by操作"><a href="#group-by操作" class="headerlink" title="group by操作"></a>group by操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.groupBy(<span class="string">"sku"</span>).count()</span><br><span class="line">skuIncomeDF.groupBy($<span class="string">"sku"</span>).count()</span><br><span class="line">skuIncomeDF.groupBy(<span class="symbol">'sku</span>).count()</span><br><span class="line">skuIncomeDF.groupBy(col(<span class="string">"sku"</span>)).count()</span><br></pre></td></tr></table></figure>
<h1 id="join操作"><a href="#join操作" class="headerlink" title="join操作"></a>join操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.join(skuIncomeDF, <span class="string">"sku"</span>)</span><br><span class="line">skuIncomeDF.join(skuIncomeDF, <span class="type">Seq</span>(<span class="string">"sku"</span>, <span class="string">"category"</span>))</span><br><span class="line">skuIncomeDF.join(skuIncomeDF, <span class="type">Seq</span>(<span class="string">"sku"</span>), <span class="string">"inner"</span>)</span><br><span class="line"></span><br><span class="line">skuIncomeDF.join(skuProductDF, $<span class="string">"goods_id"</span> === $<span class="string">"goods_id1"</span>)</span><br><span class="line">skuIncomeDF.join(skuProductDF, col(<span class="string">"goods_id"</span>) === col(<span class="string">"goods_id1"</span>))</span><br><span class="line">skuIncomeDF.join(skuProductDF, col(<span class="string">"goods_id"</span>).equalTo(col(<span class="string">"goods_id1"</span>)))</span><br><span class="line">skuIncomeDF.joinWith(skuProductDF, skuIncomeDF(<span class="string">"goods_id"</span>) === skuProductDF(<span class="string">"goods_id1"</span>), <span class="string">"inner"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="order-by"><a href="#order-by" class="headerlink" title="order by"></a>order by</h1><p>底层用的还是sort。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.orderBy(<span class="string">"sku"</span>, <span class="string">"category"</span>, <span class="string">"amount"</span>)</span><br><span class="line">skuIncomeDF.orderBy($<span class="string">"sku"</span>, $<span class="string">"category"</span>, $<span class="string">"amount"</span>.desc)</span><br><span class="line">skuIncomeDF.orderBy(col(<span class="string">"sku"</span>), col(<span class="string">"category"</span>), col(<span class="string">"amount"</span>).desc)</span><br></pre></td></tr></table></figure></p>
<h1 id="sort-操作"><a href="#sort-操作" class="headerlink" title="sort 操作"></a>sort 操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.sort(<span class="string">"sku"</span>, <span class="string">"category"</span>, <span class="string">"amount"</span>)</span><br><span class="line">skuIncomeDF.sort($<span class="string">"sku"</span>, $<span class="string">"category"</span>, $<span class="string">"amount"</span>.desc)</span><br><span class="line">skuIncomeDF.sort(col(<span class="string">"sku"</span>), col(<span class="string">"category"</span>), col(<span class="string">"amount"</span>).desc)</span><br></pre></td></tr></table></figure>
<h1 id="sortwithinpartition操作"><a href="#sortwithinpartition操作" class="headerlink" title="sortwithinpartition操作"></a>sortwithinpartition操作</h1><p>分区内部进行排序，局部排序。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.sortWithinPartitions(<span class="string">"sku"</span>, <span class="string">"category"</span>)</span><br><span class="line">skuIncomeDF.sortWithinPartitions($<span class="string">"sku"</span>, $<span class="string">"category"</span>, $<span class="string">"amount"</span>.desc)</span><br><span class="line">skuIncomeDF.sortWithinPartitions(col(<span class="string">"sku"</span>), col(<span class="string">"category"</span>).desc)</span><br></pre></td></tr></table></figure></p>
<h1 id="withColumn-操作"><a href="#withColumn-操作" class="headerlink" title="withColumn 操作"></a>withColumn 操作</h1><p>作用:假如列，存在就替换，不存在新增;对已有的列进行重命名。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.withColumn(<span class="string">"amount"</span>, $<span class="string">"amount"</span> + <span class="number">1</span>)</span><br><span class="line">skuIncomeDF.withColumn(<span class="string">"amount"</span>, <span class="symbol">'amount</span> + <span class="number">1</span>)</span><br><span class="line">skuIncomeDF.withColumnRenamed(<span class="string">"amount"</span>, <span class="string">"amount1"</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="foreach操作"><a href="#foreach操作" class="headerlink" title="foreach操作"></a>foreach操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.foreach(row =&gt; println(row.get(<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>
<h1 id="foreachPartition操作"><a href="#foreachPartition操作" class="headerlink" title="foreachPartition操作"></a>foreachPartition操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.foreachPartition((it: <span class="type">Iterator</span>[<span class="type">Row</span>]) =&gt; &#123;</span><br><span class="line">  it.foreach(row =&gt; println(row.get(<span class="number">0</span>)))</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h1 id="distinct操作"><a href="#distinct操作" class="headerlink" title="distinct操作"></a>distinct操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.distinct()</span><br></pre></td></tr></table></figure>
<h1 id="dropDuplicates操作"><a href="#dropDuplicates操作" class="headerlink" title="dropDuplicates操作"></a>dropDuplicates操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.dropDuplicates(<span class="string">"sku"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="drop操作"><a href="#drop操作" class="headerlink" title="drop操作"></a>drop操作</h1><p>删除一列，或者多列。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.drop(<span class="string">"sku"</span>, <span class="string">"category"</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="cube操作"><a href="#cube操作" class="headerlink" title="cube操作"></a>cube操作</h1><p><strong>说明</strong>：相当于(category,year),(year),(category),() 分别分组然后对amount求sum<br>参考：<a href="https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-multi-dimensional-aggregation.html" target="_blank" rel="noopener">https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-multi-dimensional-aggregation.html</a>   </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.cube($<span class="string">"category"</span>, $<span class="string">"year"</span>.cast(<span class="string">"string"</span>).as(<span class="string">"year"</span>))</span><br><span class="line">  .agg(sum(<span class="string">"amount"</span>))</span><br><span class="line">  .sort(col(<span class="string">"category"</span>).desc_nulls_first, col(<span class="string">"year"</span>).desc_nulls_first)</span><br></pre></td></tr></table></figure>
<h1 id="rollup操作"><a href="#rollup操作" class="headerlink" title="rollup操作"></a>rollup操作</h1><p><strong>说明</strong>：等价于分别对(category,year),(year),()进行 groupby 对amount求sum。<br>参考：<a href="https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-multi-dimensional-aggregation.html" target="_blank" rel="noopener">https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-multi-dimensional-aggregation.html</a><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.rollup($<span class="string">"category"</span>, $<span class="string">"year"</span>.cast(<span class="string">"string"</span>).as(<span class="string">"year"</span>))</span><br><span class="line">  .agg(sum(<span class="string">"amount"</span>) as <span class="string">"amount"</span>, grouping_id() as <span class="string">"gid"</span>)</span><br><span class="line">  .sort($<span class="string">"category"</span>.desc_nulls_last, $<span class="string">"year"</span>.asc_nulls_last)</span><br></pre></td></tr></table></figure></p>
<h1 id="pivot操作"><a href="#pivot操作" class="headerlink" title="pivot操作"></a>pivot操作</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skuIncomeDF.groupBy(<span class="string">"category"</span>)</span><br><span class="line">  .pivot(<span class="string">"year"</span>, <span class="type">Seq</span>(<span class="string">"2014"</span>, <span class="string">"2015"</span>, <span class="string">"2016"</span>, <span class="string">"2017"</span>))</span><br><span class="line">  .agg(sum(<span class="string">"amount"</span>))</span><br></pre></td></tr></table></figure>
<h1 id="转置操作"><a href="#转置操作" class="headerlink" title="转置操作"></a>转置操作</h1><p>文章来自：<a href="http://bailiwick.io/2017/10/21/transpose-data-with-spark/" target="_blank" rel="noopener">http://bailiwick.io/2017/10/21/transpose-data-with-spark/</a><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Import the requisite methods</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">DataFrame</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;array, col, explode, lit, struct&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create a dataframe</span></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(<span class="type">Seq</span>(</span><br><span class="line">  (<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">  (<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>),</span><br><span class="line">  (<span class="number">4</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">3</span>),</span><br><span class="line">  (<span class="number">6</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line">)).toDF(<span class="string">"uid"</span>, <span class="string">"col1"</span>, <span class="string">"col2"</span>, <span class="string">"col3"</span>, <span class="string">"col4"</span>, <span class="string">"col5"</span>, <span class="string">"col6"</span>)</span><br><span class="line"></span><br><span class="line">df.show(<span class="number">10</span>,<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the transpose user defined function.</span></span><br><span class="line"><span class="comment">// Imputs:</span></span><br><span class="line"><span class="comment">//   transDF: The dataframe which will be transposed</span></span><br><span class="line"><span class="comment">//   transBy: The column that the dataframe will be transposed by</span></span><br><span class="line"><span class="comment">// Outputs:</span></span><br><span class="line"><span class="comment">//   Dataframe datatype consisting of three columns:</span></span><br><span class="line"><span class="comment">//     transBy</span></span><br><span class="line"><span class="comment">//     column_name</span></span><br><span class="line"><span class="comment">//     column_value</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transposeUDF</span></span>(transDF: <span class="type">DataFrame</span>, transBy: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">DataFrame</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> (cols, types) = transDF.dtypes.filter&#123; <span class="keyword">case</span> (c, _) =&gt; !transBy.contains(c)&#125;.unzip</span><br><span class="line">  require(types.distinct.size == <span class="number">1</span>)      </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> kvs = explode(array(</span><br><span class="line">    cols.map(c =&gt; struct(lit(c).alias(<span class="string">"column_name"</span>), col(c).alias(<span class="string">"column_value"</span>))): _*</span><br><span class="line">  ))</span><br><span class="line">  <span class="keyword">val</span> byExprs = transBy.map(col(_))</span><br><span class="line"></span><br><span class="line">  transDF</span><br><span class="line">    .select(byExprs :+ kvs.alias(<span class="string">"_kvs"</span>): _*)</span><br><span class="line">    .select(byExprs ++ <span class="type">Seq</span>($<span class="string">"_kvs.column_name"</span>, $<span class="string">"_kvs.column_value"</span>): _*)</span><br><span class="line">&#125;</span><br><span class="line">transposeUDF(df, <span class="type">Seq</span>(<span class="string">"uid"</span>)).show(<span class="number">12</span>,<span class="literal">false</span>)</span><br><span class="line"><span class="type">Output</span>:</span><br><span class="line">df.show(<span class="number">10</span>,<span class="literal">false</span>)</span><br><span class="line">+---+----+----+----+----+----+----+</span><br><span class="line">|uid|col1|col2|col3|col4|col5|col6|</span><br><span class="line">+---+----+----+----+----+----+----+</span><br><span class="line">|<span class="number">1</span>  |<span class="number">1</span>   |<span class="number">2</span>   |<span class="number">3</span>   |<span class="number">8</span>   |<span class="number">4</span>   |<span class="number">5</span>   |</span><br><span class="line">|<span class="number">2</span>  |<span class="number">4</span>   |<span class="number">3</span>   |<span class="number">8</span>   |<span class="number">7</span>   |<span class="number">9</span>   |<span class="number">8</span>   |</span><br><span class="line">|<span class="number">3</span>  |<span class="number">6</span>   |<span class="number">1</span>   |<span class="number">9</span>   |<span class="number">2</span>   |<span class="number">3</span>   |<span class="number">6</span>   |</span><br><span class="line">|<span class="number">4</span>  |<span class="number">7</span>   |<span class="number">8</span>   |<span class="number">6</span>   |<span class="number">9</span>   |<span class="number">4</span>   |<span class="number">5</span>   |</span><br><span class="line">|<span class="number">5</span>  |<span class="number">9</span>   |<span class="number">2</span>   |<span class="number">7</span>   |<span class="number">8</span>   |<span class="number">7</span>   |<span class="number">3</span>   |</span><br><span class="line">|<span class="number">6</span>  |<span class="number">1</span>   |<span class="number">1</span>   |<span class="number">4</span>   |<span class="number">2</span>   |<span class="number">8</span>   |<span class="number">4</span>   |</span><br><span class="line">+---+----+----+----+----+----+----+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transposeUDF(df, <span class="type">Seq</span>(<span class="string">"uid"</span>)).show(<span class="number">12</span>,<span class="literal">false</span>)</span><br><span class="line">+---+-----------+------------+</span><br><span class="line">|uid|column_name|column_value|</span><br><span class="line">+---+-----------+------------+</span><br><span class="line">|<span class="number">1</span>  |col1       |<span class="number">1</span>           |</span><br><span class="line">|<span class="number">1</span>  |col2       |<span class="number">2</span>           |</span><br><span class="line">|<span class="number">1</span>  |col3       |<span class="number">3</span>           |</span><br><span class="line">|<span class="number">1</span>  |col4       |<span class="number">8</span>           |</span><br><span class="line">|<span class="number">1</span>  |col5       |<span class="number">4</span>           |</span><br><span class="line">|<span class="number">1</span>  |col6       |<span class="number">5</span>           |</span><br><span class="line">|<span class="number">2</span>  |col1       |<span class="number">4</span>           |</span><br><span class="line">|<span class="number">2</span>  |col2       |<span class="number">3</span>           |</span><br><span class="line">|<span class="number">2</span>  |col3       |<span class="number">8</span>           |</span><br><span class="line">|<span class="number">2</span>  |col4       |<span class="number">7</span>           |</span><br><span class="line">|<span class="number">2</span>  |col5       |<span class="number">9</span>           |</span><br><span class="line">|<span class="number">2</span>  |col6       |<span class="number">8</span>           |</span><br><span class="line">+---+-----------+------------+</span><br><span class="line">only showing top <span class="number">12</span> rows</span><br></pre></td></tr></table></figure></p>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://legacy.gitbook.com/book/jaceklaskowski/mastering-spark-sql/details" target="_blank" rel="noopener">https://legacy.gitbook.com/book/jaceklaskowski/mastering-spark-sql/details</a><br><a href="https://www.toutiao.com/i6631318012546793992/" target="_blank" rel="noopener">https://www.toutiao.com/i6631318012546793992/</a>   </p>

          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tgluon.github.io/2019/04/18/sparksql读取数据库问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/18/sparksql读取数据库问题/" itemprop="url">sparksql读取数据库问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-18T16:10:12+08:00">
                2019-04-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sparksql/" itemprop="url" rel="index">
                    <span itemprop="name">sparksql</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/18/sparksql读取数据库问题/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/18/sparksql读取数据库问题/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  110
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="spark-jdbc方式读取数据库，每个excutor都会去拉数据？"><a href="#spark-jdbc方式读取数据库，每个excutor都会去拉数据？" class="headerlink" title="spark jdbc方式读取数据库，每个excutor都会去拉数据？"></a>spark jdbc方式读取数据库，每个excutor都会去拉数据？</h1><p><strong>说明</strong>：该问题来源spark技术分享朋友群<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spark.read(<span class="string">"jdbc"</span>)</span><br><span class="line">  .option(<span class="string">"url"</span>, url)</span><br><span class="line">  .option(<span class="string">"dbtable"</span>, <span class="string">"pets"</span>)</span><br><span class="line">  .option(<span class="string">"user"</span>, user)</span><br><span class="line">  .option(<span class="string">"password"</span>, password)</span><br><span class="line">  .option(<span class="string">"numPartitions"</span>, <span class="number">10</span>)</span><br><span class="line">  .option(<span class="string">"partitionColumn"</span>, <span class="string">"owner_id"</span>)</span><br><span class="line">  .option(<span class="string">"lowerBound"</span>, <span class="number">1</span>)</span><br><span class="line">  .option(<span class="string">"upperBound"</span>, <span class="number">10000</span>)</span><br><span class="line">  .load()</span><br></pre></td></tr></table></figure></p>
<p>这种一般会转换为<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> pets <span class="keyword">WHERE</span> owner_id &gt;= <span class="number">1</span> <span class="keyword">and</span> owner_id &lt; <span class="number">1000</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> pets <span class="keyword">WHERE</span> owner_id &gt;= <span class="number">1000</span> <span class="keyword">and</span> owner_id &lt; <span class="number">2000</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> pets <span class="keyword">WHERE</span> owner_id &gt;= <span class="number">2000</span> <span class="keyword">and</span> owner_id &lt; <span class="number">3000</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    
     <div>
      
     </div>
     <div>
     
    </div>

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="tang" />
            
              <p class="site-author-name" itemprop="name">tang</p>
              <p class="site-description motion-element" itemprop="description">火星度假村追梦程序员。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/tgluon" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i></a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tang</span>

  
</div>


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
<span id="busuanzi_container_site_pv">
    本站总访问量:<span id="busuanzi_value_site_pv"></span>次
</span>
</div>
  
<!--<div class="powered-by">{
  }由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动{}</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">{
  }主题 &mdash; {
  }<a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">{
    }NexT.Pisces{
  }</a> v5.1.4{
}</div>
-->



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共60.9k字</span>
</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>


  
  <script type="text/javascript"
color="0,0,255" opacity='0.7' zIndex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  
  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    

  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
<script type="text/javascript" src="/js/src/love.js"></script>
</html>
