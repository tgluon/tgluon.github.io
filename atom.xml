<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>blog</title>
  
  <subtitle>追梦青年</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://tgluon.github.io/"/>
  <updated>2018-08-13T15:34:16.000Z</updated>
  <id>https://tgluon.github.io/</id>
  
  <author>
    <name>tang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>maven删除本地仓库lastUpdated文件</title>
    <link href="https://tgluon.github.io/2018/08/13/maven%E5%88%A0%E9%99%A4lastupdated%E6%96%87%E4%BB%B6%E5%91%BD%E4%BB%A4/"/>
    <id>https://tgluon.github.io/2018/08/13/maven删除lastupdated文件命令/</id>
    <published>2018-08-13T15:43:23.000Z</published>
    <updated>2018-08-13T15:34:16.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">windows:</span><br><span class="line">for /r %i in (*.lastUpdated) do del %i</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">linux:</span><br><span class="line">find ~/ . -name &quot;*.lastUpdated&quot; -exec rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;
      
    
    </summary>
    
      <category term="maven" scheme="https://tgluon.github.io/categories/maven/"/>
    
    
      <category term="maven" scheme="https://tgluon.github.io/tags/maven/"/>
    
  </entry>
  
  <entry>
    <title>ORCFILE格式存储到hive表</title>
    <link href="https://tgluon.github.io/2018/07/28/ORCFILE%E6%A0%BC%E5%BC%8F%E5%AD%98%E5%82%A8%E5%88%B0hive%E8%A1%A8/"/>
    <id>https://tgluon.github.io/2018/07/28/ORCFILE格式存储到hive表/</id>
    <published>2018-07-27T23:43:23.000Z</published>
    <updated>2018-07-28T00:40:59.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>ORC指的是Optimized Record Columnar,就是说相对于其他文件格式，它已更优化方式存储数据.ORC能将原始的大小缩减75%，从而提升数据处理速度。ORC比Text,Squence和RC文件格式有更好的性能，而且ORC是目前是hive唯一支持事物的文件格式。<br>ORCFILE格式的输出包是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.hive.ql.io.orc</span><br></pre></td></tr></table></figure></p><p><code>注意:</code>本段文字来自《Hadoop构建数据仓库实践》书籍6.2.1章节</p><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><h2 id="建立ORCFILE格式表"><a href="#建立ORCFILE格式表" class="headerlink" title="建立ORCFILE格式表"></a>建立ORCFILE格式表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_orcfile(   </span><br><span class="line">    c1 <span class="keyword">string</span>,  </span><br><span class="line">    c2 <span class="built_in">int</span>,   </span><br><span class="line">    c3 <span class="keyword">string</span>,   </span><br><span class="line">    c4 <span class="keyword">string</span>)  </span><br><span class="line">    <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> </span><br><span class="line">    <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span></span><br><span class="line">    <span class="keyword">stored</span> <span class="keyword">as</span> orcfile;</span><br></pre></td></tr></table></figure><h2 id="向表中导入数据"><a href="#向表中导入数据" class="headerlink" title="向表中导入数据"></a>向表中导入数据</h2><p><code>注意</code>：不能直接向ORCFILE表插入数据，需要从其他表向ORCFILE表插入数据。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_orcfile  <span class="keyword">select</span> * <span class="keyword">from</span> t_textfile</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;ORC指的是Optimized Record Columnar,就是说相对于其他文件格式，它已更优化方式存储数据.ORC能将原始的大小缩减7
      
    
    </summary>
    
      <category term="hive" scheme="https://tgluon.github.io/categories/hive/"/>
    
    
      <category term="hive" scheme="https://tgluon.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>RCFILE格式存储到hive表</title>
    <link href="https://tgluon.github.io/2018/07/28/RCFILE%E6%A0%BC%E5%BC%8F%E5%AD%98%E5%82%A8%E5%88%B0hive%E8%A1%A8/"/>
    <id>https://tgluon.github.io/2018/07/28/RCFILE格式存储到hive表/</id>
    <published>2018-07-27T23:43:23.000Z</published>
    <updated>2018-07-28T00:40:59.557Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>RCFILE指的是 Record Columnar File,是一种高效压缩率的二进制文件格式，<strong>被用于在一个时间点操作多行的场景</strong>。RCFILEs是由二进制键/值对组成的平面文件，这点于SEQUENCEFILE非常相似。RCFILE以记录的形式存储表中的列，即列存储方式。它先分割行做水平分区，然后分割列做垂直分区。RCFILE把一行的元数据作为键，把行数据作为值，这种面向列的存储在执行数据分析时更高效。<br>RCFILE格式的输入输出包是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.hive.ql.io.RCFileInputFormat</span><br><span class="line">org.apache.hadoop.hive.ql.io.RCFileOutputFormat</span><br></pre></td></tr></table></figure></p><p><code>注意:</code>本段文字来自《Hadoop构建数据仓库实践》书籍6.2.1章节</p><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><h2 id="建立RCFILE格式表"><a href="#建立RCFILE格式表" class="headerlink" title="建立RCFILE格式表"></a>建立RCFILE格式表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_rcfile(   </span><br><span class="line">    c1 <span class="keyword">string</span>,  </span><br><span class="line">    c2 <span class="built_in">int</span>,   </span><br><span class="line">    c3 <span class="keyword">string</span>,   </span><br><span class="line">    c4 <span class="keyword">string</span>)  </span><br><span class="line">    <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> </span><br><span class="line">    <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span></span><br><span class="line">    <span class="keyword">stored</span> <span class="keyword">as</span> rcfile;</span><br></pre></td></tr></table></figure><h2 id="向表中导入数据"><a href="#向表中导入数据" class="headerlink" title="向表中导入数据"></a>向表中导入数据</h2><p><code>注意</code>：不能直接向RCFILE表插入数据，需要从其他表向ORCFILE表插入数据。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_rcfile  <span class="keyword">select</span> * <span class="keyword">from</span> t_textfile</span><br></pre></td></tr></table></figure></p><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t_rcfile</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;RCFILE指的是 Record Columnar File,是一种高效压缩率的二进制文件格式，&lt;strong&gt;被用于在一个时间点操作多行的
      
    
    </summary>
    
      <category term="hive" scheme="https://tgluon.github.io/categories/hive/"/>
    
    
      <category term="hive" scheme="https://tgluon.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>TEXTFILE格式存储到hive表</title>
    <link href="https://tgluon.github.io/2018/07/28/TEXTFILE%E6%A0%BC%E5%BC%8F%E5%AD%98%E5%82%A8%E5%88%B0hive%E8%A1%A8/"/>
    <id>https://tgluon.github.io/2018/07/28/TEXTFILE格式存储到hive表/</id>
    <published>2018-07-27T23:43:23.000Z</published>
    <updated>2018-07-28T00:40:59.562Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>TEXTFILE就是普通的文本型文件，是hadoop里面最常用的输入输出格式，也是hive默认文件格式，如果表定义为TEXFILE,则可以向该表中装载以逗号、tab、空格作为分隔符的数据，也可以导入json格式文件。<br>TEXTFILE格式的输出包是：   </p><blockquote></blockquote><p>org.apache.hadoop.mapred.TextfileInputFormat<br>org.apache.hadoop.mapred.TextfileOutputFormat</p><p><code>注意:</code>本段文字来自《Hadoop构建数据仓库实践》书籍6.2.1章节</p><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><h2 id="建立TEXTFILE格式表"><a href="#建立TEXTFILE格式表" class="headerlink" title="建立TEXTFILE格式表"></a>建立TEXTFILE格式表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_textfile(   </span><br><span class="line">    c1 <span class="keyword">string</span>,  </span><br><span class="line">    c2 <span class="built_in">int</span>,   </span><br><span class="line">    c3 <span class="keyword">string</span>,   </span><br><span class="line">    c4 <span class="keyword">string</span>)  </span><br><span class="line">    <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> </span><br><span class="line">    <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span></span><br><span class="line">    <span class="keyword">stored</span> <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure><h2 id="装载数据"><a href="#装载数据" class="headerlink" title="装载数据"></a>装载数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/textfile/a.txt'</span> <span class="keyword">into</span>/overwrite t_textfile;</span><br></pre></td></tr></table></figure><h2 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t_textfile</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;TEXTFILE就是普通的文本型文件，是hadoop里面最常用的输入输出格式，也是hive默认文件格式，如果表定义为TEXFILE,则可以向
      
    
    </summary>
    
      <category term="hive" scheme="https://tgluon.github.io/categories/hive/"/>
    
    
      <category term="hive" scheme="https://tgluon.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>sequencefile方式存储到hive表</title>
    <link href="https://tgluon.github.io/2018/07/28/SEQUENCEFILE%E6%A0%BC%E5%BC%8F%E5%AD%98%E5%82%A8%E5%88%B0hive%E8%A1%A8/"/>
    <id>https://tgluon.github.io/2018/07/28/SEQUENCEFILE格式存储到hive表/</id>
    <published>2018-07-27T17:43:23.000Z</published>
    <updated>2018-07-28T00:40:59.560Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>我们知道hadoop处理少量大文件比大量小文件的性能要好。如果文件小于hadoop定义的块尺寸(hadoop2.x默认128MB),可以认为是小文件.元数据的增长将转化为Namenode的开销。如果有大量小文件,Namenode会成为瓶颈。为了解决这个问题，hadoop引入了sequence文件，将sequence作为存储小文件的容器。<br>Sequnce文件是有二进制键值对组成的平面文件。Hive将查询转换成MapReduce作业时，决定一个给定记录的哪些键/值对被使用。Sequence文件是可分割的二进制格式，主要的用途是联合多个小文件。<br>SEQUENCEFILE格式的输入输入包是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">org.apache.hadoop.hive.ql.id.HiveSequenceFileOutputFormat</span><br></pre></td></tr></table></figure></p><p><code>注意:</code>本段文字来自《Hadoop构建数据仓库实践》书籍6.2.1章节</p><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><h2 id="建立Sequencefile格式表"><a href="#建立Sequencefile格式表" class="headerlink" title="建立Sequencefile格式表"></a>建立Sequencefile格式表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_sequencefile(   </span><br><span class="line">    c1 <span class="keyword">string</span>,  </span><br><span class="line">    c2 <span class="built_in">int</span>,   </span><br><span class="line">    c3 <span class="keyword">string</span>,   </span><br><span class="line">    c4 <span class="keyword">string</span>)  </span><br><span class="line">    <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> </span><br><span class="line">    <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span></span><br><span class="line">    <span class="keyword">stored</span> <span class="keyword">as</span> sequencefile;</span><br></pre></td></tr></table></figure><h2 id="向表中导入数据"><a href="#向表中导入数据" class="headerlink" title="向表中导入数据"></a>向表中导入数据</h2><p><code>注意</code>：与TEXTFILE有些不同，应为SEQUENCEFILE是二进制格式，所以需要从其他表向SEQUENCEFILE表插入数据。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_sequencefile  <span class="keyword">select</span> * <span class="keyword">from</span> t_textfile</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;我们知道hadoop处理少量大文件比大量小文件的性能要好。如果文件小于hadoop定义的块尺寸(hadoop2.x默认128MB),可以认为
      
    
    </summary>
    
      <category term="hive" scheme="https://tgluon.github.io/categories/hive/"/>
    
    
      <category term="hive" scheme="https://tgluon.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>加载json文件到hive表</title>
    <link href="https://tgluon.github.io/2018/07/28/%E5%8A%A0%E8%BD%BDjson%E6%96%87%E4%BB%B6%E5%88%B0hive%E8%A1%A8/"/>
    <id>https://tgluon.github.io/2018/07/28/加载json文件到hive表/</id>
    <published>2018-07-27T16:43:23.000Z</published>
    <updated>2018-07-28T00:40:59.564Z</updated>
    
    <content type="html"><![CDATA[<h1 id="struct类型应用"><a href="#struct类型应用" class="headerlink" title="struct类型应用"></a>struct类型应用</h1><h2 id="准备json文件"><a href="#准备json文件" class="headerlink" title="准备json文件"></a>准备json文件</h2><p>simple.json<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"foo"</span>:<span class="string">"abc"</span>,<span class="attr">"bar"</span>:<span class="string">"200901011000000"</span>,<span class="attr">"quux"</span>:&#123;<span class="attr">"quuxid"</span>:<span class="number">1234</span>,<span class="attr">"quuxname"</span>:<span class="string">"sam"</span>&#125;&#125;</span><br></pre></td></tr></table></figure></p><h2 id="添加hive-hcatalog-core-jar包"><a href="#添加hive-hcatalog-core-jar包" class="headerlink" title="添加hive-hcatalog-core.jar包"></a>添加hive-hcatalog-core.jar包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar /home/hadoop/hive/lib/hive-hcatalog-core.jar</span><br></pre></td></tr></table></figure><h2 id="建立测试表"><a href="#建立测试表" class="headerlink" title="建立测试表"></a>建立测试表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> mytest;</span><br><span class="line"><span class="keyword">use</span> mytest;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span>  my_table(</span><br><span class="line">   foo <span class="keyword">string</span>,</span><br><span class="line">   bar <span class="keyword">string</span>,</span><br><span class="line">   quux <span class="keyword">struct</span>&lt;quuxid:<span class="built_in">int</span>,quuxname:<span class="keyword">string</span>&gt;</span><br><span class="line">) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> serde <span class="string">'org.apache.hive.hcatlog.data.JsonSerde'</span></span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure><h2 id="装载数据"><a href="#装载数据" class="headerlink" title="装载数据"></a>装载数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/data/simple.json'</span> <span class="keyword">into</span> <span class="keyword">table</span> my_table;</span><br></pre></td></tr></table></figure><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> foo, bar,quux.quuxid,quux.quuname <span class="keyword">from</span> my_table;</span><br></pre></td></tr></table></figure><h1 id="sstruct结合array类型应用"><a href="#sstruct结合array类型应用" class="headerlink" title="sstruct结合array类型应用"></a>sstruct结合array类型应用</h1><h2 id="准备json文件-1"><a href="#准备json文件-1" class="headerlink" title="准备json文件"></a>准备json文件</h2><p>complex.json<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;"docid":"abc","user":&#123;"id":123,"username":"saml1234","name":"sam","shippingaddress":&#123;"address1":"123mainst","address2:""","city":"durham","state":"nc"&#125;,"orders":[&#123;"itemid":6789,"orderdate":"11/11/2012"&#125;,&#123;"itemid":4352,"orderdate"："12/12/2012"&#125;]&#125;&#125;</span><br></pre></td></tr></table></figure></p><h2 id="添加hive-hcatalog-core-jar包-1"><a href="#添加hive-hcatalog-core-jar包-1" class="headerlink" title="添加hive-hcatalog-core.jar包"></a>添加hive-hcatalog-core.jar包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar /home/hadoop/hive/lib/hive-hcatalog-core.jar</span><br></pre></td></tr></table></figure><h2 id="建立测试表-1"><a href="#建立测试表-1" class="headerlink" title="建立测试表"></a>建立测试表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> mytest;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span>  <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> complex_json(</span><br><span class="line"> docid <span class="keyword">string</span>,</span><br><span class="line"> <span class="keyword">user</span> <span class="keyword">struct</span>&lt;<span class="keyword">id</span>: <span class="built_in">int</span>,</span><br><span class="line">      username: <span class="keyword">string</span>,</span><br><span class="line">      shippingaddress:<span class="keyword">struct</span>&lt;address1:<span class="keyword">string</span></span><br><span class="line">           address2: <span class="keyword">string</span>,</span><br><span class="line">           city: <span class="keyword">string</span>,</span><br><span class="line">           state: <span class="keyword">string</span>&gt;,</span><br><span class="line">           orders:<span class="built_in">array</span>&lt;<span class="keyword">struct</span>&lt;itemid:<span class="built_in">int</span>,orderdate:<span class="keyword">String</span>&gt;&gt;&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> serde <span class="string">'org.apache.hive.hcatlog.data.JsonSerde'</span></span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure><h2 id="装载数据-1"><a href="#装载数据-1" class="headerlink" title="装载数据"></a>装载数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/data/complex.json'</span> overwrite <span class="keyword">table</span> complex_json;</span><br></pre></td></tr></table></figure><h2 id="查询-1"><a href="#查询-1" class="headerlink" title="查询"></a>查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> docid,user.id,user.shippingaddress.city <span class="keyword">as</span> city ,user.orders[<span class="number">0</span>].itemid <span class="keyword">as</span> order0id,user.orders[<span class="number">1</span>].itemid <span class="keyword">as</span> order1ib    </span><br><span class="line"><span class="keyword">from</span> complex_json;</span><br></pre></td></tr></table></figure><h1 id="动态map类型应用"><a href="#动态map类型应用" class="headerlink" title="动态map类型应用"></a>动态map类型应用</h1><h2 id="json文件"><a href="#json文件" class="headerlink" title="json文件"></a>json文件</h2><p>a.json<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"conflict"</span>:&#123;<span class="attr">"liveid"</span>:<span class="number">123</span>,<span class="attr">"zhuboid"</span>:<span class="string">"456"</span>,<span class="attr">"media"</span>:<span class="number">789</span>,<span class="attr">"proxy"</span>:<span class="string">"ac"</span>,<span class="attr">"result"</span>:<span class="number">10000</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"conflict"</span>:&#123;<span class="attr">"liveid"</span>:<span class="number">123</span>,<span class="attr">"zhuboid"</span>:<span class="string">"456"</span>,<span class="attr">"media"</span>:<span class="number">789</span>,<span class="attr">"proxy"</span>:<span class="string">"ac"</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"conflict"</span>:&#123;<span class="attr">"liveid"</span>:<span class="number">123</span>,<span class="attr">"zhuboid"</span>:<span class="string">"456"</span>,<span class="attr">"media"</span>:<span class="number">789</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"conflict"</span>:&#123;<span class="attr">"liveid"</span>:<span class="number">123</span>,<span class="attr">"zhuboid"</span>:<span class="string">"456"</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"conflict"</span>:&#123;<span class="attr">"liveid"</span>:<span class="number">123</span>&#125;&#125;</span><br></pre></td></tr></table></figure></p><h2 id="添加hive-hcatalog-core-jar包-2"><a href="#添加hive-hcatalog-core-jar包-2" class="headerlink" title="添加hive-hcatalog-core.jar包"></a>添加hive-hcatalog-core.jar包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar /home/hadoop/hive/lib/hive-hcatalog-core.jar</span><br></pre></td></tr></table></figure><h2 id="建立测试表-2"><a href="#建立测试表-2" class="headerlink" title="建立测试表"></a>建立测试表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> mytest;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> json_table(</span><br><span class="line">    conflict <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> serde <span class="string">'org.apache.hive.hcatlog.data.JsonSerde'</span></span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure><h2 id="查询-2"><a href="#查询-2" class="headerlink" title="查询"></a>查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> json_table;   </span><br><span class="line"><span class="keyword">select</span> conflict[<span class="string">'media'</span>] <span class="keyword">from</span> json_table;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;struct类型应用&quot;&gt;&lt;a href=&quot;#struct类型应用&quot; class=&quot;headerlink&quot; title=&quot;struct类型应用&quot;&gt;&lt;/a&gt;struct类型应用&lt;/h1&gt;&lt;h2 id=&quot;准备json文件&quot;&gt;&lt;a href=&quot;#准备json文件&quot; cla
      
    
    </summary>
    
      <category term="hive" scheme="https://tgluon.github.io/categories/hive/"/>
    
    
      <category term="hive" scheme="https://tgluon.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>大数据平台监控工具</title>
    <link href="https://tgluon.github.io/2018/07/24/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/"/>
    <id>https://tgluon.github.io/2018/07/24/监控工具/</id>
    <published>2018-07-24T10:19:59.000Z</published>
    <updated>2018-07-24T10:39:00.771Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大数据平台监控工具"><a href="#大数据平台监控工具" class="headerlink" title="大数据平台监控工具"></a>大数据平台监控工具</h1><h2 id="Prometheus-grafana"><a href="#Prometheus-grafana" class="headerlink" title="Prometheus+grafana"></a>Prometheus+grafana</h2><p><code>环境搭建参考博客：</code></p><blockquote><p><a href="http://blog.51cto.com/youerning/2050543" target="_blank" rel="noopener">http://blog.51cto.com/youerning/2050543</a>   </p></blockquote><h2 id="cerebro"><a href="#cerebro" class="headerlink" title="cerebro"></a>cerebro</h2><p><code>作为本地监控，监控elasticsearch</code>     </p><blockquote><p><a href="https://github.com/lmenezes/cerebro" target="_blank" rel="noopener">https://github.com/lmenezes/cerebro</a></p></blockquote><h2 id="openTSDB-grafana"><a href="#openTSDB-grafana" class="headerlink" title="openTSDB+grafana"></a>openTSDB+grafana</h2><p><code>参考</code></p><blockquote><p><a href="https://blog.csdn.net/u011537073/article/details/54565742" target="_blank" rel="noopener">https://blog.csdn.net/u011537073/article/details/54565742</a></p></blockquote><h2 id="tableau"><a href="#tableau" class="headerlink" title="tableau"></a>tableau</h2><p><code>付费</code> </p><blockquote><p><a href="https://www.tableau.com/support/help" target="_blank" rel="noopener">https://www.tableau.com/support/help</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;大数据平台监控工具&quot;&gt;&lt;a href=&quot;#大数据平台监控工具&quot; class=&quot;headerlink&quot; title=&quot;大数据平台监控工具&quot;&gt;&lt;/a&gt;大数据平台监控工具&lt;/h1&gt;&lt;h2 id=&quot;Prometheus-grafana&quot;&gt;&lt;a href=&quot;#Prometh
      
    
    </summary>
    
      <category term="大数据平台监控" scheme="https://tgluon.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="大数据平台监控" scheme="https://tgluon.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>环境变量配置</title>
    <link href="https://tgluon.github.io/2018/07/22/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"/>
    <id>https://tgluon.github.io/2018/07/22/环境变量配置/</id>
    <published>2018-07-22T15:10:10.000Z</published>
    <updated>2018-07-24T10:18:23.016Z</updated>
    
    <content type="html"><![CDATA[<h1 id="java环境变量配置"><a href="#java环境变量配置" class="headerlink" title="java环境变量配置"></a>java环境变量配置</h1><h2 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h2><h3 id="方式一-常用"><a href="#方式一-常用" class="headerlink" title="方式一(常用):"></a>方式一(常用):</h3><p>变量名：JAVA_HOME<br>变量值：D:\Program Files\Java\jdk1.8.0_73<br>变量名：PATH<br>变量值：%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin<br>变量名：classpath<br>变量值：.,%JAVA_HOME%\lib;%JAVA_HOME%\lib\dt.jar;  %JAVA_HOME%\lib\tools.jar  </p><h3 id="方法二："><a href="#方法二：" class="headerlink" title="方法二："></a>方法二：</h3><p>path:<br>D:\Program Files\Java\jdk1.8.0_60\bin<br>classpath:<br>D:\Program Files\Java\jdk1.8.0_60\lib<br>javac</p><h2 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h2><p>JAVA_HOME=/home/hadoop/java/jdk1.8.0_73<br>CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>PATH=$PATH:$JAVA_HOME/bin<br>export JAVA_HOME CLASSPATH   </p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>在命令行输入一下命令进行验证：<br>1.java<br>2.javac   </p><h2 id="查看版本号"><a href="#查看版本号" class="headerlink" title="查看版本号"></a>查看版本号</h2><h1 id="maven环境变量配置"><a href="#maven环境变量配置" class="headerlink" title="maven环境变量配置"></a>maven环境变量配置</h1><h2 id="windows-1"><a href="#windows-1" class="headerlink" title="windows"></a>windows</h2><p><code>MAVEM_HOME</code><br>D:\Program Files\maven<br><code>path</code><br>%MAVEN_HOME%\bin<br>注意：%MAVEN_HOME%\bin 应该放在path的最前面。   </p><h2 id="linux-1"><a href="#linux-1" class="headerlink" title="linux"></a>linux</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MAVEN_HOME=/home/hadoop/maven     </span><br><span class="line">PATH=$PATH:$MAVEN_HOME/bin</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;java环境变量配置&quot;&gt;&lt;a href=&quot;#java环境变量配置&quot; class=&quot;headerlink&quot; title=&quot;java环境变量配置&quot;&gt;&lt;/a&gt;java环境变量配置&lt;/h1&gt;&lt;h2 id=&quot;windows&quot;&gt;&lt;a href=&quot;#windows&quot; class
      
    
    </summary>
    
      <category term="环境变量配置" scheme="https://tgluon.github.io/categories/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="java" scheme="https://tgluon.github.io/tags/java/"/>
    
  </entry>
  
</feed>
